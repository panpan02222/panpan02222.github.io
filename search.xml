<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2024/07/15/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>利用 NPU 运行 ChatGLM3 全流程</title>
    <url>/2024/04/26/AI/20240426_%E5%88%A9%E7%94%A8NPU%E8%BF%90%E8%A1%8CChatGLM3%E5%85%A8%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<p>利用 NPU 运行 ChatGLM3 全流程</p>
<span id="more"></span>


<h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><ol>
<li><p>新建 Conda 虚拟环境  <code>conda create -n env_name python==3.10</code></p>
</li>
<li><p>下载 ChatGLM3 源代码 <code>git clone https://github.com/THUDM/ChatGLM3.git</code></p>
</li>
<li><p>下载模型权重 </p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">git lfs install</span><br><span class="line">git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装基础环境，进入源码仓库 <code>cd ChatGLM3</code> , pip 安装 <code>pip install -r requirements.txt</code><br><strong>特别说明 : torch 版本可在 requirements.txt 中手动修改</strong></p>
</li>
<li><p>安装 npu 基础环境，下载对应 torch 的 <strong>torch-npu</strong> 依赖包，本地安装 <code>pip install xxx.whl</code><br><a href="https://gitee.com/ascend/pytorch/releases">torch-npu 官方下载地址</a></p>
</li>
<li><p>运行以下代码，验证环境是否安装成功</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_npu</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">z = x.mm(y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<hr>
<h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h4><ol>
<li>修改代码 <code>ChatGLM3-main/basic_demo/cli_demo.py</code><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_npu <span class="comment"># 新增一行</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># transoformer架构需要加 `.to('npu') `</span></span><br><span class="line">model = AutoModel.from_pretrained(MODEL_PATH, trust_remote_code=<span class="literal">True</span>).to(<span class="string">'npu'</span>).<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># model = AutoModel.from_pretrained(MODEL_PATH, trust_remote_code=True, device_map="auto").eval()</span></span><br></pre></td></tr></tbody></table></figure></li>
<li>运行代码 <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python basic_demo/cli_demo.py</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><hr>
<h5 id="安装依赖deepspeed"><a href="#安装依赖deepspeed" class="headerlink" title="安装依赖deepspeed"></a>安装依赖 <strong>deepspeed</strong></h5><ol>
<li><code>pip install deepspeed==0.9.2</code></li>
<li>下载 DeepSpeed,  执行本地安装 <figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cd DeepSpeed-v0.9.2</span><br><span class="line">pip3 install -e ./</span><br></pre></td></tr></tbody></table></figure>
 <a href="https://gitee.com/ascend/DeepSpeed/">DeepSpeed 官方仓库</a></li>
</ol>
<hr>
<ol start="0">
<li>注释微调依赖文件 <code>vim requirements.txt</code>  ,  安装微调相关依赖 <code>pip install -r requirements.txt</code><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">jieba&gt;=0.42.1</span><br><span class="line">ruamel_yaml&gt;=0.18.6</span><br><span class="line">rouge_chinese&gt;=1.0.3</span><br><span class="line">jupyter&gt;=1.0.0</span><br><span class="line">datasets&gt;=2.18.0</span><br><span class="line">peft&gt;=0.10.0</span><br><span class="line"># deepspeed==0.13.1 #注释</span><br><span class="line"># mpi4py&gt;=3.1.5 #注释</span><br></pre></td></tr></tbody></table></figure></li>
<li>运行微调脚本，按需修改路径 <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> finetune_demo</span><br><span class="line"></span><br><span class="line">OMP_NUM_THREADS=1 torchrun --standalone --nnodes=1 --nproc_per_node=8  finetune_hf.py  /home/jovyan/chatglm3/AdvertiseGen_fix  THUDM/chatglm3-6b  configs/sft.yaml configs/ds_zero_3.json</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<blockquote>
<p>参考链接<br><a href="https://zhipu-ai.feishu.cn/wiki/HIj5wVxGqiUg3rkbQ1OcVEe5n9g">chatglm3 官方说明</a><br><a href="https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/PyTorch/built-in/foundation/ChatGLM-6B">ascend 运行 chatglm1 官方教程</a><br><a href="https://www.hiascend.com/software/modelzoo/models/detail/5dfa1b69e0db4b8f889c5ee20aa23dcb">ascend 运行 chatglm2 官方教程</a></p>
</blockquote>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>nccl</tag>
        <tag>npu</tag>
        <tag>chatglm3</tag>
        <tag>deepspeed</tag>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>llama2-13B 联通云 AI 算力平台训练任务测试</title>
    <url>/2024/04/25/AI/20240425_Llama2-13B%20%E8%81%94%E9%80%9A%E4%BA%91AI%E7%AE%97%E5%8A%9B%E5%B9%B3%E5%8F%B0%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p>基于联通云 AI 算力平台训练 llama2-13B 任务测试</p>
<!---more-->

<h2 id="一、准备环境"><a href="#一、准备环境" class="headerlink" title="一、准备环境"></a>一、准备环境</h2><h4 id="创建notebook"><a href="#创建notebook" class="headerlink" title="创建notebook"></a>创建 notebook</h4><p><del>在创建 notebook 选项中，根据如下进行选择</del></p>
<p><del>付费类型：按量计费</del></p>
<p><del>名称：llama2</del></p>
<p><del>云区域：上海二十二区</del></p>
<p><del>算力规格：184C1504G，8*910B_liquid</del></p>
<p><del>镜像：公共镜像 jupyter:pytorch2.1.0-cann7</del></p>
<p><del>存储卷：AI 原生存储</del></p>
<p><del>确认配置后点击创建，一段时间后创建完成，点击打开</del></p>
<hr>
<h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><ul>
<li><p>打开 terminal，默认在 base 环境下，在当前用户根目录下下载代码与权重与数据集</p>
<p>  <code>git clone https://gitee.com/ascend/ModelLink.git</code></p>
<p>  <code>git clone https://gitee.com/ascend/AscendSpeed.git</code></p>
<p>  <code>git clone --depth 1 https://gitee.com/ascend/DeepSpeed.git -b v0.9.2</code></p>
<blockquote>
<p>注：下载权重时若文件过大，git 的时候需要使用 git-lfs，安装命令如下</p>
<p>wget <a href="https://github.com/git-lfs/git-lfs/releases/download/v3.1.2/git-lfs-linux-arm64-v3.1.2.tar.gz">https://github.com/git-lfs/git-lfs/releases/download/v3.1.2/git-lfs-linux-arm64-v3.1.2.tar.gz</a><br><code>tar -xvf git-lfs-linux-arm64-v3.1.2.tar.gz</code></p>
<p><code>sudo ./install.sh</code></p>
<p><code>git lfs install</code></p>
</blockquote>
</li>
</ul>
<hr>
<h4 id="安装依赖-1"><a href="#安装依赖-1" class="headerlink" title="安装依赖"></a>安装依赖</h4><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cd AscendSpeed`</span><br><span class="line"></span><br><span class="line">pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line"></span><br><span class="line">cd ModelLink</span><br><span class="line"></span><br><span class="line">pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></tbody></table></figure>

<hr>
<h4 id="创建conda环境"><a href="#创建conda环境" class="headerlink" title="创建conda环境"></a>创建 conda 环境</h4><ul>
<li><p>将 base 环境拷贝成新的 conda 环境</p>
<p>  <code>conda create -n test1 --clone base</code></p>
</li>
</ul>
<hr>
<h4 id="打包新环境"><a href="#打包新环境" class="headerlink" title="打包新环境"></a>打包新环境</h4><ul>
<li><p>进入新环境</p>
<p>  <code>conda deactivate</code></p>
<p>  <code>conda activate test</code></p>
</li>
</ul>
<hr>
<h4 id="安装conda-pack"><a href="#安装conda-pack" class="headerlink" title="安装conda-pack"></a>安装 conda-pack</h4><pre><code>`pip install conda-pack -i https://pypi.tuna.tsinghua.edu.cn/simple`
</code></pre>
<hr>
<h4 id="打包新环境至文件夹"><a href="#打包新环境至文件夹" class="headerlink" title="打包新环境至文件夹"></a>打包新环境至文件夹</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda pack -n <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">tar -zxf test.tar.gz -C <span class="built_in">test</span>/</span><br></pre></td></tr></tbody></table></figure>

<hr>
<h4 id="返回base环境，安装依赖"><a href="#返回base环境，安装依赖" class="headerlink" title="返回base环境，安装依赖"></a>返回 base 环境，安装依赖</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> <span class="built_in">test</span>/bin/deactivate</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> DeepSpeed</span><br><span class="line"></span><br><span class="line">pip install -e .</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> AscendSpeed</span><br><span class="line"></span><br><span class="line">pip install -e .</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ..</span><br></pre></td></tr></tbody></table></figure>

<hr>
<h4 id="处理数据集"><a href="#处理数据集" class="headerlink" title="处理数据集"></a>处理数据集</h4><pre><code>`cd ModelLink`

`vim dataset.sh`
</code></pre>
<ul>
<li>添加如下内容 </li>
</ul>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">python ./tools/preprocess_data.py \</span><br><span class="line">       --input ./data/train-00000-of-00001-a09b74b3ef9c3b56.parquet \</span><br><span class="line">       --tokenizer-name-or-path ../Llama-2-13b-chat-ms \</span><br><span class="line">       --output-prefix ./dataset/alpaca \</span><br><span class="line">       --workers 4 \</span><br><span class="line">       --log-interval 1000 \</span><br><span class="line">       --tokenizer-type PretrainedFromHF</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p>进行数据处理</p>
<p>  <code>bash dataset.sh</code></p>
</li>
</ul>
<hr>
<h4 id="创建训练脚本"><a href="#创建训练脚本" class="headerlink" title="创建训练脚本"></a>创建训练脚本</h4><p><code>vim examples/llama2/pretrain_llama2_13B_ptd_8p_2.sh</code></p>
<ul>
<li>添加如下内容 </li>
</ul>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">export CUDA_DEVICE_MAX_CONNECTIONS=1</span><br><span class="line">export NPU_ASD_ENABLE=0</span><br><span class="line"></span><br><span class="line">GPUS_PER_NODE=8</span><br><span class="line">MASTER_ADDR=$MASTER_ADDR</span><br><span class="line">MASTER_PORT=$MASTER_PORT</span><br><span class="line">NODE_RANK=$RANK</span><br><span class="line">WORLD_SIZE=$WORLD_SIZE</span><br><span class="line">NNODES=2</span><br><span class="line"></span><br><span class="line">CKPT_SAVE_DIR=/home/aifs/ModelLink/output/ckpt</span><br><span class="line">DATA_PATH=/home/aifs/ModelLink/dataset/alpaca_text_document</span><br><span class="line">TOKENIZER_MODEL=/home/aifs/Llama-2-13b-chat-ms/tokenizer.model</span><br><span class="line">TP=8</span><br><span class="line">PP=1</span><br><span class="line"></span><br><span class="line">DISTRIBUTED_ARGS="</span><br><span class="line">    --nproc_per_node $GPUS_PER_NODE \</span><br><span class="line">    --nnodes $NNODES \</span><br><span class="line">    --node_rank $NODE_RANK \</span><br><span class="line">    --master_addr $MASTER_ADDR \</span><br><span class="line">    --master_port $MASTER_PORT</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">GPT_ARGS="</span><br><span class="line">    --tensor-model-parallel-size ${TP} \</span><br><span class="line">    --pipeline-model-parallel-size ${PP} \</span><br><span class="line">    --sequence-parallel \</span><br><span class="line">    --num-layers 40 \</span><br><span class="line">    --hidden-size 5120 \</span><br><span class="line">    --ffn-hidden-size 13824 \</span><br><span class="line">    --num-attention-heads 40 \</span><br><span class="line">    --tokenizer-type Llama2Tokenizer \</span><br><span class="line">    --tokenizer-model ${TOKENIZER_MODEL} \</span><br><span class="line">    --seq-length 4096 \</span><br><span class="line">    --max-position-embeddings 4096 \</span><br><span class="line">    --micro-batch-size 2 \</span><br><span class="line">    --global-batch-size 16 \</span><br><span class="line">    --make-vocab-size-divisible-by 1 \</span><br><span class="line">    --lr 1e-6 \</span><br><span class="line">    --train-iters 5000 \</span><br><span class="line">    --lr-decay-style cosine \</span><br><span class="line">    --untie-embeddings-and-output-weights \</span><br><span class="line">    --disable-bias-linear \</span><br><span class="line">    --attention-dropout 0.0 \</span><br><span class="line">    --init-method-std 0.01 \</span><br><span class="line">    --hidden-dropout 0.0 \</span><br><span class="line">    --position-embedding-type rope \</span><br><span class="line">    --normalization RMSNorm \</span><br><span class="line">    --use-fused-rmsnorm \</span><br><span class="line">    --swiglu \</span><br><span class="line">    --use-flash-attn \</span><br><span class="line">    --no-masked-softmax-fusion \</span><br><span class="line">    --attention-softmax-in-fp32 \</span><br><span class="line">    --min-lr 1e-8 \</span><br><span class="line">    --weight-decay 1e-1 \</span><br><span class="line">    --lr-warmup-fraction 0.01 \</span><br><span class="line">    --clip-grad 1.0 \</span><br><span class="line">    --adam-beta1 0.9 \</span><br><span class="line">    --initial-loss-scale 4096 \</span><br><span class="line">    --adam-beta2 0.95 \</span><br><span class="line">    --no-gradient-accumulation-fusion \</span><br><span class="line">    --no-load-optim \</span><br><span class="line">    --no-load-rng \</span><br><span class="line">    --bf16</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">DATA_ARGS="</span><br><span class="line">    --data-path $DATA_PATH \</span><br><span class="line">    --split 949,50,1</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">OUTPUT_ARGS="</span><br><span class="line">    --log-interval 1 \</span><br><span class="line">    --save-interval 10000 \</span><br><span class="line">    --eval-interval 1000 \</span><br><span class="line">    --eval-iters 10 \</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">python -m torch.distributed.launch $DISTRIBUTED_ARGS pretrain_gpt.py \</span><br><span class="line">    $GPT_ARGS \</span><br><span class="line">    $DATA_ARGS \</span><br><span class="line">    $OUTPUT_ARGS \</span><br><span class="line">    --distributed-backend nccl \</span><br><span class="line">    --save $CKPT_SAVE_DIR \</span><br><span class="line">    | tee logs/train_llama2_13b.log</span><br></pre></td></tr></tbody></table></figure>

<pre><code>`vim train_1.sh`
</code></pre>
<ul>
<li>添加如下内容 </li>
</ul>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">export CRYPTOGRAPHY_OPENSSL_NO_LEGACY=1</span><br><span class="line">export ASCEND_LAUNCH_BLOCKING=1</span><br><span class="line">bash examples/llama2/pretrain_llama2_13B_ptd_8p_2.sh</span><br></pre></td></tr></tbody></table></figure>
<hr>
<h2 id="二、创建训练任务"><a href="#二、创建训练任务" class="headerlink" title="二、创建训练任务"></a>二、创建训练任务</h2><p><del>在提交任务中，根据如下进行选择</del></p>
<p><del>任务名称：test</del></p>
<p><del>训练环境：预置镜像 PyTorch2.1.0 pytorch2.1.0-cann7</del></p>
<p><del>存储挂载：AI 原生存储</del></p>
<p><del>云区域：上海二十二区</del></p>
<p><del>存储路径：AI_product</del></p>
<p><del>启动命令：</del></p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">source /home/aifs/test1/bin/activate &amp;&amp; source /usr/local/Ascend/ascend-toolkit/set_env.sh &amp;&amp; cd /home/aifs/DeepSpeed &amp;&amp; pip install -e . &amp;&amp; cd /home/aifs/AscendSpeed &amp;&amp; pip install -e . &amp;&amp; cd .. &amp;&amp; cd ModelLink &amp;&amp; bash train_1.sh</span><br></pre></td></tr></tbody></table></figure>

<p><del>算力池：公共算力池</del></p>
<p><del>付费类型：按量计费</del></p>
<p><del>算力规格：184C1504G，8*910B_liquid</del></p>
<p><del>节点数量：2</del></p>
<p><del>确认配置后点击提交，一段时间后创建完成</del></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>DB-GPT 源代码部署</title>
    <url>/2024/07/23/AI/20240724_DB-GPT%E6%BA%90%E4%BB%A3%E7%A0%81%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>源代码部署 DB-GPT 操作流程，含测试，部署，注意事项等。</p>
<p><img src="/../../img/dbgpt.png" alt="dbgpt"></p>
<span id="more"></span>

<h4 id="1-下载源码"><a href="#1-下载源码" class="headerlink" title="1. 下载源码"></a>1. 下载源码</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/eosphoros-ai/DB-GPT.git</span><br></pre></td></tr></tbody></table></figure>


<h4 id="2-安装Minconda-运行环境"><a href="#2-安装Minconda-运行环境" class="headerlink" title="2. 安装Minconda(运行环境)"></a>2. 安装 Minconda (运行环境)</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 新建文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> -p ~/miniconda3</span><br><span class="line"><span class="comment"># 在线下载minconda安装包</span></span><br><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh</span><br><span class="line"><span class="comment"># 运行安装程序</span></span><br><span class="line">bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3</span><br><span class="line"><span class="comment"># 删除安装包</span></span><br><span class="line"><span class="built_in">rm</span> -rf ~/miniconda3/miniconda.sh</span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p>[!NOTE]</p>
<p>安装 <code>Minconda</code> 软件后重新连接终端，用于激活.</p>
</blockquote>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">初始化</span><br><span class="line">~/miniconda3/bin/conda init bash</span><br><span class="line">~/miniconda3/bin/conda init zsh</span><br></pre></td></tr></tbody></table></figure>



<h4 id="3-新建代码运行环境"><a href="#3-新建代码运行环境" class="headerlink" title="3. 新建代码运行环境"></a>3. 新建代码运行环境</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 基于minconda新建一个名称为dbgpt_env的基础环境, 且python版本为3.10</span></span><br><span class="line">conda create -n dbgpt_env python=3.10</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p>Conda 环境常用命令 :</p>
<ul>
<li>列出所有的环境 <code>conda env list </code></li>
<li>激活指定环境 <code>conda activate xxxx</code>|xxx 为环境名称</li>
<li>退出当前环境 <code>conda deactivate</code>| 默认环境为:<code>base</code></li>
<li>查看当前环境的基础信息 <code>conda info</code> | 主要检查 python 版本，安装库的路径，<code>conda源地址</code></li>
</ul>
</li>
<li><p>清华源地址</p>
<ul>
<li><code>https://pypi.tuna.tsinghua.edu.cn/simple</code></li>
</ul>
</li>
<li><p>修改 pip 下载源的地址</p>
<ul>
<li><code>https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/</code></li>
</ul>
</li>
</ul>
<h4 id="4-安装项目所需依赖包-库"><a href="#4-安装项目所需依赖包-库" class="headerlink" title="4. 安装项目所需依赖包/库"></a>4. 安装项目所需依赖包 / 库</h4><ul>
<li>DB-GPT 下有 setup.py, 为作者写的安装依赖脚本 </li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install -e <span class="string">".[default]"</span></span><br></pre></td></tr></tbody></table></figure>



<h4 id="5-安装可以远程访问模型的软件"><a href="#5-安装可以远程访问模型的软件" class="headerlink" title="5. 安装可以远程访问模型的软件"></a>5. 安装可以远程访问模型的软件</h4><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">apt-get install git-lfs</span><br></pre></td></tr></tbody></table></figure>



<h4 id="6-调用在线Qwen接口进行访问"><a href="#6-调用在线Qwen接口进行访问" class="headerlink" title="6. 调用在线Qwen接口进行访问"></a>6. 调用在线 <code>Qwen</code> 接口进行访问</h4><ul>
<li>安装 <code>qwen</code> 接口所需依赖<ul>
<li><code>pip install dashscope</code></li>
</ul>
</li>
</ul>
<h4 id="7-下载Embedding模型"><a href="#7-下载Embedding模型" class="headerlink" title="7 .下载Embedding模型"></a>7 . 下载 Embedding 模型</h4><ul>
<li><p>在 DB-GPT 项目下，新建文件夹 <code>models</code>| 用于放置 Embedding 模型</p>
<ul>
<li><code>mkdir models</code> </li>
<li><code>cd models</code></li>
</ul>
</li>
<li><p>在线下载 Embedding 模型 | 目前好用的有:<strong>m3e-large</strong>, <strong>text2vec-large-chinese</strong> 等</p>
<ul>
<li><p><code>git clone https://huggingface.co/GanymedeNil/text2vec-large-chinese</code></p>
</li>
<li><p><code>git clone https://huggingface.co/moka-ai/m3e-large</code></p>
</li>
</ul>
</li>
</ul>
<h4 id="8-配置模型"><a href="#8-配置模型" class="headerlink" title="8. 配置模型"></a>8. 配置模型</h4><ul>
<li><p>在 DB-GPT 根目录处，复制环境 <code>cp .env.template  .env</code></p>
</li>
<li><p>编辑 <code>VIM .env</code></p>
</li>
<li><p>按照文档进行修改</p>
 <figure class="highlight tex"><table><tbody><tr><td class="code"><pre><span class="line">LLM<span class="built_in">_</span>model=deepseek<span class="built_in">_</span>proxyllm</span><br><span class="line">DEEPSEEK<span class="built_in">_</span>MODEL<span class="built_in">_</span>VERSION=deepseek-chat</span><br><span class="line">DEEPSEEK<span class="built_in">_</span>API<span class="built_in">_</span>BASE=https://api.deepseek.com/v1</span><br><span class="line">DEEPSEEK<span class="built_in">_</span>API<span class="built_in">_</span>KEY=api<span class="built_in">_</span>key</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>具体的模型名称可查看 <code>cat /home/ubuntu/DB-GPT/dbgpt/configs/model_config.py</code> 文件</p>
</li>
</ul>
<h4 id="9-安装SQLite"><a href="#9-安装SQLite" class="headerlink" title="9. 安装SQLite"></a>9. 安装 SQLite</h4><ul>
<li><code>sudo apt install sqlite</code></li>
</ul>
<h4 id="10-运行服务"><a href="#10-运行服务" class="headerlink" title="10. 运行服务"></a>10. 运行服务</h4><ul>
<li><pre><code class="python"># 在DB-GPT根目录运行
python dbgpt/app/dbgpt_server.py
</code></pre>
</li>
<li><p>在浏览器输入:<code>http://localhost:5670/</code> 可查看 web 网站</p>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>Llamaindex_构建 RAG Agent</title>
    <url>/2024/08/01/AI/20240801_Llamaindex%E6%8E%A5%E5%85%A5%E5%8D%83%E5%B8%86RAG/</url>
    <content><![CDATA[<p>记录从使用 <strong>Llama-index</strong> 框架，基于在线文心千帆大模型 <strong>ERNIE-4.0</strong>, 构建实现本地知识检索.</p>
<p><img src="/../../img/basic_rag.png"></p>
<span id="more"></span>

<h4 id="导入大模型"><a href="#导入大模型" class="headerlink" title="导入大模型"></a>导入大模型</h4><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.llms.qianfan <span class="keyword">import</span> Qianfan</span><br><span class="line"></span><br><span class="line">access_key = <span class="string">""</span></span><br><span class="line">secret_key = <span class="string">""</span></span><br><span class="line">model_name = <span class="string">"ERNIE-4.0-8K-Latest"</span></span><br><span class="line">url = <span class="string">"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro"</span></span><br><span class="line">llm = Qianfan(access_key, secret_key, model_name, url, context_window=<span class="number">8192</span>)</span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p> <code>model_name</code> 可在千帆平台查看，如下图:</p>
</blockquote>
<p><img src="/../../img/llamaindex-02.jpg"></p>
<hr>
<h4 id="导入本地Embedding"><a href="#导入本地Embedding" class="headerlink" title="导入本地Embedding"></a>导入本地 Embedding</h4><ul>
<li>下载 Embedding 模型 </li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line">model_dir = snapshot_download(<span class="string">'Xorbits/bge-m3'</span>, cache_dir=<span class="string">'/data/LLMs'</span>)</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>加载本地 Embedding 模型 </li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbedding</span><br><span class="line"></span><br><span class="line">cache_folder = <span class="string">r"embed_model/m3e-large"</span></span><br><span class="line">embed_model = HuggingFaceEmbedding(cache_folder=cache_folder)</span><br></pre></td></tr></tbody></table></figure>

<hr>
<h4 id="构建本地知识库"><a href="#构建本地知识库" class="headerlink" title="构建本地知识库"></a>构建本地知识库</h4><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> SimpleDirectoryReader, VectorStoreIndex</span><br><span class="line"></span><br><span class="line">directory = <span class="string">"/data/documents"</span> <span class="comment">#文档路径</span></span><br><span class="line">vector_index = VectorStoreIndex.from_documents(documents)</span><br></pre></td></tr></tbody></table></figure>

<hr>
<h4 id="构建查询引擎"><a href="#构建查询引擎" class="headerlink" title="构建查询引擎"></a>构建查询引擎</h4><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">query_engine = vector_index.as_query_engine(similarity_top_k=<span class="number">3</span>, llm=llm)</span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p><code>similarity_top_k</code> 可根据经验自行调整，推荐设置 3, 5. </p>
<p><strong>意为：问题与知识库匹配出最多 3 个相似的片段</strong></p>
</blockquote>
<hr>
<h4 id="构建RAG-Agent"><a href="#构建RAG-Agent" class="headerlink" title="构建RAG Agent"></a>构建 RAG Agent</h4><ul>
<li>构建工具 </li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_tool</span>(<span class="params">name, full_name, documents=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f"./data/<span class="subst">{name}</span>"</span>):</span><br><span class="line">        <span class="comment"># build vector index</span></span><br><span class="line">        vector_index = VectorStoreIndex.from_documents(documents)</span><br><span class="line">        vector_index.storage_context.persist(persist_dir=<span class="string">f"./data/<span class="subst">{name}</span>"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        vector_index = load_index_from_storage(</span><br><span class="line">            StorageContext.from_defaults(persist_dir=<span class="string">f"./data/<span class="subst">{name}</span>"</span>),</span><br><span class="line">        )</span><br><span class="line">    query_engine = vector_index.as_query_engine(similarity_top_k=<span class="number">3</span>, llm=llm)</span><br><span class="line">    query_engine_tool = QueryEngineTool(</span><br><span class="line">        query_engine=query_engine,</span><br><span class="line">        metadata=ToolMetadata(</span><br><span class="line">            name=name,</span><br><span class="line">            description=(</span><br><span class="line">                <span class="string">"Provides information about Uber quarterly financials ending"</span></span><br><span class="line">                <span class="string">f" <span class="subst">{full_name}</span>"</span></span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> query_engine_tool</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>设置 Agent</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core.agent <span class="keyword">import</span> AgentRunner, ReActAgent</span><br><span class="line"></span><br><span class="line">agent = ReActAgent.from_tools(</span><br><span class="line">    query_engine_tools, llm=agent_llm, verbose=<span class="literal">True</span>, max_iterations=<span class="number">20</span></span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>运行 </li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">response = agent.chat(<span class="string">"您的问题"</span>)</span><br></pre></td></tr></tbody></table></figure>

<h4 id="整体代码"><a href="#整体代码" class="headerlink" title="整体代码"></a>整体代码</h4><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> Settings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> SimpleDirectoryReader, VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.llms.qianfan <span class="keyword">import</span> Qianfan</span><br><span class="line"><span class="keyword">from</span> llama_index.core.tools <span class="keyword">import</span> QueryEngineTool, ToolMetadata</span><br><span class="line"><span class="keyword">from</span> llama_index.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbedding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化Qianfan模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rag</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.access_key = <span class="string">""</span></span><br><span class="line">        <span class="variable language_">self</span>.secret_key = <span class="string">""</span></span><br><span class="line">        <span class="variable language_">self</span>.model_name = <span class="string">"ERNIE-4.0-8K-Latest"</span></span><br><span class="line">        <span class="variable language_">self</span>.url = <span class="string">"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro"</span></span><br><span class="line">        <span class="variable language_">self</span>.llm = Qianfan(<span class="variable language_">self</span>.access_key, <span class="variable language_">self</span>.secret_key, <span class="variable language_">self</span>.model_name, <span class="variable language_">self</span>.url, context_window=<span class="number">8192</span>)</span><br><span class="line">        <span class="variable language_">self</span>.cache_folder = <span class="string">r"embed_model/m3e-large"</span></span><br><span class="line">        <span class="variable language_">self</span>.directory = <span class="string">r"/data/documents"</span>  <span class="comment"># 数据目录路径</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_tool</span>(<span class="params">self, name, full_name, documents=<span class="literal">None</span></span>):</span><br><span class="line">        embed_model = HuggingFaceEmbedding(cache_folder=<span class="variable language_">self</span>.cache_folder)</span><br><span class="line">        Settings.embed_model = embed_model</span><br><span class="line">        vector_index = VectorStoreIndex.from_documents(documents)</span><br><span class="line">        persist_path = <span class="string">f"<span class="subst">{self.directory}</span>/<span class="subst">{name}</span>"</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(persist_path):</span><br><span class="line">            vector_index.storage_context.persist(persist_dir=persist_path)</span><br><span class="line">        query_engine = vector_index.as_query_engine(similarity_top_k=<span class="number">3</span>, llm=<span class="variable language_">self</span>.llm)</span><br><span class="line">        query_engine_tool = QueryEngineTool(query_engine=query_engine, metadata=ToolMetadata(name=name, description=<span class="string">f"Provides information from document <span class="subst">{full_name}</span>"</span>))</span><br><span class="line">        <span class="keyword">return</span> query_engine_tool</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_args</span>(<span class="params">self</span>):</span><br><span class="line">        query_engine_tools = []</span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(<span class="variable language_">self</span>.directory):</span><br><span class="line">            <span class="keyword">if</span> filename.endswith(<span class="string">".txt"</span>):</span><br><span class="line">                filepath = os.path.join(<span class="variable language_">self</span>.directory, filename)</span><br><span class="line">                documents = SimpleDirectoryReader(input_files=[filepath]).load_data()</span><br><span class="line">                tool_name = filename[:-<span class="number">4</span>]  <span class="comment"># 去除'.txt'得到工具名称</span></span><br><span class="line">                tool = <span class="variable language_">self</span>.get_tool(tool_name, tool_name, documents=documents)</span><br><span class="line">                query_engine_tools.append(tool)</span><br><span class="line">        <span class="keyword">return</span> query_engine_tools</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">query_engine</span>(<span class="params">self, query</span>):</span><br><span class="line">        <span class="keyword">from</span> llama_index.core.agent <span class="keyword">import</span> ReActAgent</span><br><span class="line">        tools = <span class="variable language_">self</span>.parse_args()</span><br><span class="line">        agent = ReActAgent.from_tools(tools, llm=<span class="variable language_">self</span>.llm, verbose=<span class="literal">True</span>, max_iterations=<span class="number">20</span>)</span><br><span class="line">        response = agent.chat(query)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Rag 实例并执行查询</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    rag = Rag()</span><br><span class="line">    <span class="built_in">print</span>(rag.query_engine(query=<span class="string">"问题"</span>))</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>





<blockquote>
<h4 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h4><p><a href="https://docs.llamaindex.ai/en/stable/examples/agent/agent_runner/agent_runner_rag_controllable/">https://docs.llamaindex.ai/en/stable/examples/agent/agent_runner/agent_runner_rag_controllable/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>llamaindex</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>自研训练大语言模型显存计算器</title>
    <url>/2024/07/24/AI/20240724_%E8%87%AA%E7%A0%94%E8%AE%AD%E7%BB%83%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E8%AE%A1%E7%AE%97%E5%99%A8/</url>
    <content><![CDATA[<p>计算全量训练一个大语言模型时，所需的算力卡显存.</p>
<p><img src="/../../img/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%98%BE%E5%AD%98%E8%AE%A1%E7%AE%97%E5%99%A8.jpg" alt="计算器界面展示"><br><code>RuntimeError: CUDA out of memory.</code></p>
<span id="more"></span>



<p><img src="https://pic4.zhimg.com/v2-5e80264a8fe8ffaf312d08a50ce103eb_r.jpg"></p>
<p><strong>图解：不同数据类型的浮点表示</strong></p>
<p>该图显示了四种不同数据类型的浮点表示：FP32、TF32、FP16 和 BFLOAT16。浮点表示是一种用于表示实数的数据格式。它由三个部分组成：</p>
<ul>
<li><strong>符号位</strong>：指示数字是正数还是负数。</li>
<li><strong>指数</strong>：指示有效数字的范围。</li>
<li><strong>尾数</strong>：指示有效数字的精确度。</li>
</ul>
<p><strong>FP32</strong></p>
<p>FP32 是最常用的浮点格式。它具有 32 位，其中：</p>
<ul>
<li>1 位符号位</li>
<li> 8 位指数</li>
<li> 23 位尾数</li>
</ul>
<p>FP32 可以表示范围为 -2^127 到 2^127 的数字，精度为 7 个小数点。</p>
<p><strong>TF32</strong></p>
<p>TF32 是一种用于 TensorFlow 的特殊浮点格式。它具有 32 位，其中：</p>
<ul>
<li>1 位符号位</li>
<li> 8 位指数</li>
<li> 10 位尾数</li>
</ul>
<p>TF32 可以表示范围为 -2^127 到 2^127 的数字，精度为 3 个小数点。</p>
<p><strong>FP16</strong></p>
<p>FP16 是一种半精度浮点格式。它具有 16 位，其中：</p>
<ul>
<li>1 位符号位</li>
<li> 5 位指数</li>
<li> 10 位尾数</li>
</ul>
<p>FP16 可以表示范围为 -2^14 到 2^14 的数字，精度为 3 个小数点。</p>
<p><strong>BFLOAT16</strong></p>
<p>BFLOAT16 是一种 Brain Floating Point 格式。它具有 16 位，其中：</p>
<ul>
<li>1 位符号位</li>
<li> 8 位指数</li>
<li> 7 位尾数</li>
</ul>
<p>BFLOAT16 可以表示范围为 -2^127 到 2^127 的数字，精度为 2 个小数点。</p>
<p><strong>比较</strong></p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>大小</th>
<th>符号位</th>
<th>指数</th>
<th>尾数</th>
<th>范围</th>
<th>精度</th>
</tr>
</thead>
<tbody><tr>
<td> FP32</td>
<td>32 位</td>
<td> 1 位</td>
<td> 8 位</td>
<td> 23 位</td>
<td> -2^127 到 2^127</td>
<td>7 个小数点</td>
</tr>
<tr>
<td> TF32</td>
<td>32 位</td>
<td> 1 位</td>
<td> 8 位</td>
<td> 10 位</td>
<td> -2^127 到 2^127</td>
<td>3 个小数点</td>
</tr>
<tr>
<td> FP16</td>
<td>16 位</td>
<td> 1 位</td>
<td> 5 位</td>
<td> 10 位</td>
<td> -2^14 到 2^14</td>
<td>3 个小数点</td>
</tr>
<tr>
<td> BFLOAT16</td>
<td>16 位</td>
<td> 1 位</td>
<td> 8 位</td>
<td> 7 位</td>
<td> -2^127 到 2^127</td>
<td>2 个小数点</td>
</tr>
</tbody></table>
<p><strong>选择数据类型</strong></p>
<p>选择哪种数据类型取决于您的具体需求。如果您需要最大的精度，请使用 FP32。如果您需要节省内存或带宽，则可以使用 FP16 或 BFLOAT16。但是，请注意，FP16 和 BFLOAT16 的精度较低，可能会导致舍入误差。</p>
<p><strong>总结</strong></p>
<p>浮点表示是一种用于表示实数的数据格式。它由三个部分组成：符号位、指数和尾数。有四种常见的数据类型：FP32、TF32、FP16 和 BFLOAT16。选择哪种数据类型取决于您的具体需求。</p>
<h2>1. 大模型参数计算公式</h2>

<table>
<thead>
<tr>
<th>n-layer</th>
<th> 模型层数</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td> d-model</td>
<td> 模型残差输出维度大小</td>
<td></td>
</tr>
<tr>
<td> d-ff</td>
<td> 前馈神经网络输出维度大小</td>
<td></td>
</tr>
<tr>
<td> d-attn</td>
<td> 注意力网络输出维度大小</td>
<td></td>
</tr>
<tr>
<td> n-heads</td>
<td> 每一层的多头注意力的数量</td>
<td></td>
</tr>
<tr>
<td> n-ctx</td>
<td> 输入的上下文长度大小</td>
<td></td>
</tr>
</tbody></table>
<h2>2. 显存占用量计算公式</h2>

<ul>
<li><p>模型参数存储</p>
<ul>
<li><p>模型参数量 : 1B 为 10 亿，例如 <code>LLaMA 7B模型有大约7 billion（即7×10^9）个参数</code></p>
</li>
<li><p>单位参数所占存储量</p>
</li>
</ul>
<figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line">  data_types = <span class="punctuation">[</span></span><br><span class="line">    (<span class="string">"FP32"</span><span class="punctuation">,</span> <span class="number">4</span>)<span class="punctuation">,</span>  # 单精度浮点数</span><br><span class="line">    (<span class="string">"FP16"</span><span class="punctuation">,</span> <span class="number">2</span>)<span class="punctuation">,</span>  # 半精度浮点数</span><br><span class="line">    (<span class="string">"BF16"</span><span class="punctuation">,</span> <span class="number">2</span>)<span class="punctuation">,</span>  # Brain Floating Point</span><br><span class="line">    (<span class="string">"FP64"</span><span class="punctuation">,</span> <span class="number">8</span>)<span class="punctuation">,</span>  # 双精度浮点数</span><br><span class="line">    (<span class="string">"INT8"</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span>  # <span class="number">8</span>位整数</span><br><span class="line">    (<span class="string">"INT16"</span><span class="punctuation">,</span> <span class="number">2</span>)<span class="punctuation">,</span>  # <span class="number">16</span>位整数</span><br><span class="line">    (<span class="string">"INT32"</span><span class="punctuation">,</span> <span class="number">4</span>)<span class="punctuation">,</span>  # <span class="number">32</span>位整数</span><br><span class="line">    (<span class="string">"INT64"</span><span class="punctuation">,</span> <span class="number">8</span>)<span class="punctuation">,</span>  # <span class="number">64</span>位整数</span><br><span class="line">    (<span class="string">"UINT8"</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span>  # <span class="number">8</span>位无符号整数</span><br><span class="line">    (<span class="string">"UINT16"</span><span class="punctuation">,</span> <span class="number">2</span>)<span class="punctuation">,</span>  # <span class="number">16</span>位无符号整数</span><br><span class="line">    (<span class="string">"UINT32"</span><span class="punctuation">,</span> <span class="number">4</span>)<span class="punctuation">,</span>  # <span class="number">32</span>位无符号整数</span><br><span class="line">    (<span class="string">"UINT64"</span><span class="punctuation">,</span> <span class="number">8</span>)<span class="punctuation">,</span>  # <span class="number">64</span>位无符号整数</span><br><span class="line">    (<span class="string">"BOOL"</span><span class="punctuation">,</span> <span class="number">1</span>)  # 布尔值</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p>计算公式 :</p>
</li>
<li><pre><code class="python">#  模型参数存储总量 = 模型参数量 * 单位参数所占存储量
</code></pre>
</li>
</ul>
</li>
<li><p>优化器状态</p>
</li>
<li><p>激活值</p>
</li>
<li><p>额外显存开销</p>
</li>
</ul>
<h3 id="相关知识链接"><a href="#相关知识链接" class="headerlink" title="相关知识链接"></a>相关知识链接</h3><ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/626867287">大模型训练策略</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2302701">人工智能大语言模型微调技术</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/644815089">LLM 结构对比</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/626553071">Sequence Parallel</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/687226668">大模型显存计算公式与优化</a></p>
</li>
<li><p><a href="https://www.youtube.com/watch?v=GGLr-TtKguA">理解 Transformer，注意力机制 (Attention)</a></p>
</li>
<li><p><a href="https://www.bilibili.com/read/cv24855760/">NVIDA GPU 卡 SXM 和 PCIe 之间的差异性</a></p>
</li>
<li><p><a href="https://llm-system-requirements.streamlit.app/">LLM Memory Requirements</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>Wps 离线插件使用方法</title>
    <url>/2024/08/06/AI/20240806_Wps%E7%A6%BB%E7%BA%BF%E6%8F%92%E4%BB%B6%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>本人自研的基于 WPS 加载项开发的智能助手.</p>
<span id="more"></span>

<ul>
<li><p>双击打开 <code>publish.html</code> 文件</p>
<p><img src="/../../img/wps.png"></p>
</li>
<li><p>双击运行 <code>set_wps.bat</code> 文件</p>
<p><img src="/../../img/wps-2.png"></p>
</li>
<li><p>打开 WPS - 文字，查看</p>
<p><img src="/../../img/wps-3.png"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Huggingface 镜像网站下载大模型及数据集</title>
    <url>/2024/08/12/AI/20240812_%E5%9F%BA%E4%BA%8EHuggingface%E9%95%9C%E5%83%8F%E7%BD%91%E7%AB%99%E4%B8%8B%E8%BD%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    <content><![CDATA[<p>使用镜像网站下载大模型及数据集，以及配置下载参数 (本地路径等)</p>
<p><img src="/../../img/huggingface-1.png"></p>
<span id="more"></span>

<h3 id="基于HF镜像网站下载大模型-数据集"><a href="#基于HF镜像网站下载大模型-数据集" class="headerlink" title="基于HF镜像网站下载大模型&amp;数据集"></a>基于 HF 镜像网站下载大模型 &amp; 数据集</h3><h4 id="命令行下载"><a href="#命令行下载" class="headerlink" title="命令行下载"></a>命令行下载</h4><ul>
<li><p>安装 Huggingface 依赖库</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>下载<strong>大模型</strong>命令</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">huggingface-cli download --resume-download meta-llama/Meta-Llama-3.1-8B-Instruct --local-dir meta-llama/Meta-Llama-3.1-8B-Instruct</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p><code>--resume-download</code> 模型的信息</p>
<p><img src="/../../img/huggingface-2.png"></p>
</li>
<li><p><code>--local-dir</code> 模型下载的路径</p>
</li>
</ul>
</li>
<li><p>下载<strong>数据集</strong>命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">huggingface-cli download --resume-download --repo-type dataset lavita/medical-qa-shared-task-v1-toy</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p><code>--resume-download --repo-type dataset</code> 数据集信息</p>
<p><img src="/../../img/huggingface-3.png"></p>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="代码下载"><a href="#代码下载" class="headerlink" title="代码下载"></a>代码下载</h4><ul>
<li><p>首先获取 Huggingface 的 Access Tokens</p>
<p><img src="/../../img/huggingface-4.png"></p>
</li>
<li><p>下载代码如下:</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"HF_ENDPOINT"</span>] = <span class="string">"https://hf-mirror.com"</span>  <span class="comment"># 设置为hf的国内镜像网站</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line"><span class="comment"># model_name = "google/mt5-large"</span></span><br><span class="line"><span class="comment"># model_name = "intfloat/multilingual-e5-large"</span></span><br><span class="line"><span class="comment"># model_name = "intfloat/e5-mistral-7b-instruct"</span></span><br><span class="line"><span class="comment"># model_name = "openai/clip-vit-large-patch14-336"</span></span><br><span class="line"><span class="comment"># model_name = "OpenGVLab/InternVL2-2B"</span></span><br><span class="line"><span class="comment"># model_name = "google/deplot"</span></span><br><span class="line"><span class="comment"># model_name = "facebook/galactica-6.7b"</span></span><br><span class="line"><span class="comment"># model_name = "OpenGVLab/InternViT-300M-448px"</span></span><br><span class="line"><span class="comment"># model_name = "OpenGVLab/InternViT-6B-448px-V1-5"</span></span><br><span class="line"><span class="comment"># model_name = "internlm/internlm2_5-7b-chat"</span></span><br><span class="line"><span class="comment"># model_name = "internlm/internlm2_5-20b-chat"</span></span><br><span class="line"><span class="comment"># model_name = "OpenGVLab/InternVL2-8B"</span></span><br><span class="line"><span class="comment"># model_name = "OpenGVLab/InternVL2-40B"</span></span><br><span class="line"><span class="comment"># model_name = "microsoft/kosmos-2.5"</span></span><br><span class="line"><span class="comment"># model_name = "meta-llama/Meta-Llama-3-8B"</span></span><br><span class="line"><span class="comment"># model_name = "llava-hf/llava-1.5-7b-hf"</span></span><br><span class="line"><span class="comment"># model_name = "llava-hf/llava-v1.6-vicuna-13b-hf"</span></span><br><span class="line"><span class="comment"># model_name = "EleutherAI/llemma_7b"</span></span><br><span class="line"><span class="comment"># model_name = "EleutherAI/llemma_34b"</span></span><br><span class="line"><span class="comment"># model_name = "meta-llama/Meta-Llama-3-70B"</span></span><br><span class="line"><span class="comment"># model_name = "meta-llama/Meta-Llama-3-8B-Instruct"</span></span><br><span class="line"><span class="comment"># model_name = "meta-llama/Meta-Llama-3-70B-Instruct"</span></span><br><span class="line"><span class="comment"># model_name = "meta-llama/Meta-Llama-3.1-70B-Instruct"</span></span><br><span class="line"><span class="comment"># model_name = "echo840/Monkey"</span></span><br><span class="line"><span class="comment"># model_name = "google/pix2struct-base"</span></span><br><span class="line"><span class="comment"># model_name = "google/pix2struct-large"</span></span><br><span class="line"><span class="comment"># model_name = "Qwen/Qwen2-7B-Instruct"</span></span><br><span class="line"><span class="comment"># model_name = "Qwen/Qwen2-72B-Instruct"</span></span><br><span class="line">model_name = <span class="string">"Qwen/Qwen-VL-Chat"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># while True 是为了防止断联</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        snapshot_download(</span><br><span class="line">            repo_id=model_name,</span><br><span class="line">            local_dir_use_symlinks=<span class="literal">True</span>,  <span class="comment"># 在local-dir指定的目录中都是一些“链接文件”</span></span><br><span class="line">            ignore_patterns=[<span class="string">"*.bin"</span>],  <span class="comment"># 忽略下载哪些文件</span></span><br><span class="line">            local_dir=model_name,</span><br><span class="line">            token=<span class="string">""</span>,   <span class="comment"># huggingface的token</span></span><br><span class="line">            resume_download=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>下载数据集代码</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"HF_ENDPOINT"</span>] = <span class="string">"https://hf-mirror.com"</span>  <span class="comment"># 设置为hf的国内镜像网站</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset = "google/matcha-chart2text-pew"</span></span><br><span class="line"><span class="comment"># dataset = "google/matcha-chart2text-statista"</span></span><br><span class="line"><span class="comment"># dataset = "huggingtweets/a2d2"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># while True 是为了防止断联s</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        snapshot_download(</span><br><span class="line">            repo_id=dataset,</span><br><span class="line">            local_dir_use_symlinks=<span class="literal">True</span>,  <span class="comment"># 在local-dir指定的目录中都是一些“链接文件”</span></span><br><span class="line">            ignore_patterns=[<span class="string">"*.bin"</span>],  <span class="comment"># 忽略下载哪些文件</span></span><br><span class="line">            local_dir=<span class="string">'Dataset/'</span>+dataset,</span><br><span class="line">            token=<span class="string">"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"</span>,   <span class="comment"># huggingface的token</span></span><br><span class="line">            resume_download=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<blockquote>
<h4 id="references"><a href="#references" class="headerlink" title="references"></a>references</h4><p><a href="https://bbs.huaweicloud.com/blogs/425588">https://bbs.huaweicloud.com/blogs/425588</a></p>
<p><a href="https://padeoe.com/huggingface-large-models-downloader/">https://padeoe.com/huggingface-large-models-downloader/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Swift 框架 Lora 微调多模态 MiniCPM-v2.6</title>
    <url>/2024/08/23/AI/20240823_%E5%9F%BA%E4%BA%8ESwift%E5%BE%AE%E8%B0%83MiniCPM-v2.6/</url>
    <content><![CDATA[<p>记录本人使用<strong>自定义数据</strong> , 从处理文本 / 图片，到构建 <strong>Train.jsonl</strong>, 最终使用 Swift<strong>Lora 微调</strong> MiniCPM-v-2.6 的全部过程.</p>
<p><img src="/../../img/minicpm-01.png"></p>
<span id="more"></span>

<h4 id="下载模型"><a href="#下载模型" class="headerlink" title="下载模型"></a>下载模型</h4><ul>
<li><p><strong>方法一 (手动下载):</strong></p>
<ul>
<li><p>模型 Huggingface 地址 : </p>
<p><a href="https://huggingface.co/openbmb/MiniCPM-V-2_6/tree/main">https://huggingface.co/openbmb/MiniCPM-V-2_6/tree/main</a></p>
</li>
</ul>
</li>
<li><p><strong> 方法二 (huggingface-cli):</strong></p>
<ul>
<li><p>安装依赖</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>运行命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">huggingface-cli download --resume-download openbmb/MiniCPM-V-2_6 --local-dir bloom-560m</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/../../img/minicpm-02.png"></p>
<blockquote>
<p>更多方法可见<a href="https://panpan02222.github.io/2024/08/12/AI/20240812_%E5%9F%BA%E4%BA%8EHuggingface%E9%95%9C%E5%83%8F%E7%BD%91%E7%AB%99%E4%B8%8B%E8%BD%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86/">基于 Huggingface 镜像网站下载大模型及数据集</a></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="安装推理-训练框架-Swift"><a href="#安装推理-训练框架-Swift" class="headerlink" title="安装推理/训练框架(Swift)"></a>安装推理 / 训练框架 (Swift)</h4><ul>
<li><p>源码安装</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/modelscope/swift.git</span><br><span class="line"><span class="built_in">cd</span> swift</span><br><span class="line">pip install -e .[llm]</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><ul>
<li><p>使用自己的数据，需要最终处理为 jsonl 格式，考虑到数据保密，在此不展示真实数据.</p>
</li>
<li><p>数据集格式可以自定义为以下几种格式 :</p>
<figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line"># 第一种方式</span><br><span class="line"><span class="punctuation">{</span><span class="attr">"query"</span><span class="punctuation">:</span>&lt;image&gt;这里是图片的描述信息<span class="punctuation">,</span><span class="attr">"response"</span><span class="punctuation">:</span><span class="string">"这里写图片的回复内容"</span><span class="punctuation">,</span><span class="attr">"images"</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">"image_path"</span><span class="punctuation">]</span><span class="punctuation">}</span></span><br><span class="line"># 第二种方式</span><br><span class="line"><span class="punctuation">{</span><span class="attr">"query"</span><span class="punctuation">:</span><span class="string">"这张图片上左上角有个猫&lt;image&gt;,这张图片上有个老虎&lt;image&gt;."</span><span class="punctuation">,</span><span class="attr">"response"</span><span class="punctuation">:</span><span class="string">"猫和老虎都是猫科动物"</span><span class="punctuation">,</span><span class="attr">"images"</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">"image_path"</span><span class="punctuation">]</span><span class="punctuation">}</span></span><br><span class="line"># 第三种方式</span><br><span class="line"><span class="punctuation">{</span><span class="attr">"query"</span><span class="punctuation">:</span><span class="string">"问题"</span><span class="punctuation">,</span> <span class="attr">"response"</span><span class="punctuation">:</span><span class="string">"回答"</span><span class="punctuation">,</span><span class="attr">"history"</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">[</span><span class="string">"query1"</span><span class="punctuation">,</span><span class="string">"response1"</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">"images"</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">"image_path"</span><span class="punctuation">]</span><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>处理为 train.jsonl 的最终截图：</p>
<p><img src="/../../img/minicpm-06.png"></p>
</li>
<li><p>详细数据集格式见:</p>
<p><a href="https://swift.readthedocs.io/zh-cn/latest/LLM/%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%8B%93%E5%B1%95.html#id3">Swift - 自定义数据集</a></p>
<p><img src="/../../img/minicpm-05.png" alt="image-20240826162613927"></p>
</li>
</ul>
<hr>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul>
<li><p>将图片以及处理后的 train.jsonl、val.jsonl 放置指定的目录下.</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">/home/miniCPM/datasets</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>源码安装 Swift</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/modelscope/swift.git</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> swift</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">pip install -e .[llm]</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>训练脚本</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 默认会将lora_target_modules设置为llm和resampler所有的linear</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 NPROC_PER_NODE=4 swift sft \</span><br><span class="line">  --model_type minicpm-v-v2_6-chat \</span><br><span class="line">  --model_id_or_path OpenBMB/MiniCPM-V-2_6 \</span><br><span class="line">  --sft_type lora \</span><br><span class="line">  --dataset train.jsonl \</span><br><span class="line">  --val_dataset val.jsonl \</span><br><span class="line">  <span class="comment"># --dataset coco-en-mini#20000 \</span></span><br><span class="line">  --deepspeed default-zero2</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><blockquote>
<p>CUDA_VISIBLE_DEVICES 算力卡数量</p>
<p>NPROC_PER_NODE 多机训练数量</p>
<p><strong>model_id_or_path, dataset, val_dataset</strong> 模型和数据集的路径</p>
</blockquote>
</li>
</ul>
</li>
<li><p>训练日志截图</p>
<p>  <img src="/../../img/minicpm-07.png" alt="image-20240827095749858"></p>
</li>
</ul>
<hr>
<h4 id="合并权重-推理"><a href="#合并权重-推理" class="headerlink" title="合并权重+推理"></a>合并权重 + 推理</h4><ul>
<li><p>运行推理命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 如果要全量测试请设置: `--show_dataset_sample -1`</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=0 swift infer \</span><br><span class="line">    --ckpt_dir output/minicpm-v-v2_6-chat/vx-xxx/checkpoint-xxx \</span><br><span class="line">    --load_dataset_config <span class="literal">true</span> --merge_lora <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure></li>
<li><blockquote>
<p>ckpt_dir 微调后的模型权重地址</p>
</blockquote>
</li>
</ul>
<hr>
<h4 id="效果演示"><a href="#效果演示" class="headerlink" title="效果演示"></a>效果演示</h4><blockquote>
<p>根据上一步合并，已经得到了新的模型权重，位置在 <code>/你的服务器地址/root/autodl-tmp/.autodl/output/minicpm-v-v2_6-chat/v0-xxx/checkpoint-xxx-merged</code></p>
</blockquote>
<ul>
<li><p>使用 <strong>Swift 的 web-ui</strong> 推理演示</p>
<ul>
<li><p>启动命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">swift web-ui</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/../../img/minicpm-10.png" alt="image-20240827141134270"></p>
</li>
<li><p>截图展示</p>
<p><img src="/../../img/minicpm-11.png" alt="image-20240827141346202"></p>
<p><img src="/../../img/minicpm-12.png" alt="image-20240827143004282"></p>
</li>
</ul>
</li>
<li><p>使用 <strong>Swift 的 cli 推理</strong>演示</p>
<ul>
<li>启动命令 </li>
</ul>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 swift infer \</span><br><span class="line">    --ckpt_dir <span class="string">"/XXX/output/minicpm-v-v2_6-chat/v0-XXX/checkpoint-XXX-merged"</span> \</span><br><span class="line">    --max_length 4096</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li><p>截图展示</p>
<p><img src="/../../img/minicpm-09.png" alt="image-20240827135738257"></p>
</li>
</ul>
</li>
<li><p>使用 <strong>MiniCPM 代码库</strong>的 <strong>web-ui</strong> 推理演示</p>
<ul>
<li><p>启动命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">python web_demo_2.6.py</span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p>需要修改代码文件中 <code>model_path</code> 为合并后的权重路径</p>
</blockquote>
</li>
<li><p>截图展示</p>
</li>
</ul>
<p><img src="/../../img/minicpm-08.png" alt="image-20240827132840559"></p>
</li>
<li><p>使用 <strong>Python 代码</strong>推理演示</p>
<ul>
<li><p>代码如下</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> load_checkpoint_and_dispatch, init_empty_weights</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> omnilmm.utils <span class="keyword">import</span> disable_torch_init</span><br><span class="line"><span class="keyword">from</span> omnilmm.model.omnilmm <span class="keyword">import</span> OmniLMMForCausalLM</span><br><span class="line"><span class="keyword">from</span> omnilmm.model.utils <span class="keyword">import</span> build_transform</span><br><span class="line"><span class="keyword">from</span> omnilmm.train.train_utils <span class="keyword">import</span> omni_preprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">img2base64</span>(<span class="params">file_name</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        encoded_string = base64.b64encode(f.read())</span><br><span class="line">        <span class="keyword">return</span> encoded_string</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MiniCPMV2_6</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_path, multi_gpus=<span class="literal">False</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'torch_version:'</span>, torch.__version__)</span><br><span class="line">        <span class="keyword">if</span> multi_gpus: <span class="comment"># inference on multi-gpus</span></span><br><span class="line">            <span class="keyword">from</span> accelerate <span class="keyword">import</span> load_checkpoint_and_dispatch, init_empty_weights, infer_auto_device_map</span><br><span class="line">            <span class="keyword">with</span> init_empty_weights():</span><br><span class="line">                model = AutoModel.from_pretrained(model_path, trust_remote_code=<span class="literal">True</span>, </span><br><span class="line">                    attn_implementation=<span class="string">'sdpa'</span>, torch_dtype=torch.bfloat16)</span><br><span class="line"></span><br><span class="line">            device_map = infer_auto_device_map(model, max_memory={<span class="number">0</span>: <span class="string">"10GB"</span>, <span class="number">1</span>: <span class="string">"10GB"</span>},</span><br><span class="line">                no_split_module_classes=[<span class="string">'SiglipVisionTransformer'</span>, <span class="string">'Qwen2DecoderLayer'</span>])</span><br><span class="line">            device_id = device_map[<span class="string">"llm.model.embed_tokens"</span>]</span><br><span class="line">            device_map[<span class="string">"llm.lm_head"</span>] = device_id <span class="comment"># first and last layer of llm should be in the same device</span></span><br><span class="line">            device_map[<span class="string">"vpm"</span>] = device_id</span><br><span class="line">            device_map[<span class="string">"resampler"</span>] = device_id</span><br><span class="line">            device_id2 = device_map[<span class="string">"llm.model.layers.26"</span>]</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.8"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.9"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.10"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.11"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.12"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.13"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.14"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.15"</span>] = device_id2</span><br><span class="line">            device_map[<span class="string">"llm.model.layers.16"</span>] = device_id2</span><br><span class="line">            <span class="built_in">print</span>(device_map)</span><br><span class="line"></span><br><span class="line">            <span class="variable language_">self</span>.model = load_checkpoint_and_dispatch(model, model_path, dtype=torch.bfloat16, device_map=device_map)</span><br><span class="line">            <span class="variable language_">self</span>.model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.model = AutoModel.from_pretrained(model_path, trust_remote_code=<span class="literal">True</span>,</span><br><span class="line">                attn_implementation=<span class="string">'sdpa'</span>, torch_dtype=torch.bfloat16)</span><br><span class="line">            <span class="variable language_">self</span>.model.<span class="built_in">eval</span>().cuda()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        image = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">"image"</span> <span class="keyword">in</span> <span class="built_in">input</span> <span class="keyword">and</span> <span class="built_in">len</span>(<span class="built_in">input</span>[<span class="string">"image"</span>]) &gt; <span class="number">10</span>: <span class="comment"># legacy API</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                image = Image.<span class="built_in">open</span>(io.BytesIO(base64.b64decode(<span class="built_in">input</span>[<span class="string">'image'</span>]))).convert(<span class="string">'RGB'</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"Image decode error"</span></span><br><span class="line"></span><br><span class="line">        msgs = json.loads(<span class="built_in">input</span>[<span class="string">"question"</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> msg <span class="keyword">in</span> msgs:</span><br><span class="line">            contents = msg.pop(<span class="string">'content'</span>) <span class="comment"># support str or List[Dict]</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(contents, <span class="built_in">str</span>):</span><br><span class="line">                contents = [contents]</span><br><span class="line">            </span><br><span class="line">            new_cnts = []</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> contents:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(c, <span class="built_in">dict</span>):</span><br><span class="line">                    <span class="keyword">if</span> c[<span class="string">'type'</span>] == <span class="string">'text'</span>:</span><br><span class="line">                        c = c[<span class="string">'pairs'</span>]</span><br><span class="line">                    <span class="keyword">elif</span> c[<span class="string">'type'</span>] == <span class="string">'image'</span>:</span><br><span class="line">                        c = Image.<span class="built_in">open</span>(io.BytesIO(base64.b64decode(c[<span class="string">"pairs"</span>]))).convert(<span class="string">'RGB'</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">raise</span> ValueError(<span class="string">"content type only support text and image."</span>)</span><br><span class="line">                new_cnts.append(c)</span><br><span class="line">            msg[<span class="string">'content'</span>] = new_cnts </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'msgs: <span class="subst">{<span class="built_in">str</span>(msgs)}</span>'</span>)</span><br><span class="line"></span><br><span class="line">        answer = <span class="variable language_">self</span>.model.chat(</span><br><span class="line">            image=image,</span><br><span class="line">            msgs=msgs,</span><br><span class="line">            tokenizer=<span class="variable language_">self</span>.tokenizer,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    model_path = <span class="string">"/XXX/output/minicpm-v-v2_6-chat/v0-XXX/checkpoint-XXX-merged"</span></span><br><span class="line">    chat_model = MiniCPMV2_6(model_path)</span><br><span class="line">    im_64 = img2base64(<span class="string">"/XXX/2.png"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># first round chat </span></span><br><span class="line">    msgs = [{<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: <span class="string">"影像所见,影像所得"</span>}]</span><br><span class="line">    <span class="built_in">input</span> = {<span class="string">"image"</span>: im_64, <span class="string">"question"</span>: json.dumps(msgs, ensure_ascii=<span class="literal">True</span>)}</span><br><span class="line">    answer = chat_model.chat(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(msgs[-<span class="number">1</span>][<span class="string">"content"</span>]+<span class="string">'\n'</span>, answer)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># second round chat </span></span><br><span class="line">    msgs.append({<span class="string">"role"</span>: <span class="string">"assistant"</span>, <span class="string">"content"</span>: answer})</span><br><span class="line">    msgs.append({<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: <span class="string">"针对这个影像,请告诉我一些建议"</span>})</span><br><span class="line">    <span class="built_in">input</span> = {<span class="string">"image"</span>: im_64,<span class="string">"question"</span>: json.dumps(msgs, ensure_ascii=<span class="literal">True</span>)}</span><br><span class="line">    answer = chat_model.chat(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(msgs[-<span class="number">1</span>][<span class="string">"content"</span>]+<span class="string">'\n'</span>, answer)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>截图展示</p>
<p><img src="/../../img/minicpm-13.png" alt="image-20240827145028445"></p>
</li>
</ul>
</li>
</ul>
<blockquote>
<h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><p><a href="https://huggingface.co/openbmb/MiniCPM-V-2_6/tree/main">MimiCPM-V-2.6_HuggingFace 地址</a></p>
<p><a href="https://github.com/modelscope/ms-swift/issues/1613">MiniiCPM 官网推荐微调最佳案例</a></p>
<p><a href="https://swift.readthedocs.io/zh-cn/latest/LLM/%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%8B%93%E5%B1%95.html#id3">Swift - 自定义数据集</a></p>
<p><a href="https://github.com/modelscope/ms-swift/blob/main/README_CN.md">SWIFT 用于微调的可扩展轻量级基础设施</a></p>
</blockquote>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MLLM</tag>
      </tags>
  </entry>
  <entry>
    <title>基准测试全流程</title>
    <url>/2024/04/18/In%20Linux/20240418_%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%85%A8%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<p>nccl 测试，p2pBandwidthLatency 测试，all_reduce_perf 测试</p>
<span id="more"></span>


<h3 id="基准测试整体事项"><a href="#基准测试整体事项" class="headerlink" title="基准测试整体事项"></a>基准测试整体事项</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="left">测试事项</th>
<th>是否已完成 (附带完成时间)</th>
<th> 验证截图</th>
</tr>
</thead>
<tbody><tr>
<td align="center"> 1</td>
<td align="left">cuda 安装</td>
<td>已完成 2024 年 4 月 17 日 16:50:06</td>
<td></td>
</tr>
<tr>
<td align="center">2</td>
<td align="left">nccl 安装</td>
<td>已完成 2024 年 4 月 17 日 15:25:25</td>
<td></td>
</tr>
<tr>
<td align="center">3</td>
<td align="left">cuda sample 拷贝</td>
<td>已完成 2024 年 4 月 17 日 15:50:11</td>
<td></td>
</tr>
<tr>
<td align="center">4</td>
<td align="left">nccl-test 拷贝</td>
<td>已完成 2024 年 4 月 17 日 15:15:31</td>
<td></td>
</tr>
<tr>
<td align="center">5</td>
<td align="left">p2pBandwidthLatency 测试</td>
<td>已完成 2024 年 4 月 17 日 16:50:17</td>
<td></td>
</tr>
<tr>
<td align="center">6</td>
<td align="left">all_reduce_perf 测试</td>
<td>已完成 2024 年 4 月 17 日 16:50:19</td>
<td></td>
</tr>
</tbody></table>
<h3 id="文件保存路径"><a href="#文件保存路径" class="headerlink" title="文件保存路径"></a>文件保存路径</h3><p><code>/home/shanghai/</code></p>
<hr>
<h3 id="所需文件下载链接"><a href="#所需文件下载链接" class="headerlink" title="所需文件下载链接"></a>所需文件下载链接</h3><p><a href="https://developer.nvidia.com/cuda-12-2-0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=CentOS&amp;target_version=7&amp;target_type=rpm_network">CUDA  12.2 下载地址</a><br><a href="https://developer.nvidia.com/nccl/nccl-download">nccl 2.21.5 下载地址</a><br><a href="https://github.com/NVIDIA/cuda-samples">cuda-sample 源码</a><br><a href="https://github.com/NVIDIA/nccl-tests">nccl-test 源码</a></p>
<hr>
<h3 id="CUDA安装"><a href="#CUDA安装" class="headerlink" title="CUDA安装:"></a>CUDA 安装:</h3><ol>
<li><p>下载 cuda</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装包升级权限</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">chmod +x cuda_12.2.0_535.54.03_linux.run</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>执行安装</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">./cuda_12.2.0_535.54.03_linux.run</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>配置环境变量</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>将 cuda 路径追写到 bashrc 后</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>更新环境变量</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>验证安装是否正常</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<h3 id="CUDA-sample-p2pBandwidthLatency测试"><a href="#CUDA-sample-p2pBandwidthLatency测试" class="headerlink" title="CUDA-sample-p2pBandwidthLatency测试"></a>CUDA-sample-p2pBandwidthLatency 测试</h3><ol>
<li><p>进入 sample 文件夹</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> Samples\5_Domain_Specific\p2pBandwidthLatencyTest</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>编译</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">make</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>执行文件，同时将结果保存到 10.10.70.9log.txt 中</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">./p2pBandwidthLatencyTest &gt;10.10.70.9log.txt</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<hr>
<h3 id="nccl安装"><a href="#nccl安装" class="headerlink" title="nccl安装"></a>nccl 安装</h3><ol>
<li><p>下载并安装 nccl 以及依赖</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">yum-config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-rhel7.repo</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">yum install libnccl-2.21.5-1+cuda12.2 libnccl-devel-2.21.5-1+cuda12.2 libnccl-        static-2.21.5-1+cuda12.2    </span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<h3 id="nccl-test-all-reduce-perf测试"><a href="#nccl-test-all-reduce-perf测试" class="headerlink" title="nccl-test-all_reduce_perf测试"></a>nccl-test-all_reduce_perf 测试</h3><ol>
<li><p>进入 nccl-test 文件夹 <code>cd nccl-tests/</code></p>
</li>
<li><p>执行编译测试，并将结果保存到 test.txt 中</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">./build/all_reduce_perf -b 8 -e 256M -f 2 -g 8 &gt;test.txt</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<hr>
<blockquote>
<p>参考链接<br><a href="https://market.cloud.baidu.com/doc/GPU/s/0kqm6s30y#gpu%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85">CUDA 安装以及 sample 测试</a><br><a href="https://cloud.tencent.com/developer/article/2361710">nccl 测试</a></p>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>nccl</tag>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>本人工作中常用的 Docker 命令</title>
    <url>/2021/01/11/In%20Linux/20220105_Docker%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>常用的 docker 命令</p>
<p><img src="/../../img/docker.png" alt="docker"></p>
<span id="more"></span>

<ul>
<li><p>加载镜像</p>
 <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker load 压缩包.</span><br><span class="line">docker load -i 压缩包 -t 镜像名称:版本号v1</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>查看所有镜像</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>启动容器</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker run -it -d --name=<span class="string">"容器名称"</span> --p</span><br><span class="line">-i:以交互模型运行容器，通常与-t同时使用;</span><br><span class="line">-d:后台运行容器，并返回容器ID</span><br><span class="line">--name=<span class="string">"容器名称"</span></span><br><span class="line">--runtime=nvidia -e NVIDIA_VISIBLE_DEVICE=1 :指定启动显卡号</span><br><span class="line">--p:指定端口映射，主机（宿主）端口：容器端口</span><br><span class="line"></span><br><span class="line">[<span class="built_in">sudo</span> docker run -it 镜像名称 /bin/bash]</span><br></pre></td></tr></tbody></table></figure>

   <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># example </span></span><br><span class="line">docker run -it -d -p 10016:9147 --name 容器名称 --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=3 镜像名称 bash</span><br></pre></td></tr></tbody></table></figure>



</li>
<li><p>查看所有容器</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></tbody></table></figure>



</li>
<li><p>启动容器</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker start</span><br></pre></td></tr></tbody></table></figure>



</li>
<li><p>进入容器</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it 容器名称 bash</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>退出容器</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>停止容器</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker stop 容器名称</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>删除容器</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker <span class="built_in">rm</span> 容器名称</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>在容器内新增文件，并创建新的镜像</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker <span class="built_in">cp</span> 本地路径/文件名称 容器名称：容器内路径</span><br><span class="line"><span class="built_in">exit</span>    <span class="comment">#退出容器</span></span><br><span class="line">docker   commit -m=<span class="string">"描述信息"</span> -a=<span class="string">"作者"</span> 容器<span class="built_in">id</span> 目标镜像名： [tags]</span><br></pre></td></tr></tbody></table></figure>

</li>
<li><p>查看容器信息</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker inspect 容器ID</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>删除镜像 #必须删除容器再删除镜像</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker rmi 镜像ID（前三位）</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>下载镜像到本地</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker save 镜像ID：版本 -o 路径/保存的镜像名称.tar</span><br></pre></td></tr></tbody></table></figure>


</li>
<li><p>改镜像名字</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker tags 旧名字 新名字</span><br></pre></td></tr></tbody></table></figure>

</li>
<li><p>改容器名词</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">docker rename 旧名字 新名字</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<p>删除 conda 环境<br>conda remove -n 环境名 –all</p>
<p>安装低版本 pip install setuptools==56.1.0</p>
<ul>
<li>查看环境<br>conda env list</li>
</ul>
<p>在 OSX/Linux 上使用 source activate my_env 进入环境<br>source activate 环境名称</p>
<p>之后操作文件即可</p>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>获取 NVIDIA 驱动问题的全流程</title>
    <url>/2024/05/23/In%20Linux/20240523_%E8%8E%B7%E5%8F%96nvidia%E9%A9%B1%E5%8A%A8%E9%97%AE%E9%A2%98%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<p>获取 NVIDIA 驱动问题的全流程</p>
<span id="more"></span>



<ul>
<li><p>在 master 机器内通过 ssh 登陆其他机器</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">ssh root@h800-机器号</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>run 收集有关 NVIDIA 显卡驱动程序问题的诊断信息的脚本</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">nvidia-bug-report.sh</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>将刚才生成的日志文件，重命名</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">mv nvidia-xx-xxx-log.gz nvidia-机器号-xx-xx-log.gz</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>新建文件夹命名为：日期 - log</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">mkdir 0601-log #0601对应日期</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>复制刚才生成的所有文件到文件夹内</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cp nvidia-机器号-xx-xx-log.gz 0601-log</span><br><span class="line">cp /var/log/sys* 0601-log    # 将sys开头的文件复制到0601-log文件夹内</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>压缩文件夹</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">tar -cvf 日期-log.tar 0601-log</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h3 id="补充命令"><a href="#补充命令" class="headerlink" title="补充命令"></a>补充命令</h3><ul>
<li><p>scp 协议传输跨机器传输文件</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">scp root@master:path /home/folder_name/</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>NVIDIA</tag>
      </tags>
  </entry>
  <entry>
    <title>批量加载 docker 镜像 &amp; 镜像重命名</title>
    <url>/2024/07/15/In%20Linux/20240711_%E6%89%B9%E9%87%8F%E5%8A%A0%E8%BD%BDdocker%E9%95%9C%E5%83%8F&amp;%E9%95%9C%E5%83%8F%E9%87%8D%E5%91%BD%E5%90%8D/</url>
    <content><![CDATA[<p>多台服务器同时批量加载 docker 镜像 + 重命名，并创建容器。</p>
<span id="more"></span>


<h2 id="1-加载镜像"><a href="#1-加载镜像" class="headerlink" title="1. 加载镜像"></a>1. 加载镜像</h2><ul>
<li><p>该脚本需把机器编号改为 <code>h800-01</code> ，<code>h800-10</code> 这种格式</p>
</li>
<li><p>单机执行命令：<code>docker load -i /mnt/hcufs/pytorch.tar</code></p>
</li>
<li><p>多机命令: </p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 1 63`;<span class="keyword">do</span> </span><br><span class="line">	ssh h800-<span class="variable">$i</span> <span class="string">"nohup docker load -i /mnt/hcufs/pytorch.tar &gt; /dev/null 2&gt;&amp;1 &amp;"</span>;</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>验证是否加载镜像</strong></p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">for i in $(cat serivce.txt); do ssh $i "docker images"</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h2 id="2-重命名镜像"><a href="#2-重命名镜像" class="headerlink" title="2. 重命名镜像"></a>2. 重命名镜像</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 此处的3f0为镜像的ID</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 60 62`;<span class="keyword">do</span> ssh h800-<span class="variable">$i</span> <span class="string">"docker tags 3f0 pytorch:1.0"</span>;<span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure>



<h2 id="3-创建容器"><a href="#3-创建容器" class="headerlink" title="3. 创建容器"></a>3. 创建容器</h2><ul>
<li><p>单机命令 <code>docker run --gpus all -it -m 500g --cap-add=SYS_PTRACE --cap-add=IPC_LOCK --shm-size 20g --network=host --name nvcr pytorch:1.0 bash</code></p>
</li>
<li><p>多机创建:</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 1 62`;<span class="keyword">do</span> ssh h800-<span class="variable">$i</span> <span class="string">"docker run --gpus all -it -m 500g --cap-add=SYS_PTRACE --cap-add=IPC_LOCK --shm-size 20g --network=host --name nvcr pytorch:1.0 bash &amp;&amp; exit"</span>;<span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<blockquote>
<p>[!TIP]</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-1.html">1. 服务器免密配置教程 - 1</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-2.html">2. 服务器免密配置教程 - 2</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/3.html">3. 服务器修改 host 和 hostname</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/4.html">4. 服务器挂载外部存储卷</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/5.html">5. 批量加载 docker 镜像 &amp; 镜像重命名</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/6.html">6. 安装 Nvidia-docker</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器批量安装 Nvidia-Docker</title>
    <url>/2024/07/15/In%20Linux/20240630_%E6%89%B9%E9%87%8F%E5%AE%89%E8%A3%85Nvidia-Docker/</url>
    <content><![CDATA[<p>多台服务器同时安装 Nvidia-docker</p>
<span id="more"></span>
<h2 id="1-单机安装命令"><a href="#1-单机安装命令" class="headerlink" title="1. 单机安装命令"></a>1. 单机安装命令</h2><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line"></span><br><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line">apt-get install -y nvidia-docker2</span><br><span class="line"></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>将以上保存到一个文件中，命名 <code>installNGC</code></li>
</ul>
<h2 id="2-批量安装脚本"><a href="#2-批量安装脚本" class="headerlink" title="2. 批量安装脚本"></a>2. 批量安装脚本</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 01 63`;<span class="keyword">do</span> ssh h800-<span class="variable">$i</span> <span class="string">"nohup /mnt/hcufs/tools/installNGC &gt; /dev/null 2&gt;&amp;1 &amp;"</span>;<span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p>这条命令是在 Linux 系统中用来在后台运行一个程序，并且防止终端会话结束时程序随之终止的常用方法。让我们逐部分解析这个命令：</p>
<ul>
<li><p><code>nohup</code>: 这是一个命令前缀，意为”no hang up”，它的作用是使进程忽略挂断信号 (SIGHUP)，这意味着即使用户退出当前终端会话，由 <code>nohup</code> 启动的进程仍然会继续运行。</p>
</li>
<li><p><code>/mnt/hcufs/tools/installNGC</code>: 这是你要执行的程序路径。<code>installNGC</code> 脚本或程序将会被运行，它位于 <code>/mnt/hcufs/tools</code> 目录下。</p>
</li>
<li><p><code>&gt; /dev/null</code>: 这是一个重定向操作，将标准输出（stdout）重定向到 <code>/dev/null</code> 设备文件。<code>/dev/null</code> 是一个特殊文件，任何写入其中的内容都会被丢弃，不会留下任何痕迹。这样做的目的是不让 <code>installNGC</code> 程序的输出显示在终端上。</p>
</li>
<li><p><code>2&gt;&amp;1</code>: 这是另一个重定向操作，将标准错误（stderr）重定向到与标准输出相同的地方。这里的意思是，如果 <code>installNGC</code> 程序产生任何错误输出，也将被重定向到 <code>/dev/null</code>，同样不会在终端上显示。</p>
</li>
<li><p><code>&amp;</code>: 这个符号放在命令末尾，表示该命令应该在后台运行。这意味着你可以立即返回到你的 shell 提示符，而不需要等待 <code>installNGC</code> 完成执行。</p>
</li>
</ul>
<p>综上所述，这条命令的意思是：在后台运行 <code>/mnt/hcufs/tools/installNGC</code> 程序，即使你关闭了终端会话，程序也会继续运行，并且所有标准输出和标准错误输出都将被丢弃，不会显示在屏幕上。这在长时间运行任务时非常有用，因为你可以安全地关闭终端窗口而不影响任务的执行。</p>
</li>
</ul>
<hr>
<blockquote>
<p>[!TIP]</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-1.html">1. 服务器免密配置教程 - 1</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-2.html">2. 服务器免密配置教程 - 2</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/3.html">3. 服务器修改 host 和 hostname</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/4.html">4. 服务器挂载外部存储卷</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/5.html">5. 批量加载 docker 镜像 &amp; 镜像重命名</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/6.html">6. 安装 Nvidia-docker</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器挂载外部存储卷</title>
    <url>/2024/07/15/In%20Linux/20240712_%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8C%82%E8%BD%BD%E5%A4%96%E9%83%A8%E5%AD%98%E5%82%A8%E5%8D%B7/</url>
    <content><![CDATA[<p>多服务器之间共享文件，需要挂载外部存储卷。从保存数据的服务器上，将共享目录挂载到其他服务器上。</p>
<!---more-->

<h2 id="1-发送key"><a href="#1-发送key" class="headerlink" title="1. 发送key"></a>1. 发送 key</h2><ul>
<li><p>该脚本需把机器编号改为 <code>h800-01</code> ，<code>h800-10</code> 这种格式</p>
</li>
<li><p>单机执行命令为:<code>scp -r /root/sec_dir ip地址:/</code></p>
</li>
<li><p>批量发送脚本为:</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 1 63`;<span class="keyword">do</span> scp -r /root/sec_dir h800-<span class="variable">$i</span>:/;<span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h2 id="2-升级key权限"><a href="#2-升级key权限" class="headerlink" title="2. 升级key权限"></a>2. 升级 key 权限</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 60 63`;<span class="keyword">do</span> ssh h800-<span class="variable">$i</span> <span class="string">"chmod 600 /sec_dir/*"</span>;<span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure>



<h2 id="3-挂载"><a href="#3-挂载" class="headerlink" title="3. 挂载"></a>3. 挂载</h2><ul>
<li><p>单机命令：<code>mount.hcufs -o skpath=/sec_dir 100.75.34.9@o2ib:100.75.34.10@o2ib:/hcufs /mnt/hcufs</code></p>
</li>
<li><p>批量挂脚本：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">seq</span> -w 1 65`;<span class="keyword">do</span> </span><br><span class="line">	ssh h800-<span class="variable">$i</span> <span class="string">"mkdir -p /mnt/hcufs;nohup mount.hcufs -o skpath=/sec_dir 100.75.34.9@o2ib:100.75.34.10@o2ib:/hcufs /mnt/hcufs &gt;/dev/null 2&gt;&amp;1 &amp;"</span>;</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<blockquote>
<p>[!TIP]</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-1.html">1. 服务器免密配置教程 - 1</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-2.html">2. 服务器免密配置教程 - 2</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/3.html">3. 服务器修改 host 和 hostname</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/4.html">4. 服务器挂载外部存储卷</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/5.html">5. 批量加载 docker 镜像 &amp; 镜像重命名</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/6.html">6. 安装 Nvidia-docker</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>多机配置 hosts 及 hostname</title>
    <url>/2024/07/15/In%20Linux/20240713_%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BF%AE%E6%94%B9host%E5%92%8Chostname/</url>
    <content><![CDATA[<p>修改 hosts 及 hostname, 使用脚本，并同步到多台服务器内.</p>
<span id="more"></span>

<h2 id="1-准备IP-txt"><a href="#1-准备IP-txt" class="headerlink" title="1. 准备IP.txt"></a>1. 准备 <code>IP.txt</code></h2><ul>
<li>把 <code>ip</code> 复制到文本内</li>
</ul>
<h2 id="2-脚本"><a href="#2-脚本" class="headerlink" title="2. 脚本"></a>2. 脚本</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ip.txt文件并将IP地址存入数组</span></span><br><span class="line">ips=()</span><br><span class="line"><span class="keyword">while</span> IFS= <span class="built_in">read</span> -r line; <span class="keyword">do</span></span><br><span class="line">    ips+=(<span class="string">"<span class="variable">$line</span>"</span>)</span><br><span class="line"><span class="keyword">done</span> &lt; ip.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历数组并执行操作</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">${!ips[@]}</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    ip=<span class="variable">${ips[$i]}</span></span><br><span class="line">    hostname=<span class="string">"h800-<span class="subst">$(printf <span class="string">"%02d"</span> $(($i+1)</span>))"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Setting up <span class="variable">$hostname</span> with IP <span class="variable">$ip</span>"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 执行SSH命令</span></span><br><span class="line">    ssh user@<span class="variable">$ip</span> <span class="string">"sudo hostnamectl set-hostname <span class="variable">$hostname</span> &amp;&amp; echo -e \"<span class="variable">$ip</span>\t<span class="variable">$hostname</span>\" | sudo tee -a /etc/hosts"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新本地hosts文件</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">"<span class="variable">$ip</span>\t<span class="variable">$hostname</span>"</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> -a /etc/hosts</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></tbody></table></figure>
<hr>
<blockquote>
<p>[!TIP]</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-1.html">1. 服务器免密配置教程 - 1</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-2.html">2. 服务器免密配置教程 - 2</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/3.html">3. 服务器修改 host 和 hostname</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/4.html">4. 服务器挂载外部存储卷</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/5.html">5. 批量加载 docker 镜像 &amp; 镜像重命名</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/6.html">6. 安装 Nvidia-docker</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 安装监控系统可视化模块</title>
    <url>/2024/07/29/In%20Linux/20240729_Ubuntu%E5%AE%89%E8%A3%85%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%8F%AF%E8%A7%86%E5%8C%96%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<p>Prometheus 是一个开放性的监控解决方案，用户可以非常方便的安装和使用 Prometheus 并且能够非常方便的对其进行扩展。为了能够更加直观的了解 Prometheus Server，接下来我们将在本地部署并运行一个 Prometheus Server 实例，通过 Node Exporter 采集当前主机的系统资源使用情况。 并通过 Grafana 创建一个简单的可视化仪表盘。</p>
<p><img src="/../../img/%E7%9B%91%E6%8E%A7-1.png" alt="image-20240729141804186"></p>
<span id="more"></span>

<blockquote>
<h4 id="Prometheus是什么？"><a href="#Prometheus是什么？" class="headerlink" title="Prometheus是什么？"></a>Prometheus 是什么？</h4><ul>
<li>Prometheus 是基于时序数据库开源监控告警系统，由 go 语言开发，很多理念和 google 的 sre 相 &gt;   符合，2016 年 5 月之后继 K8s 成为第二个正式加入 CNCF 基金会的项目，成为新一代的云原生监控 &gt;   系统。</li>
</ul>
</blockquote>
<h4 id="下载Prometheus"><a href="#下载Prometheus" class="headerlink" title="下载Prometheus"></a>下载 <code>Prometheus</code></h4><ul>
<li><a href="https://prometheus.io/download/">下载链接</a></li>
</ul>
<h4 id="安装Prometheus"><a href="#安装Prometheus" class="headerlink" title="安装Prometheus"></a>安装 Prometheus</h4><ul>
<li><p>解压</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">tar xvfz prometheus-*.tar.gz</span><br><span class="line">cd prometheus-*</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h4 id="修改Prometheus配置"><a href="#修改Prometheus配置" class="headerlink" title="修改Prometheus配置"></a>修改 Prometheus 配置</h4><ul>
<li><p>进入文件目标，并修改配置</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">vim prometheus.yml</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>将以下内容放置在配置文件内</p>
  <figure class="highlight tex"><table><tbody><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape<span class="built_in">_</span>interval:     15s <span class="params">#</span> By default, scrape targets every 15 seconds.</span><br><span class="line"></span><br><span class="line">  <span class="params">#</span> Attach these labels to any time series or alerts when communicating with</span><br><span class="line">  <span class="params">#</span> external systems (federation, remote storage, Alertmanager).</span><br><span class="line">  external<span class="built_in">_</span>labels:</span><br><span class="line">    monitor: 'codelab-monitor'</span><br><span class="line"></span><br><span class="line"><span class="params">#</span> A scrape configuration containing exactly one endpoint to scrape:</span><br><span class="line"><span class="params">#</span> Here it's Prometheus itself.</span><br><span class="line">scrape<span class="built_in">_</span>configs:</span><br><span class="line">  <span class="params">#</span> The job name is added as a label `job=&lt;job<span class="built_in">_</span>name&gt;` to any timeseries scraped from this config.</span><br><span class="line">  - job<span class="built_in">_</span>name: 'prometheus'</span><br><span class="line"></span><br><span class="line">    <span class="params">#</span> Override the global default and scrape targets from this job every 5 seconds.</span><br><span class="line">    scrape<span class="built_in">_</span>interval: 5s</span><br><span class="line"></span><br><span class="line">    static<span class="built_in">_</span>configs:</span><br><span class="line">      - targets: ['localhost:9090']</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>启动服务</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">./prometheus --config.file=prometheus.yml</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h4 id="在web浏览器查看"><a href="#在web浏览器查看" class="headerlink" title="在web浏览器查看"></a>在 web 浏览器查看</h4><ul>
<li><a href="localhost:9090">localhost:9090</a></li>
</ul>
<hr>
<blockquote>
<h4 id="Monitoring-Linux-host-metrics-with-the-Node-Exporter"><a href="#Monitoring-Linux-host-metrics-with-the-Node-Exporter" class="headerlink" title="Monitoring Linux host metrics with the Node Exporter"></a>Monitoring Linux host metrics with the Node Exporter</h4><h4 id="使用节点导出器监控-Linux-主机指标"><a href="#使用节点导出器监控-Linux-主机指标" class="headerlink" title="使用节点导出器监控 Linux 主机指标"></a>使用节点导出器监控 Linux 主机指标</h4><ul>
<li>Prometheus <a href="https://github.com/prometheus/node_exporter"><strong>Node Exporter</strong></a> 公开了 &gt; 各种与硬件和内核相关的指标。</li>
</ul>
</blockquote>
<h4 id="下载Node-Exporter"><a href="#下载Node-Exporter" class="headerlink" title="下载Node Exporter"></a>下载 Node Exporter</h4><ul>
<li><a href="https://prometheus.io/download/#node_exporter">下载地址</a></li>
</ul>
<h4 id="安装-RUN"><a href="#安装-RUN" class="headerlink" title="安装 &amp; RUN"></a>安装 &amp; RUN</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tar xvfz node_exporter-*.*-amd64.tar.gz</span><br><span class="line"><span class="built_in">cd</span> node_exporter-*.*-amd64</span><br><span class="line">./node_exporter</span><br></pre></td></tr></tbody></table></figure>

<h4 id="在web浏览器查看-1"><a href="#在web浏览器查看-1" class="headerlink" title="在web浏览器查看"></a>在 web 浏览器查看</h4><ul>
<li><a href="http://localhost:9100/">http://localhost:9100/</a></li>
</ul>
<hr>
<blockquote>
<h4 id="What-is-Grafana"><a href="#What-is-Grafana" class="headerlink" title="What is Grafana"></a>What is Grafana</h4><ul>
<li>Grafana 是一个跨平台、开源的数据可视化网络应用程序平台。用户配置连接的数据源之后，Grafana 可以在网络浏览器里显示数据图表和警告。该软件的企业版本提供更多的扩展功能。扩展功能通过插件的形式提供，终端用户可以自定义自己的数据面板界面以及数据请求方式。Grafana 被广泛使用，包括维基百科项目。</li>
<li><a href="https://grafana.com/grafana/download/10.0.0?pg=oss-graf&amp;plcmt=hero-btn-1">下载链接</a></li>
</ul>
</blockquote>
<h4 id="安装Grafana"><a href="#安装Grafana" class="headerlink" title="安装Grafana"></a>安装 Grafana</h4><h5 id="Ubuntu安装流程"><a href="#Ubuntu安装流程" class="headerlink" title="Ubuntu安装流程"></a>Ubuntu 安装流程</h5><figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 更新apt-get</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y adduser libfontconfig1 musl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载软件</span></span><br><span class="line">wget https://dl.grafana.com/enterprise/release/grafana-enterprise_10.0.0_amd64.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line"><span class="built_in">sudo</span> dpkg -i grafana-enterprise_10.0.0_amd64.deb</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><b>操作系统不是 Ubuntu 则查看上面的链接，根据自身系统进行安装</b></li>
</ul>
<h4 id="RUN-Grafana"><a href="#RUN-Grafana" class="headerlink" title="RUN Grafana"></a>RUN Grafana</h4><ul>
<li>运行 Grafana 可视化服务 </li>
</ul>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> /bin/systemctl start grafana-server</span><br></pre></td></tr></tbody></table></figure>

<h4 id="在web浏览器查看-2"><a href="#在web浏览器查看-2" class="headerlink" title="在web浏览器查看"></a>在 web 浏览器查看</h4><ul>
<li><a href="http://localhost:3000/">http://localhost:3000/</a></li>
<li> 设置流程如下:</li>
</ul>
<p><img src="/../../img/%E7%9B%91%E6%8E%A7-2.jpg" alt="step-1"></p>
<p><img src="/../../img/%E7%9B%91%E6%8E%A7-3.jpg" alt="step-2"></p>
<p><img src="/../../img/%E6%8E%A7%E5%88%B6-4.jpg" alt="step-3"></p>
<p><img src="/../../img/%E6%8E%A7%E5%88%B6-6.jpg" alt="step-4"></p>
<ul>
<li> 之后新建 <code>Dashboards</code>, 选择上面新增的 DataSrouce, 按需选择可视化的 Query 即可</li>
</ul>
<p><img src="/../../img/%E7%9B%91%E6%8E%A7-5.jpg" alt="step-5"></p>
<h4 id="导入仪表盘"><a href="#导入仪表盘" class="headerlink" title="导入仪表盘"></a>导入仪表盘</h4><p><a href="https://grafana.com/grafana/dashboards/1860-node-exporter-full/">链接</a></p>
<p><img src="/../../img/%E7%9B%91%E6%8E%A7-7.jpg"></p>
<p><a href="https://grafana.com/grafana/dashboards/9276-1-cpu/">链接</a></p>
<p><img src="/../../img/%E7%9B%91%E6%8E%A7-8.jpg"></p>
<blockquote>
<h4 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h4><p><a href="https://blog.csdn.net/qq_43437874/article/details/120355246">https://blog.csdn.net/qq_43437874/article/details/120355246</a></p>
<p><a href="https://www.cnblogs.com/ceshi2016/p/17265925.html">https://www.cnblogs.com/ceshi2016/p/17265925.html</a></p>
<p><a href="https://prometheus.wang/quickstart/prometheus-quick-start.html">https://prometheus.wang/quickstart/prometheus-quick-start.html</a></p>
</blockquote>
<h6 id="拓展代码"><a href="#拓展代码" class="headerlink" title="拓展代码"></a>拓展代码</h6><ul>
<li>安装 Prometheus</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line"><span class="built_in">export</span> VERSION=2.13.0</span><br><span class="line">curl -LO  https://github.com/prometheus/prometheus/releases/download/v<span class="variable">$VERSION</span>/prometheus-<span class="variable">$VERSION</span>.darwin-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -xzf prometheus-<span class="variable">${VERSION}</span>.darwin-amd64.tar.gz</span><br><span class="line"><span class="built_in">cd</span> prometheus-<span class="variable">${VERSION}</span>.darwin-amd64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置promethes.yml</span></span><br><span class="line">vim promethes.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line">./prometheus</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>安装 Node Exporter</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">curl -OL https://github.com/prometheus/node_exporter/releases/download/v0.17.0/node_exporter-0.17.0.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -xzf node_exporter-0.17.0.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 node_exporter 工具安装到系统中，使其可以被全局访问和使用。</span></span><br><span class="line"><span class="built_in">cd</span> node_exporter-0.17.0.linux-amd64/</span><br><span class="line"><span class="built_in">mv</span> node_exporter /usr/local/bin/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line">service node_exporter start</span><br></pre></td></tr></tbody></table></figure>

]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>Linux</tag>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>在线安装 docker&amp;nvidia-docker</title>
    <url>/2024/08/06/In%20Linux/20240806_docker&amp;nvidia-docker%E5%9C%A8%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>记录单机在线安装 docker 及英伟达 docker 的操作，只保留操作命令。选择自适应的操作系统，逐行执行即可.</p>
<span id="more"></span>

<h2 id="Ubuntu系统安装Docker"><a href="#Ubuntu系统安装Docker" class="headerlink" title="Ubuntu系统安装Docker"></a>Ubuntu 系统安装 Docker</h2><ul>
<li><p>更新 apt 包</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt update</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装依赖包</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install apt-transport-https ca-certificates curl gnupg2 software-properties-common</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>添加阿里云的 GPG 密钥</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | <span class="built_in">sudo</span> apt-key add -</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>添加 Docker 源</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> add-apt-repository <span class="string">"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu</span></span><br><span class="line"><span class="string"><span class="subst">$(lsb_release -cs)</span> stable"</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 Docker</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">apt-get install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>设置开机自动启动</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<h2 id="Ubuntu系统安装Nvidia-Docker2"><a href="#Ubuntu系统安装Nvidia-Docker2" class="headerlink" title="Ubuntu系统安装Nvidia-Docker2"></a>Ubuntu 系统安装 Nvidia-Docker2</h2><ul>
<li><p>设置 Stable 存储库和密钥</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;<span class="built_in">echo</span> $ID<span class="variable">$VERSION_ID</span>) \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | <span class="built_in">sudo</span> apt-key add - \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | <span class="built_in">sudo</span> <span class="built_in">tee</span></span><br><span class="line">/etc/apt/sources.list.d/nvidia-docker.list</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 Nvidia-docker2 安装包</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get update</span><br></pre></td></tr></tbody></table></figure>

  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install -y nvidia-docker2</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>重启 Docker</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl restart docker</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<h2 id="CentOS系统安装Docker"><a href="#CentOS系统安装Docker" class="headerlink" title="CentOS系统安装Docker"></a>CentOS 系统安装 Docker</h2><ul>
<li><p>添加 yum 源</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">yum install epel-release -y</span><br></pre></td></tr></tbody></table></figure>

  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">yum clean all</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 yum-util</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install -y yum-utils device-mapper-persistent-data lvm2</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>设置 Docker yum 源</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装并运行 Docker</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install docker-ce</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<h2 id="CentOS系统安装Nvidia-Docker"><a href="#CentOS系统安装Nvidia-Docker" class="headerlink" title="CentOS系统安装Nvidia-Docker"></a>CentOS 系统安装 Nvidia-Docker</h2><ul>
<li><p>设置 stable 存储库和密钥</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;<span class="built_in">echo</span> $ID<span class="variable">$VERSION_ID</span>) \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.repo | <span class="built_in">sudo</span> <span class="built_in">tee</span></span><br><span class="line">/etc/yum.repos.d/nvidia-docker.repo</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">DIST=$(sed -n <span class="string">'s/releasever=//p'</span> /etc/yum.conf)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">DIST=<span class="variable">${DIST:-$(. /etc/os-release; echo $VERSION_ID)}</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>安装 Nvidia-Docker2 安装包</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum makecache</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install nvidia-docker2</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>重启 Docker</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl restart docker</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>VMware 内配置共享文件夹</title>
    <url>/2024/07/29/In%20Linux/20240729_VMware%E5%86%85%E9%85%8D%E7%BD%AE%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/</url>
    <content><![CDATA[<p><img src="/../../img/VMware-1.png" alt="image-20240729144342715"></p>
<p>VMware 设置共享文件夹，改过一次然后文件夹消失了。很奇怪.</p>
<span id="more"></span>

<h4 id="安装VMware-Tools"><a href="#安装VMware-Tools" class="headerlink" title="安装VMware Tools"></a>安装 VMware Tools</h4><ul>
<li>找到<strong>虚拟机</strong> - <strong>重新安装 VMware Tools</strong> | <em>如果是灰色就执行下一步</em></li>
<li>重启虚拟机</li>
<li>重启的过程中，不停的查看<strong>重新安装 VMware Tools</strong></li>
<li> 当能点击时，点击安装即可</li>
</ul>
<h4 id="配置共享文件夹"><a href="#配置共享文件夹" class="headerlink" title="配置共享文件夹"></a>配置共享文件夹</h4><ul>
<li><p>点击<strong>虚拟机设置</strong></p>
</li>
<li><p>找到<strong>选项</strong></p>
<p><img src="/../../img/vmware-2.jpg"></p>
</li>
<li><p>选<strong>共享文件夹</strong> , 按图内进行配置</p>
</li>
</ul>
<h4 id="查看共享文件夹"><a href="#查看共享文件夹" class="headerlink" title="查看共享文件夹"></a>查看共享文件夹</h4><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cd /mnt/hgfs</span><br><span class="line">ls</span><br></pre></td></tr></tbody></table></figure>



<blockquote>
<p>[!CAUTION]</p>
<p>当执行完后，如果没有看见自己的共享文件夹，执行以下命令</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">如果输出文件夹的名称, 快执行下一步, 如果这个啥都没输出, 我没治了.</span><br><span class="line">vmhgfs-fuse /mnt/hgfs</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">sudo mount -t fuse.vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other</span><br></pre></td></tr></tbody></table></figure>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>-Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>离线安装 docker&amp;nvidia-docker</title>
    <url>/2024/08/05/In%20Linux/20240815_docker&amp;nvidia-docker%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><img src="/../../img/docker-5.jpg"></p>
<p>记录离线安装 Nvidia-Docker 流程手册，2024 年 8 月 5 日 20:48:35.</p>
<span id="more"></span>

<h1 id="Docker-Nvidia-docker离线安装安装"><a href="#Docker-Nvidia-docker离线安装安装" class="headerlink" title="Docker&amp;Nvidia-docker离线安装安装"></a>Docker&amp;Nvidia-docker 离线安装安装</h1><h3 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker 安装</h3><p><a href="https://blog.csdn.net/chexlong/article/details/127932711">离线安装 docker</a></p>
<hr>
<h3 id="nvidia-docker-安装"><a href="#nvidia-docker-安装" class="headerlink" title="nvidia-docker 安装"></a>nvidia-docker 安装</h3><h4 id="1-下载docker执行文件"><a href="#1-下载docker执行文件" class="headerlink" title="1. 下载docker执行文件"></a>1. 下载 docker 执行文件</h4><ul>
<li>点击以下的<code>下载链接</code>进行下载</li>
</ul>
<p>​	<a href="https://download.docker.com/linux/static/stable/">下载链接</a></p>
<ul>
<li> x86_64 目录中的 Docker 可执行文件，适用于大多数使用 GPU 的服务器<br><em>第一步</em><br><img src="/../../img/docker-1.png" alt="step1"><br><em>第二步</em><br><img src="/../../img/docker-3.png" alt="step2"></li>
</ul>
<h4 id="2-下载离线安装脚本"><a href="#2-下载离线安装脚本" class="headerlink" title="2.  下载离线安装脚本"></a>2.  下载离线安装脚本</h4><ul>
<li>点击以下的<code>下载链接</code>进行下载<br><a href="https://github.com/Jrohy/docker-install/">下载链接</a></li>
</ul>
<p><img src="/../../img/docker-2.png"></p>
<ul>
<li><p>执行命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">./install.sh -f /root/docker-18.09.6.tgz</span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p><strong>把后面的 tgz 包换成自己的刚才下载 docker 离线版本</strong></p>
</blockquote>
</li>
<li><p>下载<strong>对应当前系统</strong>的依赖包，<strong>共需下载 6 个文件</strong></p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 查看当前系统版本, 如果是ubuntu系统则下载deb文件,如果是centos7则下载rpm文件</span></span><br><span class="line"><span class="built_in">cat</span> /etc/os-release</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<p>​	<a href="https://github.com/NVIDIA/libnvidia-container/tree/gh-pages/stable/rpm">rpm 下载链接</a></p>
<p>​	<a href="https://github.com/NVIDIA/libnvidia-container/tree/gh-pages/stable/deb">deb 下载链接</a></p>
<pre><code># 第1个文件
https://github.com/NVIDIA/libnvidia-container/blob/gh-pages/stable/deb/amd64/libnvidia-container-dev_1.16.1-1_amd64.deb

# 第2个文件
https://github.com/NVIDIA/libnvidia-container/blob/gh-pages/stable/deb/amd64/libnvidia-container-tools_1.16.1-1_amd64.deb

# 第3个文件
https://github.com/NVIDIA/libnvidia-container/blob/gh-pages/stable/deb/amd64/libnvidia-container1-dbg_1.16.1-1_amd64.deb

# 第4个文件
https://github.com/NVIDIA/libnvidia-container/blob/gh-pages/stable/deb/amd64/libnvidia-container1_1.16.1-1_amd64.deb

# 第5个文件
https://github.com/NVIDIA/libnvidia-container/blob/gh-pages/stable/deb/amd64/nvidia-container-toolkit_1.16.1-1_amd64.deb

# 第6个文件
https://github.com/NVIDIA/libnvidia-container/blob/gh-pages/stable/deb/amd64/nvidia-container-runtime_3.14.0-1_all.deb
</code></pre>
<p><img src="/../../img/docker-4.png"></p>
<ul>
<li><p>将下载的文件放在一个文件夹下，运行命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 如果是rpm包执行rpm安装</span></span><br><span class="line"><span class="built_in">sudo</span> rpm -Uvh *.rpm --nodeps --force</span><br><span class="line"><span class="comment"># 如果是deb包执行dpkg安装</span></span><br><span class="line"><span class="built_in">sudo</span> dpkg -i *.deb</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h4 id="3-运行docker"><a href="#3-运行docker" class="headerlink" title="3.  运行docker"></a>3.  运行 docker</h4> <figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">sudo systemctl start docker</span><br></pre></td></tr></tbody></table></figure>
<h4 id="4-开机自启动docker服务"><a href="#4-开机自启动docker服务" class="headerlink" title="4. 开机自启动docker服务"></a>4. 开机自启动 docker 服务</h4><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">sudo systemctl enable docker</span><br></pre></td></tr></tbody></table></figure>

<hr>
<blockquote>
<h4 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h4><p><a href="https://blog.csdn.net/Anbi97/article/details/127428249">离线安装 nvidia-docker-1</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/397638816">离线安装 nvidia-docker-2</a></p>
</blockquote>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter Notebook 快捷指令</title>
    <url>/2021/01/15/In%20Linux/Jupyter%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4/</url>
    <content><![CDATA[<p>以下是 Jupyter Notebook 的一些常用快捷操作：</p>
<span id="more"></span>


<h3 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h3><ul>
<li><p>在 Jupyter Notebook 中按下 Esc 键即进入命令模式，此时单元格外侧边框变为蓝色。</p>
<ul>
<li>A：在当前单元格上方添加一个新单元格。</li>
<li>B：在当前单元格下方添加一个新单元格。</li>
<li>DD：删除当前单元格。</li>
<li>M：将当前单元格切换为 Markdown 模式。</li>
<li>Y：将当前单元格切换为代码模式。</li>
<li>1 ~ 6：将当前 Markdown 单元格变为对应的标题（# ~ ######）。</li>
<li>H：显示所有快捷键。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="编辑模式"><a href="#编辑模式" class="headerlink" title="编辑模式"></a>编辑模式</h3><ul>
<li><p>在 Jupyter Notebook 中按下 Enter 键，即进入编辑模式，此时单元格外侧边框变为绿色。</p>
<ul>
<li><p>Ctrl + Enter：运行当前单元格，并选中下面的单元格。若是最后一个单元格则不选中。</p>
</li>
<li><p>Shift + Enter：运行当前单元格，并选中下面的单元格。若是最后一个单元格，则新建一个单元格并选中该单元格。</p>
</li>
<li><p>Alt + Enter：运行当前单元格，并在下面插入一个新单元格，并选中该单元格。</p>
</li>
<li><p>Ctrl + /：注释或取消注释当前行或选中区域。</p>
</li>
<li><p>Shift + Tab：显示函数或类的参数和文档字符串。重复按下时，分别显示更多信息。</p>
</li>
<li><p>Ctrl + Shift + -：在光标所在行下方分割单元格。<br>Ctrl + Shift + +：在光标所在行上方分割单元格。</p>
</li>
</ul>
</li>
<li><p>以上仅是一些常用的快捷键，你也可以在 Jupyter Notebook 的 Help -&gt; Keyboard Shortcuts 中看到完整的快捷键列表，你也可以自定义快捷键的方式来使得自己更舒适使用。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Jupyter Notebook</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s 常用命令</title>
    <url>/2024/07/17/In%20Linux/Kubenets%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>本人工作中使用 k8s，记录一下常用的命令。</p>
<span id="more"></span>


<ul>
<li><p>重启运行在节点上的 <code>kubelet</code> 服务</p>
  <figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">systemctl restart  kubelet</span><br></pre></td></tr></tbody></table></figure>

</li>
<li><p>查看容器内日志</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl logs pod名称 容器名称 -n 命名空间</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>查看控制器</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl get deployments.apps -n 命名空间</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>删除控制器</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl delete deployments.apps pod名称  -n 命名空间</span><br></pre></td></tr></tbody></table></figure>

</li>
<li><p>查看所有镜像</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl get pods -A</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>进入容器</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it BML副本名称(服务名) bash -n 对应的存储源(上调命令查的)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>删除 pods</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl delete pod BML副本名称 -n 对应的存储元 bash</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>从 pod 中复制文件到本地服务器上</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">cp</span> -n 存储源 服务名：路径 本地路径</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>查看 pod 详细信息</p>
  <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">kubectl describe pod pod-name</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>局域网远程桌面</title>
    <url>/2021/01/14/Config/20210114_%E5%B1%80%E5%9F%9F%E7%BD%91%E9%93%BE%E6%8E%A5/</url>
    <content><![CDATA[<p>内网远程桌面连接方法</p>
<span id="more"></span>


<h4 id="依次执行以下命令："><a href="#依次执行以下命令：" class="headerlink" title="依次执行以下命令："></a>依次执行以下命令：</h4><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">win+r</span><br><span class="line"></span><br><span class="line">mstsc</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入需要链接的主机ip</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查询win+r--&gt;"cmd"--&gt;"ipconfig"</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 快捷指令</title>
    <url>/2024/07/17/In%20Linux/Linux%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4/</url>
    <content><![CDATA[<p>本人工作时常用到的一些 linux 快捷指令，希望对大家有所帮助。</p>
<span id="more"></span>

<ul>
<li><p>查看正在运行的 python 脚本<br>  <code>ps -ef |grep python</code></p>
<p>  <code>ps aux | grep python</code></p>
</li>
<li><p>查看当前目录下的文件占用内存</p>
<p>  <code>du -sh</code></p>
</li>
<li><p>查看文件系统磁盘占用情况</p>
<p>  <code>df -h $home</code></p>
</li>
<li><p>计算文件数</p>
<p>  <code>ls | wc -l</code></p>
</li>
<li><p>查看当前文件夹下每个文件的大小</p>
<p>  <code>ls -lh</code></p>
</li>
<li><p>暂停进程 18000 秒</p>
<p>  <code>sh -c | sleep 18000</code></p>
</li>
<li><p>显示物理地址<br>  <code>overlay </code></p>
</li>
</ul>
<hr>
<h4 id="tar"><a href="#tar" class="headerlink" title="tar"></a>tar</h4><ul>
<li><p><strong>解压</strong> tar.gz file</p>
<p>  <code>tar -zxvf folder.tar.gz folder</code></p>
</li>
<li><p><strong>解压</strong> tar file</p>
<p>  <code>tar -xvf folder.tar</code></p>
</li>
</ul>
<h4 id="unrar"><a href="#unrar" class="headerlink" title="unrar"></a>unrar</h4><ul>
<li><p>解压 rar file</p>
<p>  <code>unrar x example.rar</code></p>
</li>
</ul>
<h4 id="unzip"><a href="#unzip" class="headerlink" title="unzip"></a>unzip</h4><ul>
<li><p><strong>解压</strong> zip file</p>
<p><code>unzip -l example.zip</code></p>
</li>
</ul>
<hr>
<h4 id="远程操作"><a href="#远程操作" class="headerlink" title="远程操作"></a>远程操作</h4><ul>
<li><p>远程发送文件<br><code>scp folder_path root@ip:folder_path</code></p>
</li>
<li><p>远程链接服务器<br><code>ssh username@remote_server_ip</code></p>
</li>
</ul>
<hr>
<h4 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h4><ul>
<li>手动挂载 U 盘 <figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">mkdir /mnt/usb 			#新建文件夹</span><br><span class="line">fdisk -l			#查看u盘名称</span><br><span class="line">mount /dev/sdb1 /mnt/usb	#将u盘挂载到文件夹</span><br><span class="line">umount /mnt/usb			#使用完，退出挂载</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<hr>
<ul>
<li>批量安装 rpm 包<br><code>rpm -ivh *.rpm</code></li>
</ul>
<hr>
<h4 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h4><ul>
<li><p>将日志输入到 log 中<br><code>nohup python main.py &gt;log.log 2&gt;&amp;1 &amp;</code></p>
</li>
<li><p>查看日志<br><code>tail -f log.log</code></p>
</li>
</ul>
<hr>
<h4 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h4><ul>
<li>建立软链接<br>ln  -s   [源文件]   [软链接文件]</li>
</ul>
<hr>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><ul>
<li><p>排查 ip 后缀</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">curl `kubectl get svc -n bfe| fgrep ilb-controller | awk <span class="string">'{print $3}'</span>`:8086/v1/third-party/integration/bml/services?content=config  -H  <span class="string">"Authorization:Token H9zUjETTd3oajBaCJdoYNiynzfEs"</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>删垃圾</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">curl -X DELETE http://`kubectl get svc -n bfe|fgrep ilb-controller | awk <span class="string">'{print $3}'</span>`:8086/v1/third-party/integration/bml/asi-v8874znn6ph51iiu -H  <span class="string">"Authorization:Token H9zUjETTd3oajBaCJdoYNiynzfEs"</span></span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h4 id="GPT写的"><a href="#GPT写的" class="headerlink" title="GPT写的"></a>GPT 写的</h4><ul>
<li>Shell 是一种特别的交互式命令行接口，常见的有 Bash（Linux、MacOS）和 Command Prompt（Windows），以下是一些常用的 Bash Shell 操作命令：</li>
</ul>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">pwd：打印当前工作目录。</span><br><span class="line">ls：列出当前目录下的所有文件和文件夹（不包括以.开头的隐藏文件）。</span><br><span class="line">cd：进入指定目录，如 “cd /usr/local”。</span><br><span class="line">mkdir：新建一个目录，如 “mkdir dir_name”。</span><br><span class="line">touch：新建一个空文件，如 “touch file_name”。</span><br><span class="line">cp：复制文件或目录，如 “cp file1 file2”。</span><br><span class="line">mv：移动文件或目录，如 “mv file1 file2”。</span><br><span class="line">rm：删除文件或目录，如 “rm file_name” 或者 “rm -r dir_name”。</span><br><span class="line">cat：查看文件内容，如 “cat file_name”。</span><br><span class="line">grep：在文件中查找指定的文本，如 “grep ‘some text’ file_name”。</span><br><span class="line">top：查看进程信息。</span><br><span class="line">ps：列出系统中当前运行的进程信息。</span><br><span class="line">kill：结束一个进程，如 “kill PID” 或者 “killall process_name”。</span><br><span class="line">history：查看历史命令记录，如 “history”。</span><br><span class="line">chmod：修改文件或者目录的权限，如 “chmod 777 file_name”。</span><br><span class="line">df：查看磁盘空间的使用情况，如 “df -h”。</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>以上只是 Shell 命令中的一些常用的操作，Bash Shell 还支持大量的其他命令和操作，可以通过 man 命令查看命令的 manual 手册来了解更多细节信息和使用方法。</li>
</ul>
]]></content>
      <categories>
        <category>In Linux</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>修改远程桌面端口步骤</title>
    <url>/2021/01/11/Config/20220122_%E4%BF%AE%E6%94%B9%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E7%AB%AF%E5%8F%A3%E6%AD%A5%E9%AA%A4/</url>
    <content><![CDATA[<p>为 mstsc.exe 的端口修改</p>
<span id="more"></span>


<ol>
<li><p>注册表  修改 HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp    PortNumber 为 xxxx</p>
</li>
<li><p>windows 防火墙 - 高级设置 - 入站规 加上 xxxx 端口</p>
</li>
<li><p>我的电脑 - 管理 - 服务和应用程序 - 服务  启动 Remote Desktop 开头的 3 或 4 个服务</p>
</li>
<li><p>我的电脑 - 属性 - 高级系统设置 - 远程  勾选’允许运行任意版本…’</p>
</li>
<li><p>重启电脑</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title>配置 Anaconda3 的 conda 源</title>
    <url>/2024/04/25/Config/20240425_%E9%85%8D%E7%BD%AEAnaconda3%E7%9A%84conda%E6%BA%90/</url>
    <content><![CDATA[<h3 id="配置Anaconda3"><a href="#配置Anaconda3" class="headerlink" title="配置Anaconda3"></a><b>配置 Anaconda3<br></b></h3><span id="more"></span><b>

<h3 id="修改DNS配置文件-etc-resolv-conf"><a href="#修改DNS配置文件-etc-resolv-conf" class="headerlink" title="修改DNS配置文件 /etc/resolv.conf"></a>修改 DNS 配置文件 /etc/resolv.conf</h3><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cat /etc/resolv.conf </span><br><span class="line">search 608192-8443020096138588160.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">nameserver 100.123.37.248</span><br><span class="line">nameserver 114.114.114.114</span><br><span class="line">options ndots:5</span><br></pre></td></tr></tbody></table></figure>
<h4 id="修改为："><a href="#修改为：" class="headerlink" title="修改为："></a>修改为：</h4><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">search 608192-8443020096138588160.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line"># nameserver 100.123.37.248 # 注释掉原有内容</span><br><span class="line">nameserver 114.114.114.114</span><br><span class="line">options ndots:5</span><br></pre></td></tr></tbody></table></figure>

<h3 id="修改hosts文件-etc-hosts"><a href="#修改hosts文件-etc-hosts" class="headerlink" title="修改hosts文件 /etc/hosts"></a>修改 hosts 文件 /etc/hosts</h3><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cat /etc/hosts</span><br><span class="line"># Kubernetes-managed hosts file.</span><br><span class="line">127.0.0.1       localhost</span><br><span class="line">::1     localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0 ip6-localnet</span><br><span class="line">fe00::0 ip6-mcastprefix</span><br><span class="line">fe00::1 ip6-allnodes</span><br><span class="line">fe00::2 ip6-allrouters</span><br><span class="line">100.124.49.167  nb-510725983817446230-0</span><br><span class="line"></span><br><span class="line"># Entries added by HostAliases.</span><br><span class="line">100.123.232.241 kubernetes      kubernetes.default      kubernetes.default.svc</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="修改为"><a href="#修改为" class="headerlink" title="修改为:"></a>修改为:</h4><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cat /etc/hosts</span><br><span class="line"># Kubernetes-managed hosts file.</span><br><span class="line">127.0.0.1       localhost</span><br><span class="line">::1     localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0 ip6-localnet</span><br><span class="line">fe00::0 ip6-mcastprefix</span><br><span class="line">fe00::1 ip6-allnodes</span><br><span class="line">fe00::2 ip6-allrouters</span><br><span class="line">100.124.49.167  nb-510725983817446230-0</span><br><span class="line"></span><br><span class="line"># Entries added by HostAliases.</span><br><span class="line">100.123.232.241 kubernetes      kubernetes.default      kubernetes.default.svc</span><br><span class="line">101.6.15.130  mirrors.tuna.tsinghua.edu.cn</span><br></pre></td></tr></tbody></table></figure>

<h3 id="配置conda源为清华源"><a href="#配置conda源为清华源" class="headerlink" title="配置conda源为清华源"></a>配置 conda 源为清华源</h3><ol>
<li>查看 conda 配置文件的位置：<code>whereis conda</code></li>
<li>编辑配置文件：<code>vim /root/.condarc</code></li>
<li>将配置文件中的内容替换为：<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/</span><br></pre></td></tr></tbody></table></figure></li>
<li>运行 <code>conda clean -i </code>清除索引缓存</li>
<li>创建新环境 <code>conda create -n myenv python==3.10</code> 验证 conda 源是否配置成功</li>
</ol>
</b>]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title>Proxychains install</title>
    <url>/2022/07/17/Config/20220707_Proxychains%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>Proxychains 是一款基于 Linux 系统的网络代理工具，在服务器内安装 proxychains，并配置 socks5 代理。</p>
<span id="more"></span>


<ul>
<li><p>解压源码 <code>tar zxvf proxychains-ng-x.xx.tar.gz</code></p>
</li>
<li><p>进入解压后的目录，执行 <code>./configure</code></p>
</li>
<li><p>安装软件执行 <code>make</code>,<code>make intsall </code></p>
</li>
<li><p>修改代理服务器 (xxx 为你的代理服务器地址)</p>
</li>
</ul>
<blockquote>
<p> cd /usr/local/etc/proxychains.conf<br> 打开配置文件，添加以下内容：<br> 最后一行处修改 <b> socks5 xxxxxx </b></p>
</blockquote>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>配置 VNC 教程</title>
    <url>/2024/07/17/Config/20240618_%E9%85%8D%E7%BD%AEVNC%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>使用两台 windows 电脑进行远程控制，配置 VNC 的详细教程.</p>
<p>VNC（Virtual Network Computing），为一种使用 RFB 协议的屏幕画面分享及远程操作软件。此软件借由网络，可发送键盘与鼠标的动作及即时的屏幕画面。</p>
<p>VNC 与操作系统无关，因此可跨平台使用，例如可用 Windows 连线到某 Linux 的电脑，反之亦同。甚至在没有安装客户端程序的电脑中，只要有支持 JAVA 的浏览器，也可使用。</p>
<span id="more"></span>

<ol>
<li><h2 id="两台-windows电脑内下载并安装"><a href="#两台-windows电脑内下载并安装" class="headerlink" title="两台 windows电脑内下载并安装"></a><strong>两台</strong> windows 电脑内下载并安装</h2><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">TightVNC官网地址</span><br><span class="line">https://www.tightvnc.com/download.php</span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<img title="" src="file:///C:/Users/24529/AppData/Roaming/marktext/images/2024-06-18-09-26-43-1718673923532.jpg" alt="" width="563" data-align="center">

<hr>
<ol start="2">
<li><h2 id="TightVNC-服务端-被连接端-配置"><a href="#TightVNC-服务端-被连接端-配置" class="headerlink" title="TightVNC 服务端(被连接端) 配置"></a>TightVNC <strong>服务端</strong> (被连接端) 配置</h2><ul>
<li><p>默认端口号 5900</p>
</li>
<li><p>注意自己设置连接密码</p>
<img title="" src="file:///C:/Users/24529/AppData/Roaming/marktext/images/2024-06-18-09-36-02-image.png" alt="" width="337" data-align="left">

<p><strong>如果找不到配置界面，在任务栏右下角图标内右键 或点击 ‘开始菜单’-‘所有应用’-‘TightVNC’-‘Run TightVNC Service’</strong></p>
<hr>
</li>
</ul>
</li>
<li><h2 id="TightVNC-客户端-连接端-配置"><a href="#TightVNC-客户端-连接端-配置" class="headerlink" title="TightVNC 客户端(连接端) 配置"></a>TightVNC <strong>客户端</strong> (连接端) 配置</h2><ul>
<li>进入方式：开始菜单 - 所有应用 - TightVNC-TightVNC Viewer</li>
</ul>
<img title="" src="file:///C:/Users/24529/AppData/Roaming/marktext/images/2024-06-18-09-48-42-image.png" alt="" width="341" data-align="left">

<ul>
<li><p> 输入服务器的 <strong>ip 地址</strong>和<strong>端口</strong> , 并连接</p>
<img title="" src="file:///C:/Users/24529/AppData/Roaming/marktext/images/2024-06-18-09-57-49-image.png" alt="" width="412"></li>
</ul>
</li>
</ol>
<blockquote>
<p> <a href="https://cloud.baidu.com/article/3002603">参考博客 - 1</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.xuejiu123.com/253.html">参考博客 - 2</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器免密配置教程 - 1</title>
    <url>/2024/07/15/Config/20240701_%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%8D%E5%AF%86%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B-1/</url>
    <content><![CDATA[<p>工作时解决服务器免密登录问题，记录一下解决过程。</p>
<p><img src="/../../img/image-20240710103927738.png" alt="show ip"></p>
<span id="more"></span>

<blockquote>
<p>[!NOTE]</p>
<p>该手册一共 2 个版本，此文档为第一版。</p>
</blockquote>
<h2 id="1-获取密钥"><a href="#1-获取密钥" class="headerlink" title="1. 获取密钥"></a>1. 获取密钥</h2>   <figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -f /root/.ssh/rsa</span><br></pre></td></tr></tbody></table></figure>

<h2 id="2-验证"><a href="#2-验证" class="headerlink" title="2. 验证"></a>2. 验证</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> id_rsa.pub authorized_keys</span><br><span class="line"><span class="comment"># authorized_keys是用于 SSH 服务器验证远程用户身份</span></span><br></pre></td></tr></tbody></table></figure>



<h2 id="3-配置StrictHostKeyChecking"><a href="#3-配置StrictHostKeyChecking" class="headerlink" title="3. 配置StrictHostKeyChecking"></a>3. 配置 <code>StrictHostKeyChecking</code></h2><ul>
<li>创建 config 文件 <code>vim config</code></li>
</ul>
<figure class="highlight tex"><table><tbody><tr><td class="code"><pre><span class="line">StrictHostKeyChecking no</span><br><span class="line"><span class="params">#</span> 设置 StrictHostKeyChecking no 意味着SSH客户端在连接到远程主机时不会检查该主机的公钥，也不会将新的主机密钥添加到已知主机列表中。这意味着所有远程主机的密钥将被自动接受，而不会进行任何验证。</span><br></pre></td></tr></tbody></table></figure>



<h2 id="4-准备ip文件"><a href="#4-准备ip文件" class="headerlink" title="4. 准备ip文件"></a>4. 准备 ip 文件</h2><ul>
<li><p>创建 ip.txt <code>vim ip.txt</code></p>
</li>
<li><p>将需要免密的机器 <code>ip</code> 写入</p>
<p><img src="C:\Users\24529\AppData\Roaming\Typora\typora-user-images\image-20240710103927738.png" alt="image-20240710103927738"></p>
</li>
</ul>
<h2 id="5-创建脚本"><a href="#5-创建脚本" class="headerlink" title="5. 创建脚本"></a>5. 创建脚本</h2><ul>
<li>需要手动写登录密码 <code>password</code></li>
<li>前提安装 <code>expect</code></li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取 IP 地址列表</span></span><br><span class="line">servers=()</span><br><span class="line"><span class="keyword">while</span> IFS= <span class="built_in">read</span> -r line; <span class="keyword">do</span></span><br><span class="line">    servers+=(<span class="string">"<span class="variable">$line</span>"</span>)</span><br><span class="line"><span class="keyword">done</span> &lt; ip.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地 .ssh 目录路径</span></span><br><span class="line">ssh_dir=<span class="string">"<span class="variable">$HOME</span>/.ssh"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 expect 进行 scp 并自动输入密码</span></span><br><span class="line"><span class="keyword">for</span> server <span class="keyword">in</span> <span class="string">"<span class="variable">${servers[@]}</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Copying SSH keys to <span class="variable">$server</span>"</span></span><br><span class="line">    expect &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">spawn scp -r $ssh_dir root@$server:/root/</span></span><br><span class="line"><span class="string">expect {</span></span><br><span class="line"><span class="string">    "password:" {</span></span><br><span class="line"><span class="string">        send "your password\r"</span></span><br><span class="line"><span class="string">        exp_continue</span></span><br><span class="line"><span class="string">    }</span></span><br><span class="line"><span class="string">    "yes/no" {</span></span><br><span class="line"><span class="string">        send "yes\r"</span></span><br><span class="line"><span class="string">        exp_continue</span></span><br><span class="line"><span class="string">    }</span></span><br><span class="line"><span class="string">    eof {</span></span><br><span class="line"><span class="string">        exit</span></span><br><span class="line"><span class="string">    }</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Successfully copied SSH keys to <span class="variable">$server</span>"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Failed to copy SSH keys to <span class="variable">$server</span>"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"All servers have been updated with SSH keys."</span></span><br></pre></td></tr></tbody></table></figure>

<hr>
<blockquote>
<p>[!TIP]</p>
<p>补充安装 expect 包教程</p>
<h3 id="在Ubuntu上安装Expect"><a href="#在Ubuntu上安装Expect" class="headerlink" title="在Ubuntu上安装Expect"></a>在 Ubuntu 上安装 Expect</h3><ol>
<li><p><strong>更新包列表</strong>：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get update</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>安装 Expect</strong>：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install expect</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>验证安装</strong>：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">expect -v</span><br></pre></td></tr></tbody></table></figure>

<p>这将显示已安装的 <code>expect</code> 版本。</p>
</li>
</ol>
<h3 id="在CentOS上安装Expect"><a href="#在CentOS上安装Expect" class="headerlink" title="在CentOS上安装Expect"></a>在 CentOS 上安装 Expect</h3><ol>
<li><p><strong>更新包列表</strong>：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum update</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>安装 Expect</strong>：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install expect</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>验证安装</strong>：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">expect -v</span><br></pre></td></tr></tbody></table></figure>

<p>这将显示已安装的 <code>expect</code> 版本。</p>
<hr>
<p>完成这些步骤后，你的系统上就会安装 Expect 工具。Expect 是一种用于自动化交互任务的工具，常用于自动化 SSH 登录、FTP 等需要用户交互的任务。</p>
</li>
</ol>
</blockquote>
<hr>
<blockquote>
<p>[!TIP]</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-1.html">1. 服务器免密配置教程 - 1</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-2.html">2. 服务器免密配置教程 - 2</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/3.html">3. 服务器修改 host 和 hostname</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/4.html">4. 服务器挂载外部存储卷</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/5.html">5. 批量加载 docker 镜像 &amp; 镜像重命名</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/6.html">6. 安装 Nvidia-docker</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器配置永久修改 DNS</title>
    <url>/2024/07/15/Config/20240704_%E6%B0%B8%E4%B9%85%E4%BF%AE%E6%94%B9DNS/</url>
    <content><![CDATA[<p>服务器内配置 DNS</p>
<span id="more"></span>

<p>1.<br>    </p><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">vi /etc/systemd/resolved.conf</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>2.<br>    </p><figure class="highlight tex"><table><tbody><tr><td class="code"><pre><span class="line">DNS=114.114.114.114 8.8.8.8 8.8.4.4</span><br><span class="line">FallbackDNs=8.8.8.8</span><br><span class="line">Domains=domain.com</span><br></pre></td></tr></tbody></table></figure><p></p>
<ol start="3">
<li><pre><code class="bash">sudo systemctl restart systemd-resolved
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">4. ```bash</span><br><span class="line">   mv /etc/resolv.conf /etc/resolv.conf_bak</span><br></pre></td></tr></tbody></table></figure>
</code></pre>
</li>
<li><pre><code class="bash">ln -s /run/systemd/resolve/resolv.conf /etc/
</code></pre>
</li>
</ol>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建基于 Hexo 架构的个人博客</title>
    <url>/2024/07/18/Config/20240718_%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8Ehexo%E6%9E%B6%E6%9E%84%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>记录一下搭建基于 hexo 架构的个人博客的过程。从安装 node.js 开始，到安装 hexo，到配置主题，到写文章，到部署发布。</p>
<p><img src="/../../img/hexo-1.jpg" alt="hexo 首页"></p>
<span id="more"></span>


<h2 id="1-安装node-js"><a href="#1-安装node-js" class="headerlink" title="1.安装node.js"></a>1. 安装 node.js</h2><p><a></a><a href="https://nodejs.org/zh-cn/download/package-manager/">https://nodejs.org/zh-cn/download/package-manager/</a></p>
<h2 id="2-安装npm"><a href="#2-安装npm" class="headerlink" title="2.安装npm"></a>2. 安装 npm</h2><p>当你安装 node.js 时，npm 会自动安装。但是，npm 的更新比 Node.js 更频繁，因此请确保您拥有最新版本。</p>
<ul>
<li>升级 npm：<code>npm install -g npm</code></li>
</ul>
<h2 id="3-安装cnpm"><a href="#3-安装cnpm" class="headerlink" title="3.安装cnpm"></a>3. 安装 cnpm</h2><p>使用 npm 下载软件包时，有时会遇到网络问题，这时可以使用 cnpm 加速下载。cnpm 是淘宝提供的 npm 镜像，速度更快。</p>
<ul>
<li><code>npm install -g cnpm --registry=http://registry.npm.taobao.org</code></li>
</ul>
<h2 id="4-检查安装是否成功"><a href="#4-检查安装是否成功" class="headerlink" title="4.检查安装是否成功"></a>4. 检查安装是否成功</h2><ul>
<li><p>检查 node.js 版本：</p>
<p>  <code>node -v</code></p>
</li>
<li><p>检查 npm 版本：</p>
<p>  <code>npm -v</code></p>
</li>
<li><p>检查 cnpm 版本：</p>
<p>  <code>cnpm -v</code></p>
</li>
</ul>
<div class="note warning"><p>这里是警告。</p></div>]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 之 CMD 常用命令</title>
    <url>/2024/08/19/Config/20240819_Windows%E4%B9%8Bcmd%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>在 windows 操作系统内，使用终端进行的常用操作命令.</p>
<span id="more"></span>

<ul>
<li><p>查看 <code>IP</code></p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">ipconfig</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>关闭防火墙</p>
  <figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">netsh advfirewall <span class="built_in">set</span> allprofiles state off</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器免密配置教程 - 2</title>
    <url>/2024/07/15/Config/20240709_%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%8D%E5%AF%86%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B-2/</url>
    <content><![CDATA[<p>工作时解决服务器免密登录问题，记录一下解决过程。</p>
<span id="more"></span>


<blockquote>
<p>[!NOTE]</p>
<p>该手册一共 2 个版本，此文档为第<b>二</b>版。</p>
</blockquote>
<h2 id="1-准备ip文件"><a href="#1-准备ip文件" class="headerlink" title="1. 准备ip文件"></a>1. 准备 ip 文件</h2><ul>
<li><p>创建 ip.txt <code>vim ip.txt</code></p>
</li>
<li><p>将需要免密的机器 <code>ip</code> 写入</p>
</li>
</ul>
<h2 id="2-创建脚本-运行脚本"><a href="#2-创建脚本-运行脚本" class="headerlink" title="2. 创建脚本+运行脚本"></a>2. 创建脚本 + 运行脚本</h2><ul>
<li><code>vim set_key.sh</code></li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否已经生成了SSH密钥对</span></span><br><span class="line"><span class="keyword">if</span> [ ! -f ~/.ssh/id_rsa.pub ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Generating SSH key pair..."</span></span><br><span class="line">  ssh-keygen -t rsa -N <span class="string">""</span> -f ~/.ssh/id_rsa</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将公钥复制到每台目标机器</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> -r ip; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Configuring SSH key authentication for <span class="variable">$ip</span>..."</span></span><br><span class="line">  ssh-copy-id root@<span class="variable">$ip</span></span><br><span class="line"><span class="keyword">done</span> &lt; ip.txt</span><br><span class="line"><span class="built_in">echo</span> </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p><code>chmod +x set_key.sh</code></p>
</li>
<li><p><code>./set_key.sh</code></p>
</li>
</ul>
<hr>
<blockquote>
<p>[!TIP]</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-1.html">1. 服务器免密配置教程 - 1</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/1-2.html">2. 服务器免密配置教程 - 2</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/3.html">3. 服务器修改 host 和 hostname</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<a href="https://a19909442097.rth5.com/markdown_text/4.html">4. 服务器挂载外部存储卷</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/5.html">5. 批量加载 docker 镜像 &amp; 镜像重命名</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
<pangu> </pangu><a href="https://a19909442097.rth5.com/markdown_text/6.html">6. 安装 Nvidia-docker</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>Config</category>
      </categories>
      <tags>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是 RoCE/IB/RDMA</title>
    <url>/2024/07/26/Knowledge/20240726_%E4%BB%80%E4%B9%88%E6%98%AFRoCEIBRDMA/</url>
    <content><![CDATA[<p> 在分布式存储网络中，我们使用的协议有 <strong>RoCE</strong>、<strong>Infiniband（IB）</strong>和 <strong>TCP/IP</strong>。其中 RoCE 和 IB 属于 <strong>RDMA (RemoteDirect Memory Access) 技术</strong>，他和传统的 TCP/IP 有什么区别呢，接下来我们将做详细对比。</p>
<p><img src="/../../img/RDMA.png" alt="RDMA API"></p>
<span id="more"></span>

<h2 id="RoCE和IB，RDMA通述"><a href="#RoCE和IB，RDMA通述" class="headerlink" title="RoCE和IB，RDMA通述"></a>RoCE 和 IB，RDMA 通述</h2><h3 id="什么是RoCE"><a href="#什么是RoCE" class="headerlink" title="什么是RoCE"></a>什么是 RoCE</h3><ul>
<li>RoCE (译为” 基于融合以太网的 RDMA”, 英文全称: RDMA over Converged Ethernet) 是一个网络协议，允许在一个<a href="https://zh.wikipedia.org/wiki/%E4%BB%A5%E5%A4%AA%E7%BD%91">以太网</a>网络上使用<a href="https://zh.wikipedia.org/wiki/%E8%BF%9C%E7%A8%8B%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE">远程直接内存访问</a>（RDMA）。RoCE 有 RoCE v1 和 RoCE v2 两个版本。RoCE v1 是一个以太网<a href="https://zh.wikipedia.org/wiki/%E9%93%BE%E8%B7%AF%E5%B1%82">链路层</a>协议，因此允许同一个以太网<a href="https://zh.wikipedia.org/wiki/%E5%B9%BF%E6%92%AD%E5%9F%9F">广播域</a>中的任意两台主机间进行通信。RoCE v2 是一个<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%B1%82">网络层</a>协议，因而 RoCE v2 数据包可以被路由。虽然 RoCE 协议受益于<a href="https://zh.wikipedia.org/w/index.php?title=Data_center_bridging&amp;action=edit&amp;redlink=1">融合以太网网络</a>的特征，但该协议也可用于传统或非融合的以太网网络。</li>
</ul>
<h3 id="什么是IB"><a href="#什么是IB" class="headerlink" title="什么是IB"></a>什么是 IB</h3><ul>
<li>InfiniBand (直译为 “无限带宽” 技术，缩写为 IB) 是一个用于<a href="https://baike.baidu.com/item/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/0?fromModule=lemma_inlink">高性能计算</a>的计算机网络通信标准，它具有极高的<a href="https://baike.baidu.com/item/%E5%90%9E%E5%90%90%E9%87%8F/0?fromModule=lemma_inlink">吞吐量</a>和极低的<a href="https://baike.baidu.com/item/%E5%BB%B6%E8%BF%9F/0?fromModule=lemma_inlink">延迟</a>，用于计算机与计算机之间的数据互连。InfiniBand 也用作服务器与存储系统之间的直接或交换互连，以及存储系统之间的互连。</li>
</ul>
<h3 id="什么是RDMA"><a href="#什么是RDMA" class="headerlink" title="什么是RDMA"></a>什么是 RDMA</h3><ul>
<li>RDMA (译为” 远程直接内存访问”, 英文全称：remote direct memory access) 是一种绕过远程主机操作系统内核访问其内存中数据的技术。由于不经过操作系统，不仅节省了大量 CPU 资源，同样也提高了系统吞吐量、降低了系统的网络通信<a href="https://zh.wikipedia.org/wiki/Latency_(engineering)">延迟</a>，尤其适合在大规模并行<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%9B%86%E7%BE%A4">计算机集群</a>中有广泛应用。</li>
</ul>
<p><img src="/../../img/download.png" alt="TCP/RDMA"></p>
<blockquote>
<h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><p>传统应用要发送数据，‍‍需要通过 OS 封装 TCP/IP，‍‍然后依次经过主缓存、网卡缓存，‍‍再发出去。‍‍这样会导致两个限制。</p>
<p>限制一：TCP/IP 协议栈处理会带来数 10 微秒的时延。‍‍TCP 协议栈在接收发送报文时，‍‍内核需要做多次上下文的切换，‍‍每次切换需要耗费 5-10 微秒。‍另外还需要至少三次的数据拷贝‍‍和依赖 CPU 进行协议工作，‍‍这导致仅仅协议上处理就会带来数 10 微秒的‍‍固定时延，‍‍协议栈时延成为最明显的瓶颈。‍‍</p>
<p>限制二：TCP 协议栈处理导致服务器 CPU 负载‍‍居高不下。‍‍除了固定时延较长的问题，TCP/IP 网络需要主机 CPU‍‍多次参与协议的内存拷贝，‍‍网络规模越大，‍‍网络带宽越高，‍‍CPU 在收发数据时的调度负担越大，‍‍导致 CPU 持续高负载。‍‍</p>
<p>在数据中心内部，超大规模分布式计算存储资源之间，如果使用传统的 TCP/IP 进行网络互连，将占用系统大量的计算资源，造成 IO 瓶颈，无法满足更高吞吐，更低时延的网络需求。</p>
</blockquote>
<hr>
<h2 id="RoCE优缺点及关键技术"><a href="#RoCE优缺点及关键技术" class="headerlink" title="RoCE优缺点及关键技术"></a>RoCE 优缺点及关键技术</h2><h3 id="使用RoCE的优势"><a href="#使用RoCE的优势" class="headerlink" title="使用RoCE的优势"></a>使用 RoCE 的优势</h3><ul>
<li><p><strong>成本效益：</strong> </p>
<p>利用现有以太网基础设施：RoCE 可以在现有的以太网基础设施上运行，降低了部署和维护成本。 通用设备：使用通用的以太网交换机和网卡，设备成本较低。</p>
</li>
<li><p>** 兼容性和灵活性： **</p>
<p>广泛兼容：RoCE 基于以太网，兼容性和通用性好，可以与其他网络设备和协议无缝集成。 灵活部署：可以灵活地部署在不同的网络拓扑和环境中。 </p>
</li>
<li><p><strong>易于管理：</strong></p>
<p>统一管理：由于 RoCE 基于以太网，可以使用现有的网络管理工具和协议进行管理，简化了管理流程。</p>
</li>
</ul>
<h3 id="RoCE的缺点"><a href="#RoCE的缺点" class="headerlink" title="RoCE的缺点"></a>RoCE 的缺点</h3><ul>
<li><p><strong>性能：</strong></p>
<p>较高的延迟：尽管 RoCE 能够提供低延迟，但通常不如 IB 网络，在极端低延迟需求的应用中可能不如 IB 表现优秀。 网络拥塞：在共享以太网上运行时，可能受到其他网络流量的影响，导致性能下降。 </p>
</li>
<li><p><strong>可靠性：</strong></p>
<p>依赖于以太网质量：RoCE 的性能和可靠性依赖于以太网的质量，如果以太网网络质量不佳，可能会影响 RoCE 的表现。</p>
</li>
</ul>
<h3 id="RoCE对比IB总结"><a href="#RoCE对比IB总结" class="headerlink" title="RoCE对比IB总结"></a>RoCE 对比 IB 总结</h3><ul>
<li>IB 和 RoCE 的区别为链路层一个为 IB 协议，一个为 Ethernet 协议，其中 Ethernet 协议更具有普适性，且大部分场景 RoCE 时延更低、带宽更高。</li>
</ul>
<h3 id="RoCE的关键技术"><a href="#RoCE的关键技术" class="headerlink" title="RoCE的关键技术"></a>RoCE 的关键技术</h3><ul>
<li><p>由于 RDMA 要求承载网络无丢包，否则效率就会急剧下降，所以 RoCE 技术如果选用以太网进行承载，就需要通过 PFC，ECN 以及 DCQCN 等技术对传统以太网络改造，打造无损以太网络，以确保零丢包。</p>
<p><img src="/../../img/36a8e300fd6759f17464122ef108e37b.png" alt="PEC&amp;ECN"></p>
</li>
<li><p><strong>PFC:</strong></p>
<p>基于优先级的流量控制。PFC 为多种类型的流量提供基于每跳优先级的流量控制。设备在转发报文时，通过在优先级映射表中查找报文的优先级，将报文分配到队列中进行调度和转发。当 802.1p 优先级报文的发送速率超过接收速率且接收端的数据缓存空间不足时，接收端向发送端发送 PFC 暂停帧。当发送端收到 PFC 暂停帧时，发送端停止发送具有指定 802.1p 优先级的报文，直到发送端收到 PFC XON 帧或老化定时器超时。配置 PFC 时，特定类型报文的拥塞不影响其他类型报文的正常转发。</p>
</li>
<li><p><strong>ECN：</strong></p>
<p>显式拥塞通知。ECN 定义了基于 IP 层和传输层的流量控制和端到端拥塞通知机制。当设备拥塞时，ECN 会在数据包的 IP 头中标记 ECN 字段。接收端发送拥塞通知包（CNP）通知发送端放慢发送速度。ECN 实现端到端的拥塞管理，减少拥塞的扩散和加剧。</p>
</li>
</ul>
<hr>
<h2 id="RoCE应用趋势"><a href="#RoCE应用趋势" class="headerlink" title="RoCE应用趋势"></a>RoCE 应用趋势</h2><ul>
<li><p>当比较 RoCE 与其他类似的策略时，例如 iWARP（Internet Wide Area RDMA Protocol）和传统的 InfiniBand 网络，我们可以看到一些显著的区别。</p>
<p><img src="/../../img/RDMA.png" alt="RDMA"></p>
</li>
<li><p>iWARP 是一种通过 TCP/IP 协议栈实现 RDMA 的技术。虽然它可以在标准的三层网络中运行，但它的实现通常比 RoCE 复杂，并且可能需要更多的 CPU 资源来处理额外的软件堆栈。此外，iWARP 在网络性能方面可能不如 RoCE，尤其是在低延迟和高带宽的应用场景中。</p>
</li>
<li><p>InfiniBand 是一种专为高性能计算设计的网络技术，它提供了极低的延迟和非常高的带宽。尽管 InfiniBand 在性能上优于 RoCE，但它通常也更昂贵，并且需要专用的硬件。相比之下，RoCE 可以在现有的以太网基础设施上运行，降低了部署成本。</p>
<p><img src="/../../img/RoCE_Header_format.png"></p>
</li>
<li><p>随着 RoCEv2 的成熟和普及，它已成为数据中心网络中的一个主要趋势。越来越多的企业开始采用 RoCEv2 来支持高性能计算、机器学习和大规模存储集群等应用。RoCEv2 的优势在于它能够在标准以太网上实现低延迟和高带宽的 RDMA 通信，同时保持较低的成本。</p>
</li>
<li><p>未来，随着对数据密集型应用需求的增长，RoCEv2 将继续在其核心市场中发挥重要作用。随着技术的进步和新的应用场景的出现，RoCEv2 可能会进一步优化以支持更广泛的用例，包括边缘计算和物联网（IoT）领域中的实时数据处理。</p>
</li>
<li><p>RoCEv2 凭借其在性能和成本之间的平衡，正在成为数据中心网络架构中的关键技术之一，而 RoCEv1 则由于其局限性而在实际应用中逐渐被淘汰。随着网络技术和市场需求的不断发展，RoCEv2 有望在未来的数据中心和高性能计算环境中扮演更加重要的角色。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Knowledge</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>work</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是 [云算 / 超算 / 智算 / 通算]?</title>
    <url>/2024/08/16/Knowledge/20240816_%E4%BB%80%E4%B9%88%E6%98%AF%5B%E4%BA%91%E7%AE%97%E8%B6%85%E7%AE%97%E6%99%BA%E7%AE%97%E9%80%9A%E7%AE%97%5D/</url>
    <content><![CDATA[<p>互联网专业名词解释，大部分从 IBM 官网搬运.</p>
<p><img src="/../../img/it.png"></p>
<span id="more"></span>

<h2 id="什么是云计算"><a href="#什么是云计算" class="headerlink" title="什么是云计算?"></a>什么是云计算？</h2><p>云计算就是指通过互联网以服务的形式按需提供计算资源（例如存储和基础设施）。这样，个人和企业就无需自行管理物理资源，而且只需为实际使用的资源付费。</p>
<blockquote>
<p><a href="https://www.ibm.com/topics/cloud-computing?mhsrc=ibmsearch_a&amp;mhq=cloud">What is cloud computing?</a></p>
</blockquote>
<hr>
<h2 id="什么是超级计算"><a href="#什么是超级计算" class="headerlink" title="什么是超级计算?"></a>什么是超级计算？</h2><p>超级计算是一种高性能计算形式，使用功能强大的计算机” 超级计算机” 执行确定或计算，减少总求解时间。</p>
<blockquote>
<p> <a href="https://www.ibm.com/cn-zh/topics/supercomputing?mhsrc=ibmsearch_a&amp;mhq=supercomputing">What is supercomputing ?</a></p>
</blockquote>
<hr>
<h2 id="什么是高性能计算-HPC-？"><a href="#什么是高性能计算-HPC-？" class="headerlink" title="什么是高性能计算 (HPC)？"></a>什么是高性能计算 (HPC)？</h2><p>高性能计算 (HPC) 是一种利用强大处理器集群并行处理海量多维数据集（也称为大数据）并以极高速度解决复杂问题的技术。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/hpc">What is HPC ?</a></p>
</blockquote>
<hr>
<h2 id="什么是边缘计算？"><a href="#什么是边缘计算？" class="headerlink" title="什么是边缘计算？"></a>什么是边缘计算？</h2><p>边缘计算是一种分布式计算框架，可使企业应用程序更接近数据源，例如 IoT 设备或本地边缘服务器。通过接近源头数据，可实现强大的业务优势，包括加快洞察过程、缩短响应时间、增强带宽可用性。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/edge-computing">What is edge computing ?</a></p>
</blockquote>
<hr>
<h2 id="什么是物联网-IoT-？"><a href="#什么是物联网-IoT-？" class="headerlink" title="什么是物联网 (IoT)？"></a>什么是物联网 (IoT)？</h2><p>物联网 (IoT) 是指由实体设备、车辆、电器和其他实体对象组成的网络，这些实体对象内嵌传感器、软件和网络连接，可以收集和共享数据。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/internet-of-things">what is internet of things?</a></p>
</blockquote>
<hr>
<h2 id="什么是Kubernetes"><a href="#什么是Kubernetes" class="headerlink" title="什么是Kubernetes?"></a>什么是 Kubernetes?</h2><p>Kubernetes 也称为 k8s 或 kube，是一个开源<a href="https://www.ibm.com/cn-zh/topics/container-orchestration">容器编排</a>平台，用于调度和自动执行容器化应用程序的部署、管理和扩展。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/kubernetes">what’s kubernets?</a></p>
</blockquote>
<hr>
<h2 id="什么是-Docker？"><a href="#什么是-Docker？" class="headerlink" title="什么是 Docker？"></a>什么是 Docker？</h2><p><a href="https://www.ibm.com/cn-zh/topics/docker">Docker</a> 是创建和运行 Linux 容器的最流行工具。虽然数十年前人们就已经引入早期形式的容器（使用 FreeBSD Jails 和 AIX Workload Partitions 等技术），但在 2013 年，Docker 通过一种新的开发人员友好型和云友好型实现，将容器推向大众，从而实现了容器的民主化。</p>
<p>Docker 最初是一个开源项目，但今天，它也指 Docker Inc.，该公司生产 Docker（一个建立在开源项目基础上的商业容器工具包）并将这些改进回馈开源社区。</p>
<p>Docker 基于传统的 Linux 容器技术构建，但支持更精细的 Linux 内核进程虚拟化，并添加了一些功能，助力开发人员更轻松地构建、部署、管理和保护容器。</p>
<p><a href="https://www.ibm.com/cn-zh/topics/kubernetes">what’s kubernets?</a></p>
<hr>
<h2 id="什么是容器"><a href="#什么是容器" class="headerlink" title="什么是容器?"></a>什么是容器？</h2><p><a href="https://www.ibm.com/cn-zh/topics/containers">容器</a>是轻量级可执行应用程序组件，将源代码与在任何环境中运行代码所需的所有操作系统 (OS) 库和依赖关系相结合。</p>
<p>容器利用操作系统<a href="https://www.ibm.com/cn-zh/topics/virtualization">虚拟化</a>形式，通过隔离进程并控制进程可以访问的 CPU、内存和磁盘量，实现多个应用程序共享单个操作系统实例。容器比<a href="https://www.ibm.com/cn-zh/topics/virtual-machines">虚拟机</a> (VM) 更小、资源效率更高、更便携，已成为现代云原生应用程序事实上的计算单元。容器的资源效率也更高。它们允许您在更少的机器（<a href="https://www.ibm.com/cn-zh/topics/virtual-server">虚拟服务器</a>和物理服务器）上使用更少的操作系统实例运行更多的应用程序。</p>
<p>由于容器可以在随时随地一致地运行，因此它们对于支持混合多云环境的底层架构至关重要，混合多云环境是本地、<a href="https://www.ibm.com/cn-zh/topics/private-cloud">私有云、</a><a href="https://www.ibm.com/cn-zh/topics/public-cloud">公有云</a>和来自多个云供应商的多个云服务的组合。</p>
<blockquote>
<p> <a href="https://www.ibm.com/cn-zh/topics/kubernetes">what’s kubernets?</a></p>
</blockquote>
<hr>
<h2 id="什么是人工智能-AI-？"><a href="#什么是人工智能-AI-？" class="headerlink" title="什么是人工智能 (AI)？"></a>什么是人工智能 (AI)？</h2><p>人工智能 (AI) 是一种使计算机和机器能够模拟人类智能和解决问题能力的技术。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/artificial-intelligence?Ink=fle">waht is artificial intelligence ?</a></p>
</blockquote>
<hr>
<h2 id="什么是商业智能？"><a href="#什么是商业智能？" class="headerlink" title="什么是商业智能？"></a>什么是商业智能？</h2><p>商业智能 (BI) 是一种软件，用来采集业务数据并在用户友好型视图（例如报告、仪表板、图表和图形）中呈现这些数据。分析这些数据可以帮助企业获得切实可行的洞察并为决策提供指导。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/business-intelligence">what is business intelligence ?</a></p>
</blockquote>
<hr>
<h2 id="什么是数字孪生-Digital-Twin"><a href="#什么是数字孪生-Digital-Twin" class="headerlink" title="什么是数字孪生(Digital Twin)?"></a>什么是数字孪生 (Digital Twin)?</h2><p>数字孪生是某一对象或系统整个生命周期的虚拟再现，根据实时数据进行更新，并利用模拟、机器学习和推理来辅助决策。</p>
<blockquote>
<p> <a href="https://www.ibm.com/cn-zh/topics/what-is-a-digital-twin?lnk=fle">what is digital twin ?</a></p>
</blockquote>
<hr>
<h2 id="什么是数字化转型？"><a href="#什么是数字化转型？" class="headerlink" title="什么是数字化转型？"></a>什么是数字化转型？</h2><p>数字化转型是指在市场需求和技术的推动下，采用数字优先的客户、业务合作伙伴和员工体验。</p>
<blockquote>
<p> <a href="https://www.ibm.com/cn-zh/topics/digital-transformation?lnk=fle">what is digital transformation ?</a></p>
</blockquote>
<hr>
<h2 id="什么是区块链？"><a href="#什么是区块链？" class="headerlink" title="什么是区块链？"></a>什么是区块链？</h2><p>区块链是一种不可篡改的共享分类账，有助于推动业务网络中记录交易和跟踪资产的过程。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/blockchain?lnk=fle">what is blockchain?</a></p>
</blockquote>
<hr>
<h2 id="什么是-SaaS-软件即服务-？"><a href="#什么是-SaaS-软件即服务-？" class="headerlink" title="什么是 SaaS (软件即服务)？"></a>什么是 SaaS (软件即服务)？</h2><p>SaaS (软件即服务) 是托管在云端的应用软件，由 Web 浏览器、移动应用程序或瘦客户端通过互联网连接使用。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/saas">what is SaaS?</a></p>
</blockquote>
<hr>
<h2 id="什么是量子计算？"><a href="#什么是量子计算？" class="headerlink" title="什么是量子计算？"></a>什么是量子计算？</h2><p>量子计算利用专门技术（包括计算机硬件和利用量子力学的算法）来解决传统计算机或超级计算机无法解决或无法快速解决的复杂问题。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/quantum-computing">what is Quantum computing ?</a></p>
</blockquote>
<hr>
<h2 id="什么是数据挖掘？"><a href="#什么是数据挖掘？" class="headerlink" title="什么是数据挖掘？"></a>什么是数据挖掘？</h2><p>数据挖掘，又称知识发现 (KDD)，是从大量的数据集中发现模式和其他有价值信息的过程。 鉴于<a href="https://www.ibm.com/cn-zh/topics/data-warehouse">数据仓储</a>技术的发展和大数据的增长，数据挖掘技术的采用在过去几十年中迅速加快，它通过将原始数据转化为有用的知识来助力公司发展。  然而，尽管该技术不断发展以处理大规模的数据，但领导者仍面临可扩展性和自动化方面的挑战。</p>
<p>数据挖掘通过透彻的数据分析完善了组织决策。 支持这些分析的数据挖掘技术可分为两大用途；它们既可以描述目标数据集，也可以通过使用<a href="https://www.ibm.com/cn-zh/topics/machine-learning">机器学习</a>算法来预测结果。  这些方法用于组织和过滤数据，揭示最有趣的信息，从欺诈检测到用户行为、瓶颈，甚至是安全漏洞。</p>
<p>当与 <a href="https://www.ibm.com/cn-zh/topics/apache-spark">Apache Spark</a> 等数据分析和可视化工具结合使用时，深入探索数据挖掘世界从未如此轻松，提取相关见解的速度也从未如此之快。 <a href="https://www.ibm.com/cn-zh/topics/artificial-intelligence">人工智能</a>领域的进步，只会继续加速其在各行各业内的采用。  </p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/data-mining">what is data mining ?</a></p>
</blockquote>
<hr>
<h2 id="什么是矢量数据库？"><a href="#什么是矢量数据库？" class="headerlink" title="什么是矢量数据库？"></a>什么是矢量数据库？</h2><p>矢量数据库旨在高效地存储、管理和索引海量高维矢量数据。</p>
<blockquote>
<p><a href="https://www.ibm.com/cn-zh/topics/vector-database">what is vector database ?</a></p>
</blockquote>
<hr>
<blockquote>
<h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><p><a href="https://www.ibm.com/topics">https://www.ibm.com/topics</a></p>
</blockquote>
<p>reg add “HKEY_CLASSES_ROOT\Directory\shell\VSCode\command” /t REG_SZ /d “D:\Microsoft VS Code\Code.exe "%1"“ /f</p>
]]></content>
      <categories>
        <category>Knowledge</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>knowledge</tag>
      </tags>
  </entry>
  <entry>
    <title>大语言模型调优方案</title>
    <url>/2024/09/03/Knowledge/20240903_%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>大语言模型调优方案，涉及<strong>计算效能调优</strong> , <strong>推理效果调优</strong> , <strong>模型结构调优</strong></p>
<span id="more"></span>

<h2 id="算效调优"><a href="#算效调优" class="headerlink" title="算效调优"></a>算效调优</h2><p>硬件层面各个部件对大模型的优化策略</p>
<h3 id="1-GPU加速"><a href="#1-GPU加速" class="headerlink" title="1. GPU加速"></a>1. GPU 加速</h3><h4 id="1-1-为什么GPU可以对大模型有加速效果"><a href="#1-1-为什么GPU可以对大模型有加速效果" class="headerlink" title="1.1 为什么GPU可以对大模型有加速效果?"></a>1.1 为什么 GPU 可以对大模型有加速效果？</h4><p>GPU 的核心优势在于其并行处理能力，可以同时执行成千上万的计算任务。对于深度学习模型而言，这意味着可以并行处理大量的矩阵乘法和向量运算，这些是模型训练的核心。GPU 的计算能力通常以 TFLOPS（每秒万亿次浮点运算）来衡量。高 TFLOPS 值意味着 GPU 能够在较短的时间内完成更多的计算任务，从而加快模型的训练速度。</p>
<p style="text-align: center;">Tesla V100 Accelerator (Front)</p>

<p><img src="/../img/LLM-tuning-01.png" alt="image-20240905084258878"></p>
<p>选择 GPU 而非 CPU 进行大模型训练的主要原因是因为 GPU 在并行处理能力、高吞吐量和针对机器学习任务的优化方面的优势。这使得 GPU 成为训练复杂和大规模机器学习模型的首选。</p>
<ul>
<li><p><strong>并行处理能力：</strong></p>
<p>GPU 拥有成千上万个较小、更专用的核心，这使得它们能够同时处理多个任务。这种并行处理能力使 GPU 非常适合执行机器学习和深度学习算法中的大量矩阵和向量运算。相比之下，CPU（中央处理单元）核心数量较少，但每个核心的通用计算能力更强，适用于需要大量逻辑和顺序处理的任务。</p>
</li>
<li><p><strong>高吞吐量：</strong></p>
<p>GPU 能够提供更高的吞吐量，这意味着它们可以在较短的时间内处理更多的数据。这对于训练大型模型尤其重要，因为这些模型通常需要处理巨大的数据集，并执行数以亿计的运算。</p>
</li>
<li><p><strong>大规模计算：</strong></p>
<p>GPU 最初是为了处理复杂的图形和<a href="https://cloud.tencent.com/product/tiia?from_column=20065&amp;from=20065">图像处理</a>任务而设计的，这些任务需要大量的计算和数据处理。这些设计特性也让 GPU 非常适合于训练大型机器学习模型，因为这些模型需要进行大量的数学运算，特别是在训练神经网络时。</p>
</li>
<li><p><strong>优化的库和框架：</strong></p>
<p>许多深度学习框架和库，如 TensorFlow、PyTorch 等，都针对 GPU 进行了优化，以充分利用其并行处理能力。这些优化包括专门的算法和硬件加速技术，可以显著加快模型训练过程。</p>
</li>
<li><p><strong>成本：</strong></p>
<p>虽然高端 GPU 的初始投资可能比 CPU 高，但在处理大规模机器学习任务时，GPU 因其较高的效率和速度，可以提供更好的成本效益。尤其是在云计算环境中，用户可以根据需要临时租用 GPU 资源，进一步提高成本效益。</p>
</li>
</ul>
<h4 id="1-2-GPU里有什么"><a href="#1-2-GPU里有什么" class="headerlink" title="1.2 GPU里有什么,?"></a>1.2 GPU 里有什么，？</h4><p>Tensor Cores 和 CUDA Cores 都是 NVIDIA GPU 架构中的关键组成部分，但它们的设计目标和服务的对象有所不同。下面详细介绍这两种核心的区别：</p>
<h5 id="CUDA-Cores"><a href="#CUDA-Cores" class="headerlink" title="CUDA Cores"></a>CUDA Cores</h5><p>CUDA Cores 是 NVIDIA GPU 中的基础计算单元，类似于 CPU 中的核心，但专门为并行计算而优化。CUDA Cores 能够执行各种类型的数学运算，包括整数运算、单精度浮点运算以及双精度浮点运算。CUDA Cores 的数量决定了 GPU 的并行计算能力，更多的 CUDA Cores 意味着更强的并行处理能力。</p>
<p>CUDA Cores 被设计为一种通用的计算资源，可以用于执行广泛的任务，从简单的图形渲染到复杂的科学计算，甚至是深度学习模型的训练。CUDA Cores 支持通过 CUDA 编程接口直接访问，使得开发人员能够编写高效的并行计算代码。</p>
<h5 id="Tensor-Cores"><a href="#Tensor-Cores" class="headerlink" title="Tensor Cores"></a>Tensor Cores</h5><p>Tensor Cores 是 NVIDIA 为加速深度学习任务而专门设计的一种新型计算单元。它们最早出现在 2017 年的 Volta 架构中，并随后在 Turing、Ampere 等架构中得到了发展和完善。Tensor Cores 的主要特点是它们特别适合执行深度学习所需的矩阵运算，如矩阵乘法和累积运算。</p>
<p>Tensor Cores 的一个重要特性是它们支持混合精度计算，即能够在 FP16（半精度浮点数）和 TF32（Tensor Float-32）之间进行切换，从而提供更高的计算效率和能效比。此外，Tensor Cores 还能在每个时钟周期内执行多项操作，相比之下，传统的 CUDA Cores 在每个时钟周期只能执行单一操作。</p>
<h5 id="CUDA-Cores-Tensor-Cores区别"><a href="#CUDA-Cores-Tensor-Cores区别" class="headerlink" title="CUDA Cores&amp;Tensor Cores区别"></a>CUDA Cores&amp;Tensor Cores 区别</h5><ol>
<li><strong>应用场景</strong>：CUDA Cores 是通用的并行计算单元，可以处理各种计算任务；而 Tensor Cores 则专门针对深度学习中的矩阵运算进行了优化。</li>
<li><strong>计算精度</strong>：CUDA Cores 支持更广泛的精度计算，包括 FP64、FP32 和 INT32 等；Tensor Cores 则专注于半精度浮点数（FP16）和混合精度计算（如 TF32）。</li>
<li><strong>性能</strong>：在处理深度学习相关的矩阵运算时，Tensor Cores 相比 CUDA Cores 能够提供更高的性能和能效比。</li>
</ol>
<p>CUDA Cores 提供了广泛的计算灵活性，而 Tensor Cores 则是在特定任务上（如深度学习）实现了性能的飞跃。这两种核心的组合使得现代 GPU 既能满足传统计算需求，也能适应日益增长的人工智能计算需求。</p>
<h4 id="1-3-主流GPU性能对比"><a href="#1-3-主流GPU性能对比" class="headerlink" title="1.3 主流GPU性能对比"></a>1.3 主流 GPU 性能对比</h4><p><img src="/../img/LLM-tuning-02.png"></p>
<h4 id="1-4-训练-推理最佳配置"><a href="#1-4-训练-推理最佳配置" class="headerlink" title="1.4 训练/推理最佳配置"></a>1.4 训练 / 推理最佳配置</h4><p style="text-align: center;">训练最优配置</p>

<p><img src="/../img/LLM-tuning-03.png" alt="image-20240905090148556"></p>
<p style="text-align: center;">推理最优配置</p>

<p><img src="/../img/LLM-tuning-04.png" alt="image-20240905090325642"></p>
<h3 id="2-TPU-FPGA"><a href="#2-TPU-FPGA" class="headerlink" title="2. TPU/FPGA"></a>2. TPU/FPGA</h3><p>TPU（Tensor Processing Unit）和 FPGA（Field-Programmable Gate Array）都是为加速机器学习任务而设计的专用硬件。</p>
<h4 id="TPU"><a href="#TPU" class="headerlink" title="TPU"></a>TPU</h4><p><img src="/../img/LLM-tuning-25.png" alt="tpu-768x517"></p>
<p>TPU 是由 Google 开发的一种 ASIC（Application-Specific Integrated Circuit），专门针对 TensorFlow 框架进行了优化。TPU 的设计目标是在处理矩阵运算时提供更高的效率，这对于深度学习模型来说是非常关键的，因为它们通常包含大量的矩阵乘法操作。利用 TPU 可以实现以下优化：</p>
<ul>
<li><strong>高效计算</strong>：TPU 能够提供比传统 CPU 或 GPU 更高的浮点运算性能，在处理大规模神经网络时尤其有效。</li>
<li><strong>低精度支持</strong>：TPU 支持 8 位整数运算，这减少了数据传输量，加快了计算速度，同时降低了功耗。</li>
<li><strong>分布式训练</strong>：通过构建 TPU Pod，可以实现多个 TPU 之间的高效通信，从而支持更大规模的数据并行训练。</li>
<li><strong>自动优化</strong>：TPU 编译器可以自动将 TensorFlow 图转化为高效的 TPU 指令序列，减少了手动优化的需要。</li>
</ul>
<h4 id="FPGA"><a href="#FPGA" class="headerlink" title="FPGA"></a>FPGA</h4><p><img src="/../img/LLM-tuning-24.png" alt="fpga-beginners-guide"></p>
<p>FPGA 是一种可编程逻辑器件，可以在硬件级别上根据特定的任务重新配置。这种灵活性使得 FPGA 非常适合于那些需要定制化处理流程的任务。对于大模型的优化，FPGA 提供了如下优势：</p>
<ul>
<li><strong>定制化</strong>：FPGA 可以根据特定算法的需求进行编程，这意味着它可以针对特定的模型架构进行优化，达到最佳的性能。</li>
<li><strong>低延迟</strong>：FPGA 可以实现低延迟的数据处理，这对于实时应用非常重要。</li>
<li><strong>能效比</strong>：相比于 GPU，FPGA 在某些任务上可以提供更好的能效比，尤其是在需要高并发且低功耗的场景下。</li>
<li><strong>灵活性</strong>：FPGA 可以在部署后进行重新配置，以适应新的算法或模型变化。</li>
</ul>
<h3 id="3-内存带宽"><a href="#3-内存带宽" class="headerlink" title="3. 内存带宽"></a>3. 内存带宽</h3><p>提高内存带宽对于优化大模型的性能至关重要。大模型，特别是深度学习模型，通常包含数百万甚至数十亿的参数，这些参数在训练过程中需要频繁地被访问和更新。随着模型规模的增长，内存带宽成为了限制性能的一个重要因素，因为它直接影响到数据的加载和传输速度。</p>
<h4 id="3-1-内存带宽的重要性"><a href="#3-1-内存带宽的重要性" class="headerlink" title="3.1 内存带宽的重要性"></a>3.1 内存带宽的重要性</h4><p>内存带宽是指单位时间内可以从内存读取或写入的最大数据量。对于大模型而言，更高的内存带宽意味着模型可以更快地加载数据进行处理，进而提高计算效率。在大模型的训练过程中，内存带宽的不足会导致数据传输成为瓶颈，从而减慢训练速度。例如，在模型推理过程中，较大的内存缓存可以提高推理速度，但同时也减少了可用的上下文长度，需要在速度和上下文长度之间进行权衡。</p>
<h4 id="3-2-高速内存技术"><a href="#3-2-高速内存技术" class="headerlink" title="3.2 高速内存技术"></a>3.2 高速内存技术</h4><p style="text-align: center">AMD Fiji 首款使用高带宽内存技术的图形处理器</p>

<p><img src="/../img/LLM-tuning-07.png" alt="image-20240905091319693"></p>
<p>高速内存技术，如 HBM（High Bandwidth Memory）和 GDDR6。HBM 通过垂直堆叠 DRAM 芯片来提供更高的带宽，而 GDDR6 则专为高性能图形处理单元（GPU）设计，能够提供比传统 DDR 内存更高的带宽。这些技术特别适用于处理大型数据集和复杂的神经网络模型，因为它们能更有效地支持大量数据的快速读取和写入。</p>
<p><img src="/../img/LLM-tuning-05.png" alt="image-20240905091113941"></p>
<p><img src="/../img/LLM-tuning-06.png" alt="image-20240905091219597"></p>
<h4 id="3-3-分布式设置中的网络连接"><a href="#3-3-分布式设置中的网络连接" class="headerlink" title="3.3 分布式设置中的网络连接"></a>3.3 分布式设置中的网络连接</h4><p>在分布式训练环境中，除了本地内存带宽之外，网络连接的质量也至关重要。快速的网络连接（如 InfiniBand 或 RDMA over Converged Ethernet, RoCE）能够确保数据在多个计算节点间快速、高效地流动。例如，InfiniBand 网络提供的带宽相较于其他网络技术有明显的优势，为解决 AI 大模型对服务器集群中每个 GPU 之间的高速、无缝通信的需求提供了支持。这对于跨多个节点同步模型参数和梯度更新尤为重要。</p>
<p><img src="/../img/LLM-tuning-08.png" alt="image-20240905092221631"></p>
<p>提高内存带宽对于优化大模型的性能有着不可忽视的作用。通过采用高速内存技术和高效的网络连接方案，并结合合理的硬件选择和软件优化策略，可以有效克服内存带宽带来的瓶颈，从而加速大模型的训练和推理过程。</p>
<h3 id="4-存储"><a href="#4-存储" class="headerlink" title="4. 存储"></a>4. 存储</h3><h4 id="4-1-传统存储方案"><a href="#4-1-传统存储方案" class="headerlink" title="4.1 传统存储方案"></a>4.1 传统存储方案</h4><ul>
<li><h5 id="HDD-机械硬盘"><a href="#HDD-机械硬盘" class="headerlink" title="HDD(机械硬盘)"></a>HDD (机械硬盘)</h5><p>HDD 使用旋转磁盘和磁头来存储和读取数据，数据存储在旋转的盘片上，磁头通过移动到正确的轨道上来读取或写入数据。HDD 的优点在于成本较低，能够提供较大的存储空间，适用于存储大量数据且对访问速度要求不高的场景。然而，由于存在机械运动，HDD 的读写速度受限于寻道时间和旋转延迟，导致访问速度较慢，并且在面对大量随机读写请求时性能会下降。此外，机械部件容易因震动或其他物理因素损坏，可靠性较低。</p>
</li>
<li><h5 id="SSD-固态硬盘"><a href="#SSD-固态硬盘" class="headerlink" title="SSD(固态硬盘)"></a>SSD (固态硬盘)</h5><p>  SSD 使用非易失性存储器（通常是 NAND 型闪存）来存储数据，没有活动部件。这使得 SSD 具有快速访问的优势，没有机械延迟，读写速度远高于 HDD，并且抗震动能力强，更加耐用。此外，SSD 的低功耗特点使其在移动设备和数据中心中广泛应用。然而，SSD 的成本通常高于同等容量的 HDD，并且写入寿命有限，尽管近年来有所改进但仍需考虑长期使用中的耐久性问题。</p>
<p>  <img src="/../img/LLM-tuning-09.png"></p>
</li>
</ul>
<h4 id="4-2-高速存储方案"><a href="#4-2-高速存储方案" class="headerlink" title="4.2 高速存储方案"></a>4.2 高速存储方案</h4><ul>
<li><h5 id="NVMe-SSD-Non-Volatile-Memory-Express"><a href="#NVMe-SSD-Non-Volatile-Memory-Express" class="headerlink" title="NVMe SSD(Non-Volatile Memory Express)"></a>NVMe SSD(Non-Volatile Memory Express)</h5>NVMe SSD 通过 PCIe 总线直接与 CPU 通信，利用闪存技术存储数据。NVMe 协议旨在充分利用高速存储介质的特点，如低延迟和高 I/O 并行性。NVMe SSD 提供了极高的带宽，因为 PCIe 接口比 SATA 或 SAS 接口提供了更高的带宽，使得数据传输速度更快。同时，由于减少了中间环节，NVMe SSD 实现了更低的访问延迟。此外，NVMe 支持多队列和多线程，允许多个读写操作同时进行，极大地提高了 I/O 性能。然而，NVMe SSD 的成本较高，尤其是在高端产品中，并且需要特定的硬件支持，可能存在兼容性问题。</li>
</ul>
<p><img src="/../img/LLM-tuning-10.png" alt="image-20240905094222746"></p>
<h4 id="4-3-存储系统与大模型"><a href="#4-3-存储系统与大模型" class="headerlink" title="4.3 存储系统与大模型"></a>4.3 存储系统与大模型</h4><p>对于大模型的训练和推理来说，存储系统的性能至关重要。HDD 虽然在容量和成本上有优势，但由于其机械结构导致的访问速度慢和可靠性问题，已逐渐被 SSD 所取代。SSD 提供了更快的读写速度和更高的可靠性，但在面对更高要求的应用场景时，如深度学习训练，NVMe SSD 凭借其极高的带宽和低延迟特性成为了优选方案。尽管 NVMe SSD 的成本较高，但对于追求极致性能的应用来说，它是不可或缺的选择。在选择存储方案时，应根据实际需求权衡成本与性能之间的关系，以达到最优的效果。</p>
<h3 id="5-冷却系统"><a href="#5-冷却系统" class="headerlink" title="5. 冷却系统"></a>5. 冷却系统</h3><h4 id="5-1-风冷"><a href="#5-1-风冷" class="headerlink" title="5.1 风冷"></a>5.1 风冷</h4><p>风冷是最常见的数据中心冷却方法之一，它通过强制空气流动来带走设备产生的热量。这种方法相对简单且成本较低，适用于大多数常规服务器和硬件配置。风冷系统的核心组成部分包括风扇、过滤器和合理的气流管理。对于大模型的优化而言，风冷系统在训练初期阶段能够提供足够的冷却能力；然而，在处理更大、更复杂的模型时，风冷系统的局限性开始显现，尤其是在高密度部署的环境下，可能无法有效应对局部热点问题，导致硬件过热，影响计算效率和稳定性。</p>
<h4 id="5-2-液冷"><a href="#5-2-液冷" class="headerlink" title="5.2 液冷"></a>5.2 液冷</h4><p>液冷技术因其高效散热能力和更低的噪音水平而变得越来越受欢迎，主要分为直接接触液冷和间接液冷两种形式。直接接触液冷特别适用于高性能计算和深度学习训练，能够提供更高密度的冷却效果，帮助维持 GPU 和 CPU 等关键部件在一个稳定的温度范围内工作，从而确保训练过程的连续性和计算资源的有效利用。液冷还能减少因过热导致的硬件损坏风险，延长硬件寿命，对大模型的优化具有显著优势。</p>
<h4 id="5-3-热通道-冷通道分离"><a href="#5-3-热通道-冷通道分离" class="headerlink" title="5.3  热通道/冷通道分离"></a>5.3  热通道 / 冷通道分离</h4><p>热通道 / 冷通道分离通过物理手段将机房内的气流分为冷通道和热通道两部分，前者专门为服务器提供冷空气，后者则收集热空气并将其引导至冷却设备或空调系统进行处理。这种设计可以显著减少混合冷热空气的情况，提高冷却系统的效能，减少能源消耗，并延长硬件使用寿命。对于大模型而言，热通道 / 冷通道分离有助于保持计算节点的温度稳定，确保训练过程中不会因为过热而导致性能下降或硬件故障，特别适合于分布式训练环境。</p>
<h3 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h3><h4 id="6-1-高效电源供应设备"><a href="#6-1-高效电源供应设备" class="headerlink" title="6.1 高效电源供应设备"></a>6.1 高效电源供应设备</h4><p>高效的电源供应设备对于优化大模型训练至关重要。80 Plus 白金或钛金认证的电源供应器能够在不同负载条件下提供至少 80% 以上的效率，最高可达 94%，显著减少能量转换过程中的损耗。数字电源管理技术通过实时调整电源输出，确保在各种负载条件下保持高效运作，从而实现更精细的能量管理，减少能源浪费。</p>
<h4 id="6-2-动态功耗管理技术"><a href="#6-2-动态功耗管理技术" class="headerlink" title="6.2 动态功耗管理技术"></a>6.2 动态功耗管理技术</h4><p>动态功耗管理技术如动态电压和频率调整（DVFS）可以根据实际负载动态调整 CPU 和 GPU 的电压和频率。在低负载时降低电压和频率可以大幅减少功耗，而在高负载时则可以迅速恢复性能。此外，智能休眠模式可以在无活动或低负载时将部分硬件单元暂时置于休眠状态，进一步节省能源，确保大模型训练过程中能源使用的高效性。</p>
<h4 id="6-3-不间断电源-UPS-和冗余设计"><a href="#6-3-不间断电源-UPS-和冗余设计" class="headerlink" title="6.3 不间断电源 (UPS) 和冗余设计"></a>6.3 不间断电源 (UPS) 和冗余设计</h4><p>不间断电源（UPS）系统可以在电网供电中断时立即提供备用电源，确保系统不会因突然断电而停止运行，这对于长时间运行的大模型训练任务至关重要。冗余电源设计通过在关键硬件中部署冗余电源，确保即使其中一个电源故障，系统仍能继续运行，提高系统的可靠性和可用性。</p>
<h4 id="6-4-能源监测与管理"><a href="#6-4-能源监测与管理" class="headerlink" title="6.4 能源监测与管理"></a>6.4 能源监测与管理</h4><p>智能监控系统可以实时监测电源的使用情况，识别异常情况，并及时采取措施，例如调整负载分配以优化能源使用。自动化管理系统可以根据实际需求动态调整电源配置，在非高峰时段减少某些硬件的供电，在高峰期增加供电，确保能源使用的最大化效率，从而提高数据中心的整体能效比。</p>
<hr>
<h2 id="输出效果调优"><a href="#输出效果调优" class="headerlink" title="输出效果调优"></a>输出效果调优</h2><h3 id="1-优化数据"><a href="#1-优化数据" class="headerlink" title="1. 优化数据"></a>1. 优化数据</h3><h4 id="1-1-数据的重要性"><a href="#1-1-数据的重要性" class="headerlink" title="1.1 数据的重要性"></a>1.1 数据的重要性</h4><p>大规模语言模型的开发依赖于广泛而多元的数据资源。研究文献详细阐述了人类在训练 GPT-3 模型时主要利用的数据源，这包括经筛选的 CommonCrawl 数据集、WebText2、Books1、Books2 以及英文版 Wikipedia 等。例如，CommonCrawl 的初始数据量高达 45TB，筛选后仅剩 570GB。通过分词技术处理上述资料，大约产生了 5000 亿个词元。为了确保模型能够利用高品质数据进行学习，GPT-3 的训练过程中根据数据来源的差异调整了采样权重。在完成 3000 亿词元的训练量时，英文版 Wikipedia 的数据平均被循环利用了 3.4 次，而 CommonCrawl 和 Books2 的数据循环使用率分别仅为 0.44 次和 0.43 次。鉴于 CommonCrawl 数据集的筛选工作极为复杂，Meta 公司的研究团队在训练 OP 模型时采纳了结合 RoBERTa、Pile [68] 以及 PushShift.io Reddit 数据的策略。考虑到这些数据集主要以英文为主，OPT 模型也从 CommonCrawl 中提取了一部分非英文数据以丰富训练语料。大型语言模型所需的数据资源大致可分为通用数据和专业数据两类。通用数据涵盖了网页内容、图书、新闻报道、对话文本等，以其庞大的规模、多样性和易于获取的特点，为大型语言模型提供了基础的语言建模和泛化能力。而专业数据则包括多语言资料、科学文献、编程代码以及特定领域的专有信息等，这些在预训练阶段的引入，能够显著增强大型语言模型解决特定任务的能力。</p>
<p style="text-align: center">典型大语言模型所使用数量类型的分布</p>

<p><img src="/../img/LLM-tuning-11.png" alt="image-20240905101311693"></p>
<h4 id="1-2-数据回流方案"><a href="#1-2-数据回流方案" class="headerlink" title="1.2 数据回流方案"></a>1.2 数据回流方案</h4><p>数据回流是指将模型生成的数据或预测结果重新引入到训练流程中，以此来更新模型。这种方法可以用于增强模型的学习能力，尤其是在面对那些随着时间变化而变化的数据集时。通过持续地将新产生的数据反馈给模型，可以让模型适应新的模式或纠正之前的偏差，从而提高其泛化能力和预测准确性。</p>
<h3 id="2-调整超参数"><a href="#2-调整超参数" class="headerlink" title="2. 调整超参数"></a>2. 调整超参数</h3><p>调整超参数是指在训练模型之前选择一组最佳的参数值的过程，这些参数不是直接通过学习过程获得的。超参数包括学习率、批次大小、正则化系数等。合理的超参数设置对于模型的表现至关重要。通常，人们会采用网格搜索、随机搜索或贝叶斯优化等方法来进行超参数的优化，以找到能够最大化模型性能的一组超参数组合。</p>
<p><img src="/../img/LLM-tuning-12.png" alt="image-20240905101432943"></p>
<h3 id="3-提示词工程-Prompt-Engineering"><a href="#3-提示词工程-Prompt-Engineering" class="headerlink" title="3. 提示词工程  (Prompt Engineering)"></a>3. 提示词工程  (Prompt Engineering)</h3><p>提示词工程是指精心设计输入给模型的提示词，以便引导模型产生更符合期望的输出。这种技术特别适用于那些基于自然语言处理的大规模预训练模型。通过调整提示词的内容、结构以及语气，可以显著影响模型生成的结果。例如，在某些场景下，使用更正式的语言或提供更多的上下文信息可以促使模型生成更为准确和连贯的回答。提示词工程还可以用来控制生成内容的风格、语气甚至创造力水平。</p>
<p><img src="/../img/LLM-tuning-13.png" alt="image-20240905101633553"></p>
<h3 id="4-检索增强生成-Retrieval-Augmented-Generation-RAG"><a href="#4-检索增强生成-Retrieval-Augmented-Generation-RAG" class="headerlink" title="4. 检索增强生成(Retrieval-Augmented Generation, RAG)"></a>4. 检索增强生成 (Retrieval-Augmented Generation, RAG)</h3><p>检索增强生成是一种结合了检索技术和生成模型的方法，它允许模型在生成答案或内容时参考一个外部的知识库。这样做的好处是可以利用大量静态或动态的信息来增强生成的质量，特别是在处理那些需要精确信息或最新数据的任务时。RAG 可以提升生成内容的相关性和准确性，尤其是在对话系统、问答系统或文本摘要等领域。</p>
<p><img src="/../img/LLM-tuning-14.png" alt="image-20240905101730828"></p>
<h3 id="5-微调预训练模型"><a href="#5-微调预训练模型" class="headerlink" title="5. 微调预训练模型"></a>5. 微调预训练模型</h3><p>微调预训练模型是指在一个已经预先训练好的模型基础上，针对特定任务进一步训练模型的过程。预训练模型通常是在大规模数据上训练得到的，拥有良好的通用特征提取能力。通过在特定任务的小数据集上继续训练，可以使得模型更加专注于解决该任务，从而提升模型在特定领域或任务上的表现。</p>
<p style="text-align:center">微调各种尺寸大模型的硬件要求</p>

<p><img src="/LLM-tuning-17.png" alt="PixPin_2024-09-05_10-46-18"></p>
<h4 id="5-1-有监督微调-SFT"><a href="#5-1-有监督微调-SFT" class="headerlink" title="5.1 有监督微调(SFT)"></a>5.1 有监督微调 (SFT)</h4><p>在自然语言处理（NLP）领域，Supervised Finetuning（SFT）是一种至关重要的技术手段，用来提升大模型在某一特定领域的表现。通过精细的策划和实施，SFT 能够指导模型的学习过程，确保其学习成果与既定目标高度吻合。</p>
<p>SFT 指的是，用户提供一份标注好的数据集，即，包含输入的 prompt 和预期输出的 response。然后，在已有的某个基座模型上继续调整参数，来达到和下游任务对齐的目的。</p>
<h5 id="5-1-1-什么时候需要用到SFT"><a href="#5-1-1-什么时候需要用到SFT" class="headerlink" title="5.1.1 什么时候需要用到SFT ?"></a>5.1.1 什么时候需要用到 SFT ?</h5><ol>
<li>通过提示词工程无法解决或提示词中描述过于复杂时。</li>
<li>对大模型输出内容有格式要求时，而模型仍有部分条件不符合要求。</li>
<li>期望通过 SFT 来减少 prompt 中的内容，加速线上推理的耗时。</li>
</ol>
<h5 id="5-1-2-SFT数据格式"><a href="#5-1-2-SFT数据格式" class="headerlink" title="5.1.2 SFT数据格式"></a>5.1.2 SFT 数据格式</h5><p><img src="/../img/LLM-tuning-15.png" alt="image-20240905102047209"></p>
<p>每行一条 JSON 格式的数据：</p>
<ul>
<li><p>messages (list, required): 描述一个对话列表。</p>
</li>
<li><p>role (str, required): 角色，system、user、assistant 中的一个。</p>
</li>
<li><p>content (str, required): 对话内容文本。</p>
</li>
<li><p>loss_weight (float, optional): 对于内容的 loss 训练权重。当 role=system/user，loss_weight 默认值为 0.0 且不可修改；当 role=assistant，loss_weight 默认值为 1.0。通过 loss_weight 字段，可以在训练数据中修改默认值。</p>
</li>
</ul>
<h5 id="5-1-3-SFT微调所需数据量级"><a href="#5-1-3-SFT微调所需数据量级" class="headerlink" title="5.1.3 SFT微调所需数据量级"></a>5.1.3 SFT 微调所需数据量级</h5><p>模型中 SFT 的过程中，会学习 prompt 到 response 到映射关系，如果我们 SFT 的数据存在噪声（如错别字、错误格式、不符合预期输出的样本等），那么会对模型的训练过程造成比较严重的影响。因此，不可以一味去堆叠 SFT 的样本数量，样本的质量比数量更重要。</p>
<p>针对不同场景下，数据量级的建议：</p>
<ul>
<li><p>文案生成，剧本创作，小说续写等生成类任务：2～3k。</p>
</li>
<li><p>参考问答：2k ~ 1w。</p>
</li>
<li><p>文本分类：1～3k，和类别数量以及任务难易度强相关，类别较多 / 任务较难的场景可能需要 1w 条以上。</p>
</li>
</ul>
<h4 id="5-2-LoRA微调"><a href="#5-2-LoRA微调" class="headerlink" title="5.2 LoRA微调"></a>5.2 LoRA 微调</h4><h5 id="5-2-1-什么是LoRA"><a href="#5-2-1-什么是LoRA" class="headerlink" title="5.2.1 什么是LoRA ?"></a>5.2.1 什么是 LoRA ?</h5><p>LoRA（Low-Rank Adaptation of Large Language Models），直译为大语言模型的低阶自适应。LoRA 的基本原理是冻结预训练好的模型权重参数，在冻结原模型参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅 finetune 的成本显著下降，还能获得和全模型参数参与微调类似的效果。</p>
<p>随着大语言模型的发展，模型的参数量越来越大，比如 GPT-3 参数量已经高达 1750 亿，因此，微调所有模型参数变得不可行。LoRA 微调方法由微软提出，通过只微调新增参数的方式，大大减少了下游任务的可训练参数数量。</p>
<h5 id="5-2-2-LoRA微调方法的基本原理"><a href="#5-2-2-LoRA微调方法的基本原理" class="headerlink" title="5.2.2 LoRA微调方法的基本原理"></a>5.2.2 LoRA 微调方法的基本原理</h5><p>神经网络的每一层都包含矩阵的乘法。这些层中的权重矩阵通常具有满秩。当适应特定任务时，预训练语言模型具有低的 “内在维度”，将它们随机投影到更小的子空间时，它们仍然可以有效地学习。</p>
<p>在大语言模型微调的过程中，LoRA 冻结了预先训练好的模型权重，并将可训练的秩的分解矩阵注入到 Transformer 体系结构的每一层。例如，对于预训练的权重矩阵 W0，可以让其更新受到用低秩分解表示后者的约束：</p>
<ul>
<li>跟踪权重的变化而不是直接更新它们。</li>
<li>将大型权重矩阵分解为包含 “可训练参数” 的较小矩阵。</li>
</ul>
<p><img src="/../img/LLM-tuning-16.png" alt="1_N7Mrnoyvz9Qths1cC92WuQ"></p>
<h5 id="5-2-3-LoRA微调的优势"><a href="#5-2-3-LoRA微调的优势" class="headerlink" title="5.2.3 LoRA微调的优势"></a>5.2.3 LoRA 微调的优势</h5><ol>
<li>可训练参数显着减少，从而实现更快、更高效的微调。</li>
<li>保留原始的预训练权重，允许针对不同任务使用多个轻量级模型。</li>
<li>与其他参数高效方法兼容，可实现进一步优化。</li>
<li>在许多情况下，其性能可与完全微调的模型相媲美。</li>
<li>没有额外的推理延迟，因为适配器权重可以与基本模型合并。</li>
</ol>
<h5 id="5-2-4-QLoRA微调"><a href="#5-2-4-QLoRA微调" class="headerlink" title="5.2.4 QLoRA微调"></a>5.2.4 QLoRA 微调</h5><p>QLoRa 通过量化可训练参数，用更少的位数表示它们，使 LORA 更进一步。这进一步减小了模型大小，有可能实现在内存和计算资源有限的设备上的部署。</p>
<h4 id="5-3-Freeze微调"><a href="#5-3-Freeze微调" class="headerlink" title="5.3 Freeze微调"></a>5.3 Freeze 微调</h4><p>Freeze 方法，即参数冻结，对原始模型部分参数进行冻结操作，仅训练部分参数，以达到在单卡或不进行 TP 或 PP 操作，就可以对大模型进行训练。在语言模型模型微调中，Freeze 微调方法仅微调 Transformer 后几层的全连接层参数，而冻结其它所有参数。</p>
<h4 id="5-4-GaLore微调"><a href="#5-4-GaLore微调" class="headerlink" title="5.4 GaLore微调"></a>5.4 GaLore 微调</h4><p>GaLore 是一种允许全参数学习的训练策略，但比常见的低秩自适应方法（例如 LoRA）更节省内存。GaLore 关键思想是利用权重矩阵 W 的梯度缓慢变化的低秩结构，而不是试图将权重矩阵直接近似为低秩形式。使得在消费级 GPU 上训练大型语言模型成为可能。这一策略为未来的大模型训练提供了重要的技术支持，具有广泛的应用前景。</p>
<p><img src="/../img/LLM-tuning-18.png" alt="198"></p>
<h3 id="6-代理-Agent"><a href="#6-代理-Agent" class="headerlink" title="6. 代理(Agent)"></a>6. 代理 (Agent)</h3><p>增加辅助代理是指在主要模型之外引入其他小模型或组件，这些辅助代理可以帮助主模型更好地完成任务。辅助代理可能负责不同的子任务，如噪声过滤、特征增强、错误检测等，它们的工作成果可以作为额外的信息提供给主模型，从而帮助主模型做出更准确的决策。这种方法可以提高系统的鲁棒性和灵活性，使其在复杂环境中表现出色。</p>
<p><img src="/../img/LLM-tuning-26.png" alt="image-20240905142400736"></p>
<hr>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><h3 id="1-模型深度与宽度的平衡"><a href="#1-模型深度与宽度的平衡" class="headerlink" title="1. 模型深度与宽度的平衡"></a>1. 模型深度与宽度的平衡</h3><p>在语言模型中，增加模型的深度可以使其捕获更复杂的语言结构，而增加宽度则可以提供更多的表达能力。然而，深度和宽度的增加都会带来更高的计算成本和潜在的过拟合风险。可以通过实验来确定最优的层数和每层的隐藏单元数，找到一个既能提高模型性能又不会过度增加训练时间的平衡点。<img src="/../img/LLM-tuning-19.png" alt="image-20240905134548220"></p>
<h3 id="2-残差连接"><a href="#2-残差连接" class="headerlink" title="2. 残差连接"></a>2. 残差连接</h3><p>在语言模型中引入残差连接可以帮助模型更好地学习长期依赖关系，并减轻梯度消失的问题。通过让信息流绕过一层或多层，模型可以更容易地学习到输入与输出之间的映射关系。</p>
<p><img src="/../img/LLM-tuning-20.png" alt="ResBlock"></p>
<h3 id="3-注意力机制"><a href="#3-注意力机制" class="headerlink" title="3. 注意力机制"></a>3. 注意力机制</h3><p>在语言模型中使用自注意力机制，可以让模型学习到输入序列中不同位置之间的相关性。这种机制尤其适合处理变长的输入序列，因为它能够动态地为不同位置的词分配不同的权重。</p>
<h3 id="4-多头注意力"><a href="#4-多头注意力" class="headerlink" title="4. 多头注意力"></a>4. 多头注意力</h3><p>通过将注意力机制分成多个头，每个头可以独立地关注输入的不同方面。这种方式能够增强模型对输入的多样性和复杂性的理解，从而提升整体性能。</p>
<h3 id="5-Transformer架构"><a href="#5-Transformer架构" class="headerlink" title="5. Transformer架构"></a>5. Transformer 架构</h3><p>即便不采用卷积，也可以使用基于注意力机制的 Transformer 架构来构建语言模型。这种架构通过完全依赖自注意力机制来处理序列数据，避免了传统 RNN 中顺序依赖的问题，并且能够并行化训练过程，加快训练速度。即便不采用卷积，也可以使用基于注意力机制的 Transformer 架构来构建语言模型。这种架构通过完全依赖自注意力机制来处理序列数据，避免了传统 RNN 中顺序依赖的问题，并且能够并行化训练过程，加快训练速度。</p>
<p><img src="/../img/LLM-tuning-21.png" alt="image-20240905135346186"></p>
<h3 id="6-正则化技术"><a href="#6-正则化技术" class="headerlink" title="6. 正则化技术"></a>6. 正则化技术</h3><p>为了防止过拟合，可以在模型中加入正则化技术，比如 Dropout，它通过在训练过程中随机关闭一部分神经元来提高模型的鲁棒性。此外，还可以使用权重衰减等其他形式的正则化来约束模型复杂度。</p>
<p style="text-align:center">应用于标准神经网络的 Dropout</p>

<p><img src="/LLM-tuning-22.png" alt="image-20240905135513919"></p>
<h3 id="7-混合专家-Mixture-of-Experts-MoE"><a href="#7-混合专家-Mixture-of-Experts-MoE" class="headerlink" title="7 混合专家(Mixture of Experts, MoE)"></a>7 混合专家 (Mixture of Experts, MoE)</h3><p>在语言模型中，MoE 架构允许模型根据输入选择不同的专家来处理，从而在不增加太多参数的情况下提高模型的容量和表现力。这种方式特别适用于需要处理多种类型数据的语言任务。</p>
<p style="text-align:center">MoE 架构的核心组件</p>

<p><img src="/LLM-tuning-23.png" alt="image-20240905135601961"></p>
<hr>
]]></content>
      <categories>
        <category>Knowledge</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Openai API 进行接口移植</title>
    <url>/2024/07/25/Python/20240725_%E5%9F%BA%E4%BA%8EOpenai%E6%8E%A5%E5%8F%A3%E6%8B%93%E5%B1%95%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>记录一下 基于 Openai API 进行接口移植的过程，从引用 api 到测试到最后转接口使用</p>
<span id="more"></span>



<blockquote>
<h3 id="注册Openai-API账号"><a href="#注册Openai-API账号" class="headerlink" title="注册Openai API账号"></a>注册 Openai API 账号</h3><ul>
<li>老生常谈的问题 ，首先我们需要注册一个 Openai API 账号，并申请一个 API key，或者购买一个 API_KEY。</li>
<li><strong>申请点击此链接:<a href="https://platform.openai.com/login?launch">openai API 官网链接</a></strong></li>
</ul>
</blockquote>
<hr>
<h3 id="1-调用openai的GPT-4o模型接口"><a href="#1-调用openai的GPT-4o模型接口" class="headerlink" title="1.调用openai的GPT-4o模型接口"></a>1. 调用 openai 的 GPT-4o 模型接口</h3><ul>
<li><p>OK 还是最常见的 chat_generate，这里直接放代码了</p>
 <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="comment">#这里就放入刚刚购买到的key就可以啦</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> opneai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gpt_generate_text</span>(<span class="params">prompt, messages_list</span>):</span><br><span class="line">    messages = <span class="string">''</span></span><br><span class="line">    <span class="keyword">if</span> messages_list:</span><br><span class="line">        messages = <span class="string">'以下是你和用户的当前会话消息：\n\n'</span> + <span class="string">'\n'</span>.join(messages_list)</span><br><span class="line">    stream = client.chat.completions.create(</span><br><span class="line">        <span class="comment"># model="gpt-4-turbo-preview",</span></span><br><span class="line">        model=<span class="string">"gpt-4o"</span>,</span><br><span class="line">        messages=[</span><br><span class="line">            {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: messages},</span><br><span class="line">            {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt},</span><br><span class="line">        ],</span><br><span class="line">        stream=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    text = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> stream:</span><br><span class="line">        <span class="keyword">if</span> chunk.choices[<span class="number">0</span>].delta.content <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(chunk.choices[<span class="number">0</span>].delta.content, end=<span class="string">""</span>)</span><br><span class="line">            text += chunk.choices[<span class="number">0</span>].delta.content</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>这里是<strong>路由函数</strong>的撰写</p>
<ul>
<li><p>可以看到这里可以通过 GET 和 POST （GET 不可以用哦）, 这里调用我们的 gpt_generate_text 函数，传入 prompt 和 messages_list，然后返回生成的文本。</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">"/chatgpt"</span>, methods=[<span class="string">'GET'</span>, <span class="string">'POST'</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat_with_gpt</span>():</span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">'GET'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'chatgpt GET 请求'</span></span><br><span class="line">    <span class="keyword">elif</span> request.method == <span class="string">'POST'</span>:</span><br><span class="line">        data = request.json</span><br><span class="line">        prompt = data[<span class="string">'prompt'</span>]</span><br><span class="line">        messages_list = data.get(<span class="string">'messages'</span>, [])</span><br><span class="line">        text = gpt_generate_text(prompt, messages_list)</span><br><span class="line"></span><br><span class="line">        timestamp = <span class="built_in">str</span>(time.time()).split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> text:</span><br><span class="line">            response_data = {</span><br><span class="line">                <span class="string">'code'</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">'message'</span>: <span class="string">'内容生成成功'</span>,</span><br><span class="line">                <span class="string">'time'</span>: timestamp,</span><br><span class="line">                <span class="string">'data'</span>: {<span class="string">'text'</span>: text}</span><br><span class="line">            }</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            response_data = {</span><br><span class="line">                <span class="string">'code'</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">'message'</span>: <span class="string">'内容生成失败'</span>,</span><br><span class="line">                <span class="string">'time'</span>: timestamp,</span><br><span class="line">                <span class="string">'data'</span>: {<span class="string">'text'</span>: <span class="literal">None</span>}</span><br><span class="line">            }</span><br><span class="line">        <span class="keyword">return</span> jsonify(response_data)</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-调用Openai的whisper-1模型接口"><a href="#2-调用Openai的whisper-1模型接口" class="headerlink" title="2.调用Openai的whisper-1模型接口"></a>2. 调用 Openai 的 whisper-1 模型接口</h2><ul>
<li>2.1 同理这里是调用的 openai 的 <strong>whisper-1</strong> 模型进行音频转文本的函数撰写 <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transcribe_audio</span>(<span class="params">audio_file</span>):</span><br><span class="line">    audio=<span class="built_in">open</span>(audio_file, <span class="string">"rb"</span>)</span><br><span class="line">    transcription = client.audio.transcriptions.create(model=<span class="string">"whisper-1"</span>,file=audio)</span><br><span class="line">    text = transcription.text</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></tbody></table></figure></li>
<li>2.2 这里是最后<strong>路由函数</strong>的撰写 <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">"/transcribe"</span>, methods=[<span class="string">'POST'</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transcribe</span>():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'file'</span> <span class="keyword">not</span> <span class="keyword">in</span> request.files:</span><br><span class="line">        <span class="keyword">return</span> jsonify({<span class="string">"error"</span>: <span class="string">"No file part"</span>}), <span class="number">400</span></span><br><span class="line">    </span><br><span class="line">    audio_file = request.files[<span class="string">'file'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> audio_file.filename == <span class="string">''</span>:</span><br><span class="line">        <span class="keyword">return</span> jsonify({<span class="string">"error"</span>: <span class="string">"No selected file"</span>}), <span class="number">400</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> audio_file:</span><br><span class="line">        <span class="comment"># 保存文件到临时位置</span></span><br><span class="line">        temp_file_path = os.path.join(<span class="string">"temp"</span>, audio_file.filename)</span><br><span class="line">        audio_file.save(temp_file_path)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用转录函数</span></span><br><span class="line">        transcription_text = transcribe_audio(temp_file_path)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 删除临时文件</span></span><br><span class="line">        os.remove(temp_file_path)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> jsonify({<span class="string">"text"</span>: transcription_text})</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<blockquote>
<ul>
<li>首先我们要确定返回的请求中是否包含文件和文件名，如果没有，则返回错误信息和 400，</li>
<li>其次，我们需要保存文件到临时位置，然后调用我们写好的转录函数进行转录，最后删除临时文件。</li>
<li>最后返回转录后的文本给客户端 供使用。</li>
</ul>
</blockquote>
<hr>
<h2 id="3-调用Openai的TTS-1模型接口"><a href="#3-调用Openai的TTS-1模型接口" class="headerlink" title="3.调用Openai的TTS-1模型接口"></a>3. 调用 Openai 的 TTS-1 模型接口</h2><ul>
<li>3.1 调用 openai 的 API，将文本转换为语音 <figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">def text_to_speech(text, vocie, model, path):</span><br><span class="line">    </span><br><span class="line">    response = client.audio.speech.create(</span><br><span class="line">        model=model,</span><br><span class="line">        voice=vocie,</span><br><span class="line">        input=text</span><br><span class="line">    )</span><br><span class="line">    speech_file_path = Path(path)</span><br><span class="line">    with open(speech_file_path, 'wb') as file:</span><br><span class="line">        file.write(response.content)</span><br><span class="line"></span><br><span class="line">    print(f'文件已保存到: {speech_file_path}')</span><br><span class="line">    return speech_file_path</span><br></pre></td></tr></tbody></table></figure></li>
<li>3.2 文本转语音 text-to-speech 路由撰写 <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">app = Flask(__name__)</span><br><span class="line">server_ip = <span class="string">""</span>  <span class="comment"># 替换为你的服务器IP</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">'/text-to-speech'</span>, methods=[<span class="string">'POST'</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">text_to_speech_endpoint</span>():</span><br><span class="line">    data = request.json</span><br><span class="line">    text = data.get(<span class="string">'text'</span>)</span><br><span class="line">    voice = data.get(<span class="string">'voice'</span>)</span><br><span class="line">    model = data.get(<span class="string">'model'</span>)</span><br><span class="line">    output_path = <span class="string">'./output.mp3'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> text <span class="keyword">or</span> <span class="keyword">not</span> voice <span class="keyword">or</span> <span class="keyword">not</span> model:</span><br><span class="line">        <span class="keyword">return</span> {<span class="string">'error'</span>: <span class="string">'Missing required parameters'</span>}, <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># Define the directory where you want to save the files</span></span><br><span class="line">        output_dir = Path(<span class="string">'./audio_files'</span>)</span><br><span class="line">        output_dir.mkdir(exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate a unique filename using UUID</span></span><br><span class="line">        unique_filename = <span class="string">f"<span class="subst">{uuid.uuid4()}</span>.mp3"</span></span><br><span class="line">        output_path = output_dir / unique_filename</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate the speech and save the file</span></span><br><span class="line">        speech_file_path = text_to_speech(text, voice, model, output_path)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Create the file URL</span></span><br><span class="line">        file_url = <span class="string">f"http://<span class="subst">{server_ip}</span>/root/xxx/<span class="subst">{speech_file_path}</span>"</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Return the file URL as a response</span></span><br><span class="line">        <span class="keyword">return</span> jsonify({<span class="string">'file_url'</span>: file_url}), <span class="number">200</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> jsonify({<span class="string">'error'</span>: <span class="built_in">str</span>(e)}), <span class="number">500</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<ul>
<li>首先我们要在后端代码中写入 我们的服务器 ip 地址</li>
<li>我们要确保我们的 json 数据存在 四个键 text ， voice ， model ， output_path ，</li>
<li>其次我们调用 text_to_speech 函数，传入 text，voice，model，output_path，</li>
<li>然后我们生成一个唯一的 filename，保存到 output_dir 目录下</li>
<li>最后我们生成一个 file_url，然后返回给客户端。</li>
</ul>
</blockquote>
</li>
</ul>
<hr>
<h2 id="4-测试使用"><a href="#4-测试使用" class="headerlink" title="4.测试使用"></a>4. 测试使用</h2><ul>
<li>4.1 我们可以使用以下方式，这种方式在我们的 py 脚本下直接测试，传参切记</li>
</ul>
<p>​	 <code>if __name__ == "__main__":</code><br>​	    	<code>main()</code></p>
<ul>
<li><p>4.2 使用 命令行在我们的服务器上测试 GET <a href="http://xxxx/">http://xxxx</a> {“xx”:”xx”}</p>
</li>
<li><p>4.3 使用 postman 、apifox 等等工具测试</p>
</li>
</ul>
<p>​	本人这里使用的是第三种方法 apifox 这个工具，本人良心推荐大家使用，附<a href="https://apifox.com/help/">官方文档链接</a></p>
<ul>
<li><p> 4.4 测试截图及测试数据</p>
<h3 id="测试用例一-chatgpt"><a href="#测试用例一-chatgpt" class="headerlink" title="测试用例一: /chatgpt"></a>测试用例一: /chatgpt</h3><ul>
<li>测试数据 </li>
</ul>
  <figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"code"</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"data"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"text"</span><span class="punctuation">:</span> <span class="string">"你好！我是一个由人工智能驱动的助手，设计用于帮助回答问题、提供信息以及协助完成各种任务。有什么我可以帮你的吗？"</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"message"</span><span class="punctuation">:</span> <span class="string">"内容生成成功"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"time"</span><span class="punctuation">:</span> <span class="string">"1721808765"</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>响应截图</li>
</ul>
<p>  <img src="/../../img/api-1.jpg" alt="gpt4o"></p>
<hr>
<h3 id="测试用例二-transcribe"><a href="#测试用例二-transcribe" class="headerlink" title="测试用例二: /transcribe"></a>测试用例二: /transcribe</h3><ul>
<li>测试数据</li>
</ul>
<p>  <img src="/../../img/api-2-1.jpg" alt="音频文件截图"></p>
<ul>
<li>响应截图</li>
</ul>
<p>  <img src="/../../img/api-2.jpg" alt="gpt4o"></p>
<hr>
<h3 id="测试用例三-transcribe"><a href="#测试用例三-transcribe" class="headerlink" title="测试用例三: /transcribe"></a>测试用例三: /transcribe</h3><ul>
<li><p>测试数据</p>
   <figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"model"</span><span class="punctuation">:</span><span class="string">"tts-1"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"voice"</span><span class="punctuation">:</span><span class="string">"echo"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"text"</span><span class="punctuation">:</span><span class="string">"今天中午吃什么?"</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>响应截图</p>
<p><img src="/../../img/api-3.jpg" alt="gpt4o"></p>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>自研工具 - 基于 Nvidia 驱动日志 (Events.log) 统计网络震荡次数</title>
    <url>/2024/05/24/Python/20240524_%E5%BC%80%E5%8F%91%E5%88%86%E6%9E%90Nvidia%E9%A9%B1%E5%8A%A8%E9%97%AE%E9%A2%98%E6%97%A5%E5%BF%97%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>统计 Link Down 的次数，并显示服务名称和计算机名称</p>
<p><img src="/../../img/linkdown-1.png"></p>
<span id="more"></span>

<ul>
<li><p>代码部分</p>
  <figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">@File    :   count_dict-v3.py</span></span><br><span class="line"><span class="string">@Time    :   2024/05/13 09:19:02</span></span><br><span class="line"><span class="string">@Author  :   pan binghong </span></span><br><span class="line"><span class="string">@Email   :   19909442097@163.com</span></span><br><span class="line"><span class="string">@description   :   统计Link Down的次数，并显示服务名称和计算机名称</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> tkinter <span class="keyword">as</span> tk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> ttk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> filedialog</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_csv_and_process</span>():</span><br><span class="line">    file_path = filedialog.askopenfilename(filetypes=[(<span class="string">'CSV文件'</span>, <span class="string">'*.csv'</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> file_path:</span><br><span class="line">        df = pd.read_csv(file_path)</span><br><span class="line">        df_warning = df[(df[<span class="string">'Severity'</span>] == <span class="string">'Warning'</span>) &amp; (df[<span class="string">'Event Name'</span>] == <span class="string">'Link is Down'</span>)]</span><br><span class="line">        pattern1 = re.<span class="built_in">compile</span>(<span class="string">r'Source\s+([a-fA-F0-9]+)'</span>)</span><br><span class="line">        mac_list = []</span><br><span class="line">        <span class="keyword">for</span> source <span class="keyword">in</span> df_warning[<span class="string">'Source'</span>]:</span><br><span class="line">            match1 = pattern1.search(source)</span><br><span class="line">            <span class="keyword">if</span> match1:</span><br><span class="line">                mac_list.append(match1.group(<span class="number">1</span>))</span><br><span class="line">        time0 = df_warning[<span class="string">'Date/Time'</span>].iloc[-<span class="number">1</span>]</span><br><span class="line">        time1 = df_warning[<span class="string">'Date/Time'</span>].iloc[<span class="number">0</span>]</span><br><span class="line">        df_result = find_service_names_and_counts(mac_list, mac_dict, time_list=[time0, time1])</span><br><span class="line">        df_result_computer = find_computer_names_and_counts(df_warning[<span class="string">'Description'</span>], time_list=[time0, time1])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 清除之前的表格内容（如果有的话）</span></span><br><span class="line">        <span class="keyword">for</span> widget <span class="keyword">in</span> frame.winfo_children():</span><br><span class="line">            widget.destroy()</span><br><span class="line"></span><br><span class="line">        notebook = ttk.Notebook(frame)</span><br><span class="line">        notebook.pack(fill=<span class="string">'both'</span>, expand=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第一页：服务名称统计</span></span><br><span class="line">        service_frame = ttk.Frame(notebook)</span><br><span class="line">        notebook.add(service_frame, text=<span class="string">'Service Name'</span>)</span><br><span class="line">        show_dataframe_in_gui(df_result, service_frame)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二页：计算机名称统计</span></span><br><span class="line">        computer_frame = ttk.Frame(notebook)</span><br><span class="line">        notebook.add(computer_frame, text=<span class="string">'Computer Name'</span>)</span><br><span class="line">        show_dataframe_in_gui(df_result_computer, computer_frame)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_computer_names_and_counts</span>(<span class="params">descriptions, time_list</span>):  </span><br><span class="line">    start_time, end_time = time_list  </span><br><span class="line">    <span class="comment"># 创建一个字典来记录每个计算机名称的linkdown次数  </span></span><br><span class="line">    computer_counts = {}  </span><br><span class="line">    sum_counts = <span class="number">0</span>  </span><br><span class="line">    pattern2 = re.<span class="built_in">compile</span>(<span class="string">r'\(Computer:([^)]+)\)'</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> desc <span class="keyword">in</span> descriptions:  </span><br><span class="line">        match2 = pattern2.search(desc)  </span><br><span class="line">        <span class="keyword">if</span> match2:  </span><br><span class="line">            computer_name = match2.group(<span class="number">1</span>)  </span><br><span class="line">            computer_counts[computer_name] = computer_counts.get(computer_name, <span class="number">0</span>) + <span class="number">1</span>  </span><br><span class="line">            sum_counts += <span class="number">1</span>  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建不包含时间信息的DataFrame  </span></span><br><span class="line">    df_result_computer = pd.DataFrame.from_dict(computer_counts, orient=<span class="string">'index'</span>, columns=[<span class="string">'Count of Link is Down'</span>]).reset_index()  </span><br><span class="line">    df_result_computer.columns = [<span class="string">'Computer Name'</span>, <span class="string">'Count of Link is Down'</span>]  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个新行来保存时间信息  </span></span><br><span class="line">    time_info_row = pd.Series([<span class="string">'Start Time: '</span> + start_time, <span class="string">'End Time: '</span> + end_time], index=[<span class="string">'Computer Name'</span>, <span class="string">'Count of Link is Down'</span>])  </span><br><span class="line">    time_info_df = pd.DataFrame([time_info_row])  <span class="comment"># 将Series转换为DataFrame  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将时间信息DataFrame放在原始DataFrame的开始位置  </span></span><br><span class="line">    df_result_computer = pd.concat([time_info_df, df_result_computer]).reset_index(drop=<span class="literal">True</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在DataFrame的末尾添加一行总次数  </span></span><br><span class="line">    total_row = pd.DataFrame({<span class="string">'Computer Name'</span>: [<span class="string">'Total'</span>], <span class="string">'Count of Link is Down'</span>: [sum_counts]}, index=[<span class="built_in">len</span>(df_result_computer)])  </span><br><span class="line">    df_result_computer = pd.concat([df_result_computer.iloc[:-<span class="number">1</span>], total_row]).reset_index(drop=<span class="literal">True</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df_result_computer </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_service_names_and_counts</span>(<span class="params">mac_list, mac_dict, time_list</span>):  </span><br><span class="line">    <span class="comment"># 假设time_list有两个元素: [开始时间, 结束时间]  </span></span><br><span class="line">    start_time, end_time = time_list  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个字典来记录每个服务名称的linkdown次数  </span></span><br><span class="line">    service_counts = {}  </span><br><span class="line">    sum_counts = <span class="number">0</span>  </span><br><span class="line">    <span class="comment"># 遍历mac_list中的每个MAC地址  </span></span><br><span class="line">    <span class="keyword">for</span> mac <span class="keyword">in</span> mac_list:  </span><br><span class="line">        <span class="comment"># 查找MAC地址在哪个服务名称的列表中  </span></span><br><span class="line">        <span class="keyword">for</span> service_name, macs <span class="keyword">in</span> mac_dict.items():  </span><br><span class="line">            <span class="keyword">if</span> mac <span class="keyword">in</span> macs:  </span><br><span class="line">                <span class="comment"># 如果找到，增加该服务名称的计数  </span></span><br><span class="line">                service_counts[service_name] = service_counts.get(service_name, <span class="number">0</span>) + <span class="number">1</span>  </span><br><span class="line">                sum_counts += <span class="number">1</span>  </span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 跳出内部循环，因为每个MAC地址只应对应一个服务名称  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建DataFrame  </span></span><br><span class="line">    df_result = pd.DataFrame.from_dict(service_counts, orient=<span class="string">'index'</span>, columns=[<span class="string">'Count of Link is Down'</span>]).reset_index()  </span><br><span class="line">    df_result.columns = [<span class="string">'Service Name'</span>, <span class="string">'Count of Link is Down'</span>]  </span><br><span class="line"></span><br><span class="line">    time_info_row = pd.Series([<span class="string">'Start Time: '</span> + start_time, <span class="string">'End Time: '</span> + end_time], index=[<span class="string">'Service Name'</span>, <span class="string">'Count of Link is Down'</span>])  </span><br><span class="line">    time_info_df = pd.DataFrame([time_info_row])  <span class="comment"># 将Series转换为DataFrame  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将时间信息DataFrame放在原始DataFrame的开始位置  </span></span><br><span class="line">    df_result = pd.concat([time_info_df, df_result]).reset_index(drop=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在DataFrame的末尾添加一行总次数  </span></span><br><span class="line">    total_row = pd.DataFrame({<span class="string">'Service Name'</span>: [<span class="string">'Total'</span>], <span class="string">'Count of Link is Down'</span>: [sum_counts]}, index=[<span class="built_in">len</span>(df_result)-<span class="number">1</span>])  </span><br><span class="line">    df_result = pd.concat([df_result.iloc[:-<span class="number">1</span>], total_row]).reset_index(drop=<span class="literal">True</span>)  <span class="comment"># 重置索引，不包括最后一行（因为我们将在其后添加总次数）  </span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df_result   </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_dataframe_in_gui</span>(<span class="params">df, frame_widget</span>):  </span><br><span class="line">    <span class="comment"># 清除之前的表格内容（如果有的话）  </span></span><br><span class="line">    <span class="keyword">for</span> widget <span class="keyword">in</span> frame_widget.winfo_children():  </span><br><span class="line">        widget.destroy()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 注意这里：将df.columns转换为列表  </span></span><br><span class="line">    column_names = <span class="built_in">list</span>(df.columns)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个Treeview组件来显示数据  </span></span><br><span class="line">    tree = ttk.Treeview(frame_widget, columns=column_names, show=<span class="string">'headings'</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置列标题  </span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> column_names:  </span><br><span class="line">        tree.heading(col, text=col)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 插入数据到Treeview  </span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():  </span><br><span class="line">        tree.insert(<span class="string">''</span>, <span class="string">'end'</span>, values=row.tolist())  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将Treeview添加到frame中（如果它之前没有被添加到frame中，这一步是必要的）  </span></span><br><span class="line">    tree.pack(fill=<span class="string">'both'</span>, expand=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    root = tk.Tk()</span><br><span class="line">    root.geometry(<span class="string">'400x500'</span>)</span><br><span class="line">    root.title(<span class="string">'Link Down Count'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个Frame来放置Treeview  </span></span><br><span class="line">    <span class="keyword">global</span> frame</span><br><span class="line">    frame = tk.Frame(root)  </span><br><span class="line">    frame.pack(fill=<span class="string">'both'</span>, expand=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line">    load_button = tk.Button(root, text=<span class="string">'选择CSV文件'</span>, command=load_csv_and_process)</span><br><span class="line">    load_button.pack()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'mac_dict.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">global</span> mac_dict</span><br><span class="line">            mac_dict = json.load(f)</span><br><span class="line"></span><br><span class="line">        root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>导出为.exe 可执行文件命令</p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line">pyinstaller --onefile --icon=./icon/dog.ico --noconsole cld.py</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>提前准备 json 文件，格式为:</p>
 <figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line"> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"H800-1"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">"a088cxxx"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"a088cxxx"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"a088cxxx"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"a088cxxx"</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"H800-2"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">"a088cxxx"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"a088cxxx"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"a088cxxx"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"a088cxxx"</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p>键为<code>机器的名称</code></p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 查看机器名称</span></span><br><span class="line"><span class="built_in">uname</span> -n</span><br></pre></td></tr></tbody></table></figure>

<p>值为 <code>MAC地址</code></p>
<figure class="highlight sh"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 查看特定接口的MAC地址：</span></span><br><span class="line">ip <span class="built_in">link</span> show eth0</span><br></pre></td></tr></tbody></table></figure>

<p>其中 <code>eth0</code> 可以替换为你要查询的网络接口名称。</p>
</blockquote>
</li>
</ul>
<h4 id="小工具下载地址"><a href="#小工具下载地址" class="headerlink" title="小工具下载地址"></a>小工具下载地址</h4><p><a href="https://sharrr.com/s#f5524aae-7492-47cc-be11-5d98b85afbfb/3bMQOBu6ZgwilavK69J%2FmA%3D%3D/5tLg2uk_z1omqApsxrV9BCcPd9XEUGs0mRf3jQk4xtQ">统计 Link Down 小工具</a></p>
<p>过期联系我哦～</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Ops</tag>
        <tag>python</tag>
        <tag>NVIDIA</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 html 创建注册表单</title>
    <url>/2024/08/29/%E5%89%8D%E7%AB%AF/20240829_%E4%BD%BF%E7%94%A8html%E5%88%9B%E5%BB%BA%E6%B3%A8%E5%86%8C%E8%A1%A8%E5%8D%95/</url>
    <content><![CDATA[<p>使用 HTML 表单收集访问网页的用户的信息，html5 及 css3 详细说明</p>
<p><img src="/../../img/frontend_form-1.png"></p>
<span id="more"></span>

<h3 id="HTML详解"><a href="#HTML详解" class="headerlink" title="HTML详解"></a>HTML 详解</h3><ul>
<li><p>代码如下:</p>
  <figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Registration Form<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"styles.css"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Registration Form<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Please fill out this form with the required information<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">method</span>=<span class="string">"post"</span> <span class="attr">action</span>=<span class="string">'https://register-demo.freecodecamp.org'</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"first-name"</span>&gt;</span>Enter Your First Name: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"first-name"</span> <span class="attr">name</span>=<span class="string">"first-name"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"last-name"</span>&gt;</span>Enter Your Last Name: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"last-name"</span> <span class="attr">name</span>=<span class="string">"last-name"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"email"</span>&gt;</span>Enter Your Email: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"email"</span> <span class="attr">name</span>=<span class="string">"email"</span> <span class="attr">type</span>=<span class="string">"email"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"new-password"</span>&gt;</span>Create a New Password: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"new-password"</span> <span class="attr">name</span>=<span class="string">"new-password"</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">pattern</span>=<span class="string">"[a-z0-5]{8,}"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">legend</span>&gt;</span>Account type (required)<span class="tag">&lt;/<span class="name">legend</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"personal-account"</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"personal-account"</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"account-type"</span> <span class="attr">class</span>=<span class="string">"inline"</span> <span class="attr">checked</span> /&gt;</span> Personal<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"business-account"</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"business-account"</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"account-type"</span> <span class="attr">class</span>=<span class="string">"inline"</span> /&gt;</span> Business<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"profile-picture"</span>&gt;</span>Upload a profile picture: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"profile-picture"</span> <span class="attr">type</span>=<span class="string">"file"</span> <span class="attr">name</span>=<span class="string">"file"</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"age"</span>&gt;</span>Input your age (years): <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"age"</span> <span class="attr">type</span>=<span class="string">"number"</span> <span class="attr">name</span>=<span class="string">"age"</span> <span class="attr">min</span>=<span class="string">"13"</span> <span class="attr">max</span>=<span class="string">"120"</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"referrer"</span>&gt;</span>How did you hear about us?</span><br><span class="line">          <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"referrer"</span> <span class="attr">name</span>=<span class="string">"referrer"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">""</span>&gt;</span>(select one)<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"1"</span>&gt;</span>freeCodeCamp News<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"2"</span>&gt;</span>freeCodeCamp YouTube Channel<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"3"</span>&gt;</span>freeCodeCamp Forum<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"4"</span>&gt;</span>Other<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"bio"</span>&gt;</span>Provide a bio:</span><br><span class="line">          <span class="tag">&lt;<span class="name">textarea</span> <span class="attr">id</span>=<span class="string">"bio"</span> <span class="attr">name</span>=<span class="string">"bio"</span> <span class="attr">rows</span>=<span class="string">"3"</span> <span class="attr">cols</span>=<span class="string">"30"</span> <span class="attr">placeholder</span>=<span class="string">"I like coding on the beach..."</span>&gt;</span><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"terms-and-conditions"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">"inline"</span> <span class="attr">id</span>=<span class="string">"terms-and-conditions"</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">required</span> <span class="attr">name</span>=<span class="string">"terms-and-conditions"</span> /&gt;</span> I accept the <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"https://www.freecodecamp.org/news/terms-of-service/"</span>&gt;</span>terms and conditions<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"Submit"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><code>&lt;body&gt;</code> 部分主要分为 <strong>3 部分</strong> , 对应 <code>&lt;h1&gt;</code>,<code> &lt;p&gt;</code>, **<code>&lt;form&gt;</code>** 元素</p>
<p><img src="/../../img/frontend_form-2.png"></p>
</li>
<li><p><strong><code>&lt;form&gt;</code><strong>元素中包含</strong> 5 部分</strong> , 对应 3 个 <code>&lt;fieldset&gt;</code>, 1 个 <code>&lt;label&gt;</code>, 1 个 <code>&lt;submit&gt;</code></p>
<p><img src="/../../img/frontend_form-3.png"></p>
<ul>
<li><p>5 个元素中，每个元素对应功能</p>
<table>
<thead>
<tr>
<th align="center">元素名称</th>
<th align="center">功能描述</th>
<th>包含元素</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>&lt;fieldset&gt;</code></td>
<td align="center">基础用户信息：姓 \ 名 \ 邮箱 \ 密码</td>
<td><code>&lt;label&gt;</code></td>
</tr>
<tr>
<td align="center"><code>&lt;fieldset&gt;</code></td>
<td align="center">选择用户类型：个人 \ 企业</td>
<td><code>&lt;legend&gt;``&lt;label&gt;</code></td>
</tr>
<tr>
<td align="center"><code>&lt;fieldset&gt;</code></td>
<td align="center">额外补充信息：个人图片 \ 年龄 \ 用户渠道 \ 用户个人说明</td>
<td><code>&lt;label&gt;``&lt;select&gt;``&lt;textarea&gt;</code></td>
</tr>
<tr>
<td align="center"><code>&lt;label&gt;</code></td>
<td align="center">注册需知条款</td>
<td><code>&lt;label&gt;``&lt;a&gt;</code></td>
</tr>
<tr>
<td align="center"><code>&lt;input&gt;</code></td>
<td align="center">提交按钮</td>
<td><code>&lt;label&gt;</code></td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>第一个 <code>&lt;fiedldset&gt;</code> 元素详解</p>
  <figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 定义一个字段集，包含用户注册所需的基本信息输入字段 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 标签和输入框，用于输入用户的名字 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"first-name"</span>&gt;</span>Enter Your First Name: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"first-name"</span> <span class="attr">name</span>=<span class="string">"first-name"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 标签和输入框，用于输入用户的姓氏 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"last-name"</span>&gt;</span>Enter Your Last Name: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"last-name"</span> <span class="attr">name</span>=<span class="string">"last-name"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 标签和输入框，用于输入用户的电子邮件地址 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"email"</span>&gt;</span>Enter Your Email: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"email"</span> <span class="attr">name</span>=<span class="string">"email"</span> <span class="attr">type</span>=<span class="string">"email"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 标签和输入框，用于创建一个新的密码，密码必须符合指定的模式 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"new-password"</span>&gt;</span>Create a New Password: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"new-password"</span> <span class="attr">name</span>=<span class="string">"new-password"</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">pattern</span>=<span class="string">"[a-z0-5]{8,}"</span> <span class="attr">required</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>第二个 <code>&lt;fiedldset&gt;</code> 元素详解</p>
<figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 定义一个字段集，包含账户类型的选择 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 字段集的标题，说明账户类型是必填项 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">legend</span>&gt;</span>Account type (required)<span class="tag">&lt;/<span class="name">legend</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 个人账户的单选按钮，默认选中 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"personal-account"</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"personal-account"</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"account-type"</span> <span class="attr">class</span>=<span class="string">"inline"</span> <span class="attr">checked</span> /&gt;</span> Personal<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 商业账户的单选按钮 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"business-account"</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"business-account"</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"account-type"</span> <span class="attr">class</span>=<span class="string">"inline"</span> /&gt;</span> Business<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>第三个 <code>&lt;fiedldset&gt;</code> 元素详解</p>
  <figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 上传个人资料图片的表单元素 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"profile-picture"</span>&gt;</span>Upload a profile picture: <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"profile-picture"</span> <span class="attr">type</span>=<span class="string">"file"</span> <span class="attr">name</span>=<span class="string">"file"</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 输入年龄的表单元素，限制年龄范围为13到120岁 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"age"</span>&gt;</span>Input your age (years): <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"age"</span> <span class="attr">type</span>=<span class="string">"number"</span> <span class="attr">name</span>=<span class="string">"age"</span> <span class="attr">min</span>=<span class="string">"13"</span> <span class="attr">max</span>=<span class="string">"120"</span> /&gt;</span><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 选择如何听说本网站的下拉菜单 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"referrer"</span>&gt;</span>How did you hear about us?</span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"referrer"</span> <span class="attr">name</span>=<span class="string">"referrer"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">""</span>&gt;</span>(select one)<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"1"</span>&gt;</span>freeCodeCamp News<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"2"</span>&gt;</span>freeCodeCamp YouTube Channel<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"3"</span>&gt;</span>freeCodeCamp Forum<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"4"</span>&gt;</span>Other<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 提供个人简介的文本区域 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"bio"</span>&gt;</span>Provide a bio:</span><br><span class="line">    <span class="tag">&lt;<span class="name">textarea</span> <span class="attr">id</span>=<span class="string">"bio"</span> <span class="attr">name</span>=<span class="string">"bio"</span> <span class="attr">rows</span>=<span class="string">"3"</span> <span class="attr">cols</span>=<span class="string">"30"</span> <span class="attr">placeholder</span>=<span class="string">"I like coding on the beach..."</span>&gt;</span><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><code>&lt;label&gt;</code> 元素详解</p>
  <figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"terms-and-conditions"</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 复选框，用户必须勾选以接受服务条款和条件，required属性表示这个选项是必填的 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">"inline"</span> <span class="attr">id</span>=<span class="string">"terms-and-conditions"</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">required</span> <span class="attr">name</span>=<span class="string">"terms-and-conditions"</span> /&gt;</span> I accept the <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"https://www.freecodecamp.org/news/terms-of-service/"</span>&gt;</span>terms and conditions<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><code>&lt;input&gt;</code> 元素详解</p>
  <figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 提交按钮 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"Submit"</span> /&gt;</span></span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h3 id="CSS详解"><a href="#CSS详解" class="headerlink" title="CSS详解"></a>CSS 详解</h3><ul>
<li><p>代码如下 :</p>
<figure class="highlight css"><table><tbody><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span> {</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#1b1b32</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#f5f6f7</span>;</span><br><span class="line">    <span class="attribute">font-family</span>: Tahoma;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">h1</span>, <span class="selector-tag">p</span> {</span><br><span class="line">    <span class="attribute">margin</span>:  auto;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">form</span> {</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">60vw</span>;</span><br><span class="line">    <span class="attribute">max-width</span>: <span class="number">500px</span>;</span><br><span class="line">    <span class="attribute">min-width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span> auto;</span><br><span class="line">    <span class="attribute">padding-bottom</span>: <span class="number">1em</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">fieldset</span> {</span><br><span class="line">    <span class="attribute">border</span>: none;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">1rem</span> <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">border-bottom</span>: <span class="number">3px</span> solid <span class="number">#3b3b4f</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">fieldset</span><span class="selector-pseudo">:last-of-type</span> {</span><br><span class="line">    <span class="attribute">border-bottom</span>: none;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">label</span> {</span><br><span class="line">    <span class="attribute">display</span>: block;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0.2rem</span> <span class="number">0</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">input</span>,</span><br><span class="line">  <span class="selector-tag">textarea</span>,</span><br><span class="line">  <span class="selector-tag">select</span> {</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">2px</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">min-height</span>: <span class="number">2em</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">input</span>, <span class="selector-tag">textarea</span> {</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#0a0a23</span>;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#0a0a23</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#ffffff</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-class">.inline</span> {</span><br><span class="line">    <span class="attribute">width</span>: unset;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span> <span class="number">0.5em</span> <span class="number">0</span> <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">vertical-align</span>: middle;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">input</span><span class="selector-attr">[type=<span class="string">"submit"</span>]</span> {</span><br><span class="line">    <span class="attribute">display</span>: block;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">60%</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">1em</span> auto;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">2em</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1.1rem</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#3b3b4f</span>;</span><br><span class="line">    <span class="attribute">border-color</span>: white;</span><br><span class="line">    <span class="attribute">min-width</span>: <span class="number">300px</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">input</span><span class="selector-attr">[type=<span class="string">"file"</span>]</span> {</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">1px</span> <span class="number">2px</span>;</span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-class">.inline</span>{</span><br><span class="line">    <span class="attribute">display</span>: inline; </span><br><span class="line">  }</span><br><span class="line">  </span><br><span class="line">  <span class="selector-tag">a</span> {</span><br><span class="line">    <span class="attribute">color</span>:<span class="number">#dfdfe2</span></span><br><span class="line">  }</span><br><span class="line">  </span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<blockquote>
<h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><p><a href="https://www.freecodecamp.org/chinese/learn/2022/responsive-web-design/">freecodecamp_响应式网页设计_通过创建注册表学习 HTML 表单</a></p>
</blockquote>
]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>front end</tag>
        <tag>html</tag>
      </tags>
  </entry>
</search>
